{"meta":{"title":"王敏蕊个人饲养间","subtitle":"三思而后言","description":null,"author":"王敏蕊","url":"http://wangminrui.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-07-11T08:39:57.000Z","updated":"2019-07-11T09:10:00.921Z","comments":false,"path":"categories/index.html","permalink":"http://wangminrui.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-07-04T11:56:18.000Z","updated":"2019-07-04T11:56:26.824Z","comments":true,"path":"about/index.html","permalink":"http://wangminrui.github.io/about/index.html","excerpt":"","text":"基本信息 王敏蕊 女 1995.07.11 江西南昌人 2017届武汉理工大学物联网工程学士 2020届武汉理工大学计算机科学与技术硕士研究生在读（推免） 邮箱：wangminrui.panda@qq.com"},{"title":"tags","date":"2019-07-11T06:36:12.000Z","updated":"2019-07-11T06:58:07.927Z","comments":false,"path":"tags/index.html","permalink":"http://wangminrui.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"kafka操作","slug":"kafka操作","date":"2019-08-01T02:03:24.000Z","updated":"2019-08-01T07:13:54.736Z","comments":true,"path":"2019/08/01/kafka操作/","link":"","permalink":"http://wangminrui.github.io/2019/08/01/kafka操作/","excerpt":"","text":"kafka是一个分布式消息系统 查看当前topic 12# kafka目录./bin/kafka-topics.sh --list --zookeeper localhost:2181 终端命令行模拟发送、接受消息 producer 消息的生成者，即发布消息 consumer 消息的消费者，即订阅消息 broker Kafka以集群的方式运行，可以由一个或多个服务组成，服务即broker zookeeper 协调转发 打开两个终端 一个终端发送消息 一个终端接收消息： producer，指定的Socket(localhost+9092),说明生产者的消息要发往kafka，也即是broker consumer, 指定的Socket(localhost+2181),说明消费者的消息来自zookeeper（协调转发） 123456# 进入kafka工作目录# 生产者 如果是本机 kafkaserver=localhost 9092是kafka默认端口./bin/kafka-console-producer.sh --broker-list kafkaserver:9092 --topic topicn_ame# 消费者 如果是本机 zookeeperserver=localhost 2181是zookeeper默认端口.bin//kafka-console-consumer.sh --zookeeper zookeeperserver:2181 --topic topic_name --from-beginning kafka配置 在kafka工作目录下：config/server.properties kafka配置及基本命令","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wangminrui.github.io/categories/备忘录/"}],"tags":[]},{"title":"海量数据处理方法","slug":"海量数据处理方法","date":"2019-07-30T14:02:04.000Z","updated":"2019-07-31T15:19:21.196Z","comments":true,"path":"2019/07/30/海量数据处理方法/","link":"","permalink":"http://wangminrui.github.io/2019/07/30/海量数据处理方法/","excerpt":"1. Hash法Hash一般称为散列，关于散列表的知识，可参见数据结构：散列表 Hash主要用来“快速存取”，因为它可以在$O(1)$的时间复杂度下查找到目标元素，或者判断其是否存在。 适合的问题：在处理海量数据的过程中，使用Hash方法一般可以快速存取、统计某些数据，将大量数据进行分类，例如提取某日访问网站次数最多的IP地址等。","text":"1. Hash法Hash一般称为散列，关于散列表的知识，可参见数据结构：散列表 Hash主要用来“快速存取”，因为它可以在$O(1)$的时间复杂度下查找到目标元素，或者判断其是否存在。 适合的问题：在处理海量数据的过程中，使用Hash方法一般可以快速存取、统计某些数据，将大量数据进行分类，例如提取某日访问网站次数最多的IP地址等。 2. Bit-map法Bit-map（位图） 适合的问题：海量数据的快速查找、判重、删除等。 3. Bloom Filter法4. 数据库优化法5. 倒排索引法6. 外排序法7. Trie树8. 堆9. 双层桶法10. Map-Reduce 参考资料： Java程序员面试笔试宝典","categories":[{"name":"算法编程","slug":"算法编程","permalink":"http://wangminrui.github.io/categories/算法编程/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://wangminrui.github.io/tags/面试/"}]},{"title":"Java8：数值流","slug":"Java8-8","date":"2019-07-30T08:04:12.000Z","updated":"2019-07-31T14:35:31.406Z","comments":true,"path":"2019/07/30/Java8-8/","link":"","permalink":"http://wangminrui.github.io/2019/07/30/Java8-8/","excerpt":"1. 为什么数值流会做特殊处理？eg：计算一个菜单中所有菜的热量总和 123int calories = menu.stream() .map(Dish::getCalories) .reduce(0, Integer::sum) 上述代码虽然能够实现计算一个菜单中所有菜热量总和的功能，但是却暗含了装箱成本。每个Integer都必须拆箱成一个原始类型，再进行求和。 虽然流中的元素是Integer类型，但Streams接口没有定义sum方法（因为如果把Stream&lt;Dish&gt;这样的进行sum操作是没有任何意义的），因此Stream API提供原始类型特化，专门支持处理数值流。","text":"1. 为什么数值流会做特殊处理？eg：计算一个菜单中所有菜的热量总和 123int calories = menu.stream() .map(Dish::getCalories) .reduce(0, Integer::sum) 上述代码虽然能够实现计算一个菜单中所有菜热量总和的功能，但是却暗含了装箱成本。每个Integer都必须拆箱成一个原始类型，再进行求和。 虽然流中的元素是Integer类型，但Streams接口没有定义sum方法（因为如果把Stream&lt;Dish&gt;这样的进行sum操作是没有任何意义的），因此Stream API提供原始类型特化，专门支持处理数值流。 2. 原始类型流特化Java 8引入了三个原始类型特化流接口来解决这个问题：IntStream、DoubleStream和LongStream，分别将流中的元素特化为int、long和double，从而避免了暗含的装箱成本。 2.1 映射到数值流流转换为特化版本的常用方法是：mapToInt、mapToDouble和mapToLong 1234// 计算一个菜单中所有菜的热量总和int calories = menu.stream() .mapToInt(Dish::getCalories) //返回一个IntStream .sum() //如果流是空的，sum默认返回0 IntStream还支持其他方法，如：max、min、average等 2.2 转换回对象流数值流转换回对象流使用boxed方法 12IntStream intStream = menu.stream().mapToInt(Dish::getCalories);Stream&lt;Integer&gt; stream = intStream.boxed(); //将IntStream转化回Stream 2.3 默认值OptionalInt求和时如果为空，返回默认值0，这样的操作是可以的。但如果计算最大元素，返回0时如何判断这是空返回的0，还是求得的最大元素就是0？因此，对接受返回值的Optional类也有特化版本：OptionalInt、OptionalDouble和OptionalLong 1234OptionalInt maxCalories = menu.stream() .mapToInt(Dish::getCalories) .max();int max = maxCalories.orElse(1); //如果没有最大值，显式提供一个默认最大值 3. 数值范围生成一个数值范围之间的数可以用IntStream和LongStream中的静态方法：range和rangeClosed。这两个方法接受两个参数：起始值和结束值。其中，range是不包含结束值的，而rangeClosed包含结束值。 123IntStream evenNumbers = IntStream.rangeClosed(1, 100). .filter(n -&gt; n%2 == 0); //从1到100的偶数System.out.println(evenNumbers.count()); //50个偶数，如果用range方法的化，将输出49 4. 一个例子：勾股数勾股数指满足 $a^2+b^2=c^2$ 的三元组 $(a,b,c)$ 12345678910111213141516171819Stream&lt;int[]&gt; pythagoreanTiples = IntStream.rangeClosed(1, 100).boxed() .flatMap(a -&gt; IntStream.rangeClosed(a, 100) .filter(b -&gt; Math.sqrt(a*a + b*b) % 1 == 0) .mapToObj(b -&gt; new int[]&#123;a, b, (int)Math.sqrt(a*a + b*b)&#125;) );pythagoreanTiples.limit(5) .forEach(t -&gt; System.out.println(t[0] + \", \" + t[1] + \", \" + t[2]));//输出3, 4, 55, 12, 136, 8, 107, 24, 258, 15, 17","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"Java8 stream","slug":"Java8-stream","permalink":"http://wangminrui.github.io/tags/Java8-stream/"}]},{"title":"Java中的短路求值","slug":"Java中的短路求值","date":"2019-07-28T08:19:01.000Z","updated":"2019-07-30T11:32:29.366Z","comments":true,"path":"2019/07/28/Java中的短路求值/","link":"","permalink":"http://wangminrui.github.io/2019/07/28/Java中的短路求值/","excerpt":"","text":"有些操作不需要完成整个操作就能得到结果","categories":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"},{"name":"Java基础","slug":"Java基础","permalink":"http://wangminrui.github.io/tags/Java基础/"}]},{"title":"Java中import和import static的区别","slug":"Java中import和import-static的区别","date":"2019-07-27T07:46:13.000Z","updated":"2019-07-30T08:19:46.234Z","comments":true,"path":"2019/07/27/Java中import和import-static的区别/","link":"","permalink":"http://wangminrui.github.io/2019/07/27/Java中import和import-static的区别/","excerpt":"","text":"待整理","categories":[],"tags":[{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"}]},{"title":"Java8：流的复杂操作","slug":"Java8-7","date":"2019-07-26T07:15:19.000Z","updated":"2019-07-31T09:03:42.593Z","comments":true,"path":"2019/07/26/Java8-7/","link":"","permalink":"http://wangminrui.github.io/2019/07/26/Java8-7/","excerpt":"1. 筛选和切片如何选择流中的元素：用谓词筛选，筛选出各不相同的元素，忽略流中的头几个元素，或将流截短至指定长度 1.1 filter: 用谓词筛选filter接受一个谓词Predicate&lt;T&gt;，返回一个包括所有符合谓词元素的流。 1234//筛选出所有素材，创建一张素食菜单List&lt;Dish&gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(toList());","text":"1. 筛选和切片如何选择流中的元素：用谓词筛选，筛选出各不相同的元素，忽略流中的头几个元素，或将流截短至指定长度 1.1 filter: 用谓词筛选filter接受一个谓词Predicate&lt;T&gt;，返回一个包括所有符合谓词元素的流。 1234//筛选出所有素材，创建一张素食菜单List&lt;Dish&gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(toList()); 1.2 distinct: 筛选各异元素distinct返回一个元素各异（根据流所生成元素的hasCode和equals方法实现）的流 123456// 筛选出列表中所有的偶数List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);numbers.stream() .filter(i -&gt; i % 2 == 0) .distinct() .forEach(System.out::println) 1.3 limit: 截短流limit(n)会返回一个不超过给定长度的流。所需长度作为参数传递给limit。如果流是有序的，则最多会返回前n个元素。如果流是无序的，比如是一个Set，limit的结果不会以任何顺序排列。 12345//选出热量超过300卡路里的头三道菜List&lt;Dish&gt; dishes = menu.stream() .filter(d -&gt; d.getCalories() &gt; 300) .limit(3) .collect(toList()); 1.4 skip: 跳过元素skip(n)返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回一个空流。 12345//跳过超过300卡路里的头两道菜List&lt;Dish&gt; dishes = menu.stream() .filter(d -&gt; d.getCalories() &gt; 300) .skip(2) .collect(toList()); 2. 映射从流对象中提取某些信息出来 2.1 map: 对流中的每一个元素应用函数map接受一个函数作为参数，这个函数被应用到每个元素上，并将其映射成一个新的元素。 12345678910111213141516//提取菜肴名称List&lt;String&gt; dishNames = menu.stream() .map(Dish::getName) .collect(toList());//给定单词列表，想要返回另一个列表，显示每个单词中有几个字母List&lt;String&gt; words = Arrays.asList(\"Java 8\", \"Lambdas\", \"In\", \"Action\");List&lt;Integer&gt; wordLengths = words.stream() .map(String::length) .collect(toList());//返回每道菜的名称有多长List&lt;String&gt; dishNameLengths = menu.stream() .map(Dish::getName) .map(String::length) .collect(toList()); 2.2 flatMap: 流的扁平化扩展上一节的问题，给定单词表，如何返回一张列表，列出里面各不相同的字符。例如给出[“Hello”, “World”]，返回[“H”, “e”, “l”, “o”, “W”, “r”, “d”] 12345//这样是不行的words.stream() .map(word -&gt; word.split(\"\")) //为每个单词返回了一个String[]，因此返回的流是Stream&lt;String[]&gt;类型的 .distinct() //而这一步需要的是Stream&lt;String&gt;类型的输入 .collect(toList()); flatMap将上一步产生的单个流都合并起来，即扁平化为一个流 123456List&lt;String&gt; uniqueCharacters = words.stream() .map(w -&gt; w.split(\"\")) .flatMap(Arrays::stream) //Arrays::stream把每个数组变成单个流 .distinct() .collect(toList()); 2.3 test123456789101112131415161718192021222324252627// 给定数字列表，如何返回一个由每个数的平方构成的列表List&lt;Integer&gt; numbers = Arrays.asList(1,2,3,4,5);List&lt;Integer&gt; squares = numbers.stream() .map(n -&gt; n*n) .collect(toList());// 给定两个数字列表，如何返回所有数对。例如给定[1,2,3]和[3,4]，应该返回[(1,3),(1,4),(2,3),(2,4),(3,3),(3,4)]List&lt;Integer&gt; numbers1 = Arrays.asList(1, 2, 3);List&lt;Integer&gt; numbers2 = Arrays.asList(3, 4);List&lt;int[]&gt; pairs = numbers1.stream() .flatMap(i -&gt; numbers2.stream() //如果不使用flatMap，将生成&lt;Stream&lt;Integer[]&gt;&gt;，每个数组一个单个流 .map(j -&gt; new int[]&#123;i, j&#125;) ) .collect(toList());// 扩展前面的例子，如何返回总和能被3整除的数对呢？List&lt;Integer&gt; numbers1 = Arrays.asList(1, 2, 3);List&lt;Integer&gt; numbers2 = Arrays.asList(3, 4);List&lt;int[]&gt; pairs = numbers1.stream() .flatMap(i -&gt; numbers2.stream() .filter(j -&gt; (i+j)%3 == 0) //选出能被3整出的数对 .map(j -&gt; new int[]&#123;i, j&#125;) ) .collect(toList()); 3. 查找和匹配查找数据集中的某些元素是否匹配一个给定的属性 3.1 anyMatch: 检查谓词是否至少匹配一个元素anyMatch方法接受谓词参数，返回boolean类型，判断流中是否由一个元素能匹配给定谓词 1234// 看菜单中是否由素食可以选择if (menu.stream().anyMatch(Dish::isVegetarian))&#123; System.out.println(\"The menu is (somewhat) vegetarian friendly!!\");&#125; 3.2 allMatch、noneMath: 检查谓词是否匹配所有元素allMatch方法接受谓词参数，返回boolean类型，判断流中的元素是否都能匹配给定的谓词 123// 所有菜是否都低于1000卡路里boolean isHealthy = menu.stream() .allMatch(d -&gt; d.getCalorires() &lt; 1000); noneMath方法与allMatch完全相反，它用来判断流中元素是否都不能匹配给定的谓词 123// 所有菜是否都低于1000卡路里boolean isHealthy = menu.stream() .noneMatch(d -&gt; d.getCalorires() &gt;= 1000); 短路求值：不需要处理整个流就得到结果 anyMatch、allMatch和noneMatch都用到了短路操作 这种操作可以把无限流变成有限流 3.3 findAny: 查找元素findAny方法接受一个函数作为参数，返回当前流中的任意元素，可以和其他流操作结合使用 123456// 找一道素食菜肴Optional&lt;Dish&gt; dish = menu.stream() .filter(Dish::isVegetarian) .findAny(); .ifPresent(d -&gt; System.out.println(d.getName())); //在找到素食菜肴时打印出来 Optional类 Optional&lt;T&gt;类（java.util.Optional）是一个容器类，代表一个值存在或不存在 用Optional接受返回值，不用担心null的问题，避免了和null检查相关的bug Optional中有几种显式检查值是否存在或处理值不存在的情形的方法： isPresent()：Optional包含值的时候返回true，否则返回false ifPresent(Consumer&lt;T&gt; block)：在值存在时执行给定代码块 T get()：在值存在时返回值，否则抛出一个NoSuchElement异常 T orElse(T other)：在值存在时返回值，否则返回一个默认值 3.4 findFirst: 查找第一个元素findFirst方法接受一个函数作为参数，返回当前流中的第一个元素 1234567// 找到第一个平方能被3整除的数List&lt;Integer&gt; someNumbers = Arrays.asList(1,2,3,4,5);Optional&lt;Integer&gt; firstSquareDivisibleByThree = someNumbers.stream() .map(x -&gt; x*x) .filter(x -&gt; x%3 == 0) .findFirst(); findFirst方法比findAny方法在并行上限制更多 4. 归约将一个流中的元素组合起来，使用reduce操作来表达更加复杂的查询 4.1 元素求和reduce方法用Lambda反复结合每个元素，直到流被归约，它接受两个参数： 初始值 BinaryOperator&lt;T&gt;：将两个元素结合起来产生一个新值 1234567891011// Java8之前，求和操作int sum = 0;for (int x : numbers)&#123; sum += x;&#125;// Java8int sum = numbers.stream().reduce(0, (a,b) -&gt; a+b);// 当没有初始值时Optional&lt;Integer&gt; sum = numbers.stream().reduce((a,b) -&gt; a+b); reduce操作是如何对一个数字流求和的？如果有一个数据流：{2，4，6}，首先，0作为Lambda的第一个参数，从流中获得第二个参数2，形成新的累积值。然后再用累积值和流中的下一个元素4调用Lambda，产生新的累积值，重复以上过程，得到最终结果12。 4.2 最大值和最小值12345678910111213// 求最大值Optional&lt;Integer&gt; max = numbers.stream().reduce(Integer::max);// 求最小值Optional&lt;Integer&gt; min = numbers.stream().reduce(Integer::min);// 计算菜肴数long count = menu.stream().count();// 利用map和reduce计算菜肴数int count = menu.stream() .map(d -&gt; 1) //将流中每个元素都映射成数字1，然后用reduce求和 .reduce(0, (a, b) -&gt; a+b); 5. 常用操作总结 操作 类型 返回类型 使用的类型/函数式接口 函数描述符 filter 中间 Stream&lt;T&gt; Predicate&lt;T&gt; T -&gt; boolean distinct 中间（有状态-无界） Stream&lt;T&gt; skip 中间（有状态-无界） Stream&lt;T&gt; long limit 中间（有状态-无界） Stream&lt;T&gt; long map 中间 Stream&lt;R&gt; Function&lt;T,R&gt; T -&gt; R flatMap 中间 Stream&lt;R&gt; Function&lt;T, Stream&lt;R&gt;&gt; T -&gt; Stream&lt;R&gt; sorted 中间（有状态-无界） Stream&lt;T&gt; Comparator&lt;T&gt; (T, T) -&gt; int anyMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean noneMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean allMatch 终端 boolean Predicate&lt;T&gt; T -&gt; boolean findAny 终端 Optional findFirst 终端 Optional forEach 终端 void Consumer&lt;T&gt; T -&gt; void collect 终端 R Collector&lt;T, A, R&gt; reduce 终端（有状态-无界） Optional BinaryOperator&lt;T&gt; (T, T) -&gt; T count 终端 long 流操作：有状态和无状态map、filter等操作都是无状态的：他们没有内部状态reduce、sum、max等操作都是有状态的：他们需要内部状态来累积结果sort、distinct等操作本来和map和filter差不多—都是接受一个流，再生成一个流，但有一个关键区别是，sort和distinct都需要知道先前的历史，即要求将流中所有元素放入缓冲区才能进行操作，这对存储要求是无界的，要是流比较大或是无限的，就可能会有问题，这种操作叫做有状态操作。 6. 实战背景： 交易员类 12345678910111213141516171819202122public class Traders &#123; private final String name; private final String city; public Traders(String n, String c) &#123; this.name = n; this.city = c; &#125; public String getName() &#123; return name; &#125; public String getCity() &#123; return city; &#125; public String toString() &#123; return \"name: \" + this.name + \", \" + \"city: \" + this.city; &#125;&#125; 执行交易类 1234567891011121314151617181920212223242526272829public class Transaction &#123; private final Traders trader; private final int year; private final int value; public Transaction(Traders trader, int year, int value) &#123; this.trader = trader; this.year = year; this.value = value; &#125; public Traders getTrader() &#123; return trader; &#125; public int getYear() &#123; return year; &#125; public int getValue() &#123; return value; &#125; public String toString() &#123; return \"&#123;\" + this.trader.getName() + \", \" + \"year \" + this.year + \", \" + \"value \" + this.value + \"&#125;\"; &#125;&#125; 需要执行的操作： 找出2011年发生的所有交易，并按交易额排序（从低到高） 交易员都在哪些不同的城市工作过？ 查找所有来自剑桥的交易员，并按姓名排序 返回所有交易员的姓名字符串，按字母顺序排序 有没有交易员是在米兰工作的 打印生活在剑桥的交易员的所有交易额 所有交易额中，最高的交易额是多少 找到交易额最小的交易 解答： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import java.util.Arrays;import java.util.List;import java.util.Optional;import java.util.stream.Collectors;import static java.util.Comparator.comparing;public class TraderAndTransaction &#123; public static void main(String[] args) &#123; Traders raoul = new Traders(\"Raoul\", \"Cambridge\"); Traders mario = new Traders(\"Mario\", \"Milan\"); Traders alan = new Traders(\"Alan\", \"Cambridge\"); Traders brian = new Traders(\"Brian\", \"Cambridge\"); List&lt;Transaction&gt; transactions = Arrays.asList( new Transaction(brian, 2011, 300), new Transaction(raoul, 2012, 1000), new Transaction(raoul, 2011, 400), new Transaction(mario, 2012, 710), new Transaction(mario, 2012, 700), new Transaction(alan, 2012, 950) ); System.out.println(\"找出2011年发生的所有交易，并按交易额排序（从低到高）\"); transactions.stream() .filter(t -&gt; t.getYear() == 2012) //2011的交易 .sorted(comparing(Transaction::getValue)) //排序 .forEach(t -&gt; System.out.println(t.toString())); System.out.println(\"-------------------------------------\"); System.out.println(\"交易员都在哪些不同的城市工作过？\"); transactions.stream() .map(transaction -&gt; transaction.getTrader().getCity()) .distinct() .forEach(System.out::println); System.out.println(\"-------------------------------------\"); System.out.println(\"查找所有来自剑桥的交易员，并按姓名排序\"); transactions.stream() .map(Transaction::getTrader) .filter(trader -&gt; trader.getCity().equals(\"Cambridge\")) .sorted(comparing(Traders::getName)) .forEach(trader -&gt; System.out.println(trader.toString())); System.out.println(\"-------------------------------------\"); System.out.println(\"返回所有交易员的姓名字符串，按字母顺序排序\"); transactions.stream() .map(Transaction::getTrader) .distinct() .sorted(comparing(Traders::getName)) .map(Traders::getName) .forEach(System.out::println); System.out.println(\"or\"); String traderStr = transactions.stream() .map(transaction -&gt; transaction.getTrader().getName()) .distinct() .sorted() .reduce(\"\", (n1, n2) -&gt; n1 + n2); System.out.println(traderStr); System.out.println(\"以上方法效率不高，所有字符串都被反复链接，每次迭代的时候都要建立一个新的 String对象\"); traderStr = transactions.stream() .map(transaction -&gt; transaction.getTrader().getName()) .distinct() .sorted() .collect(Collectors.joining()); System.out.println(traderStr); System.out.println(\"-------------------------------------\"); System.out.println(\"有没有交易员是在米兰工作的\"); boolean milanBased = transactions.stream() .anyMatch(transaction -&gt; transaction.getTrader().getCity().equals(\"Milan\")); System.out.println(milanBased); System.out.println(\"-------------------------------------\"); System.out.println(\"打印生活在剑桥的交易员的所有交易额\"); transactions.stream() .filter(transaction -&gt; transaction.getTrader().getCity().equals(\"Cambridge\")) .map(Transaction::getValue) .forEach(System.out::println);; System.out.println(\"-------------------------------------\"); System.out.println(\"所有交易额中，最高的交易额是多少\"); Optional&lt;Integer&gt; highestValue = transactions.stream() .map(Transaction::getValue) .reduce(Integer::max); System.out.println(highestValue); System.out.println(\"-------------------------------------\"); System.out.println(\"找到交易额最小的交易\"); Optional&lt;Transaction&gt; smallestTransaction = transactions.stream() .reduce((t1, t2) -&gt; t1.getValue() &lt; t2.getValue() ? t1 : t2); System.out.println(smallestTransaction.get().toString()); System.out.println(\"or\"); smallestTransaction = transactions.stream() .min(comparing(Transaction::getValue)); System.out.println(smallestTransaction.get().toString()); &#125;&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"Java8 stream","slug":"Java8-stream","permalink":"http://wangminrui.github.io/tags/Java8-stream/"}]},{"title":"关于是否使用存储过程的疑惑","slug":"关于是否使用存储过程的疑惑","date":"2019-07-24T08:36:25.000Z","updated":"2019-07-26T01:46:53.754Z","comments":true,"path":"2019/07/24/关于是否使用存储过程的疑惑/","link":"","permalink":"http://wangminrui.github.io/2019/07/24/关于是否使用存储过程的疑惑/","excerpt":"","text":"这篇博客讲得很详细了 基本上是不推荐的，不推荐理由主要是： 存储过程节省了数据在网络上的传输时间，但节省时间相对太少，可以忽略不计 存储过程一次编译多次执行，但有时候随着数据结构和需求的变化，很可能出现以前的存储过程已经不满足现在的需求，而修改存储过程是一项巨大的任务 存储过程不方便调试和扩展，更没有移植性（阿里巴巴Java编程规范描述的，它强制禁止使用存储过程），如果多个团队同时开发将会是非常难协调的","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"数据库","slug":"学习笔记/数据库","permalink":"http://wangminrui.github.io/categories/学习笔记/数据库/"}],"tags":[{"name":"疑惑辣么多","slug":"疑惑辣么多","permalink":"http://wangminrui.github.io/tags/疑惑辣么多/"},{"name":"数据库","slug":"数据库","permalink":"http://wangminrui.github.io/tags/数据库/"},{"name":"存储过程","slug":"存储过程","permalink":"http://wangminrui.github.io/tags/存储过程/"}]},{"title":"Java8：流的基本概念与基本操作","slug":"Java8-6","date":"2019-07-23T07:34:35.000Z","updated":"2019-07-30T06:10:43.402Z","comments":true,"path":"2019/07/23/Java8-6/","link":"","permalink":"http://wangminrui.github.io/2019/07/23/Java8-6/","excerpt":"1. 为什么要使用流集合是Java中使用最多的API，几乎每个Java应用程序都会制造和处理集合，但集合操作却远远算不上完美： 无法声明式地完成数据操作：很多业务逻辑都涉及类似于数据库的操作，比如：在菜肴中找出低卡路里的菜，如果使用集合操作，需要用迭代器迭代很多遍，但是在SQL语句中，只需要声明式地指定操作：select name from dishes where calorie &lt; 400 大数据量时很麻烦：处理大量数据时，很可能需要并行操作，集合的并行代码更加复杂，调试也很困难","text":"1. 为什么要使用流集合是Java中使用最多的API，几乎每个Java应用程序都会制造和处理集合，但集合操作却远远算不上完美： 无法声明式地完成数据操作：很多业务逻辑都涉及类似于数据库的操作，比如：在菜肴中找出低卡路里的菜，如果使用集合操作，需要用迭代器迭代很多遍，但是在SQL语句中，只需要声明式地指定操作：select name from dishes where calorie &lt; 400 大数据量时很麻烦：处理大量数据时，很可能需要并行操作，集合的并行代码更加复杂，调试也很困难 2. 什么是流流是Java API的新成员 流允许以声明式方式处理数据集合（通过查询语句来表达，而不是临时编写一个实现），可以看作是遍历数据的高级迭代器 流可以透明地并行处理数据，无需编写任何多线程代码 2.1 流的定义 流是从支持数据处理操作的源生成的元素序列 将定义拆开来看： 元素序列： 就像集合一样，流也提供了一个接口，可以访问特定元素类型的一组有序值 集合是数据结构，它的主要目的是以特定的时间/空间复杂度存储和访问元素（如ArrayList、LinkedList） 流的目的在于表达计算（如filter、sorted、map等） 集合讲的是数据，流讲的是计算 源： 流需要一个可以提供数据的源 流的源可以是：集合、数组或输入/输出资源 从有序集合生成的流会保持原有的顺序 数据处理操作： 支持数据处理操作中的数据处理操作类似数据库的操作，已经函数式编程语言常用的操作 如filter、map、reduce、find、match、sort等 2.2 流的特点 流水线： 很多流操作本身会返回一个流，这样多个操作可以链接起来 这样使得一些优化成为可能，如延迟和短路 流水线的操作可以看作对数据源进行数据库式查询 内部迭代 集合的迭代器属于显示迭代 流的迭代式在背后进行的，成为内部迭代 2.3 一个例子：Java7和Java8的对比1234567891011121314151617181920212223242526272829303132333435363738//需求：返回低热量的菜肴名称//Java7List&lt;Dish&gt; lowCaloricDishes = new ArrayList&lt;&gt;();for (Dish d : menu)&#123; if (d.getCalories() &lt; 400)&#123; lowCaloricDishes.add(d); //累加器筛选元素 &#125;&#125;Collections.sort(lowCaloriesDishes, new Comparator&lt;Dish&gt;()&#123; public int compare(Dish d1, Dish d2)&#123; return Integer.compare(d1.getCalories(), d2.getCalories()); //用匿名类对菜肴排序 &#125;&#125;);List&lt;String&gt; lowCaloricDishesName = new ArrayList&lt;&gt;();for (Dish d : lowCaloricDishes)&#123; lowCaloricDishesName.add(d.getName()); //低热量的菜肴名称列表&#125;//Java8import static java.util.Comparator.comparing;import static java.util.stream.Collectors.toList;List&lt;String&gt; lowCaloricDishesName = menu.stream() .filter(d -&gt; d.getCalories() &lt; 400) //选出400卡路里以下的菜肴 .sorted(comparing(Dish::getCalories)) //按照卡路里排序 .map(Dish::getName) //提取菜肴的名称 .collect(toList());//如果要利用多核架构并行执行这段代码，只需要把stream()换成parallelStream()import static java.util.Comparator.comparing;import static java.util.stream.Collectors.toList;List&lt;String&gt; lowCaloricDishesName = menu.parallelStream() .filter(d -&gt; d.getCalories() &lt; 400) //选出400卡路里以下的菜肴 .sorted(comparing(Dish::getCalories)) //按照卡路里排序 .map(Dish::getName) //提取菜肴的名称 .collect(toList()); Java8 流处理的好处是显而易见的： 代码以声明性方式写的：说明想要完成什么（筛选热量低的菜肴）而不是说明如何实现一个操作（利用循环和if条件等控制流语句），这种方式加上行为参数化能够很轻松地应对需求的变化。--声明性：更简洁、更易读 可以把基础操作链接起来：基础操作组合称复杂的数据处理流水线，同时保持代码清晰可读。--可复合：更灵活 充分利用多核架构：filter、sorted、map等操作是与线程模型无关的高层次构建，他们的内部数显可以是单线程的，也可以透明地利用多核架构，而完全不用担心线程和锁。--可并行：性能更好 2.4 另一个例子：完整的流操作12345678import static java.util.stream.Collections.toList;List&lt;String&gt; threeHighCaloricDishNames = menu.stream() .filter(d -&gt; getCalories() &gt; 300) //接受Lambda，从流中派出某些元素 .map(Dish::getName) //接受Lambda，把元素转化称其他形式或提取信息 .limit(3) //截断流，使其元素不超过给定数量 .collect(toList()); //将流转换为其他形式System.out.println(threeHighCaloricDishName); 3. 流和集合的区别3.1 区别一览 流 集合 就像在线播放的视频流 就像存在本地的视频 概念上固定的数据结构（不能增删数据） 内存中真实的数据结构 计算时间 按需计算 数据都得算出来才能成为集合的一部分 遍历次数 只能遍历一次 如果不使用迭代器，可以遍历多次 迭代方式 内部迭代 外部迭代 3.2 概念的差异粗略地说，集合和流之间的差异在于什么时候进行计算。 集合是一个内存中的数据结构，它包含数据结构中目前所有的值—集合中的每个元素都得先算出来才能添加到集合中。（可以随时向集合中添加、删除元素，但每个元素都是必须先算出来，再成为集合的一部分，并存在内存中）流是概念上固定的数据结构（不能增删数据），其元素是按需计算的。用户仅仅从流中提取需要的值，这些值像是一个延迟创建的集合，只有需要时才会计算（按需生成）。而集合是急切创建的，如果想要创建一个包含所有质数的集合，那这个程序算起来就没完没了了，因为总有新的指数要算，然后把它加到集合里，这个集合永远也创建不了。 3.3 外部迭代和内部迭代外部迭代： 使用Collection接口需要用户去做迭代，比如用for-each 内部迭代： Streams库中帮用户把迭代做了，还把得到的流值存在了某个地方，用户只要给出一个函数说要搞什么就行了 123456789101112131415161718// 集合，用for-each循环外部迭代List&lt;String&gt; names = new ArrayList&lt;&gt;();for(Dish d : menu)&#123; names.add(d.getName());&#125;//集合：用背后的迭代器做外部迭代List&lt;String names = new ArrayList&lt;&gt;();Iterator&lt;String&gt; iterator = menu.iterator();while(iterator.hasNext())&#123; Dish d = iterator.next(); names.add(d.getName());&#125;//流：内部迭代List&lt;String&gt; names = menu.stream() .map(Dish::getName) .collect(toList())); 4. 流操作java.util.stream.Stream中的Stream接口中定义了许多操作，它们可以分为两大类：中间操作、终端操作。 4.1 中间操作可以连接起来的六操作称为中间操作 filter、sorted、map等都是中间操作，中间操作接受一个流，然后返回另一个流，中间操作可以链接起来形成流水线。除非流水线上触发终端操作，否则中间操作不会执行任何处理，这是因为中间操作一般都可以合并，在终端操作时一次性全部处理。 下面看一个例子，把每一步的数据打印出来，以了解流的中间操作做了什么 12345678910111213141516171819202122List&lt;String&gt; names = menu.stream() .filter(d -&gt; &#123; System.out.println(\"filtering\" + d.getName());//打印当前筛选菜肴 return d.getCalores &gt; 300; &#125;) .map(d -&gt; &#123; System.out.println(\"mapping\" + d.getName());//打印菜名 return d.getName(); &#125;) .limit(3) .collect(toList());System.out.println(names);//打印结果//filtering pork//mapping pork//filtering beef//mapping beef//filtering chicken//mapping chicken//[pork, beef, chicken] 从打印结果来看，不同菜肴并不是最后一起处理的，这里面利用的流的延迟性质 尽管很多菜的热量都高于300卡路里，但是只选出了前三个，这是limit操作中使用的短路技巧 尽管filter和map是两个独立的操作，但他们合并到同一次遍历了（我们把这种技术叫做循环合并） 4.2 终端操作关闭流的操作称为终端操作 终端操作会从流的流水线生成结果，其结果是任何不是流的值，比如List、Integer，甚至void。比如，collect操作生成一个结果，forEach是一个返回void的终端操作，它会对源中的每个元素应用一个Lambda 1menu.stream().forEach(System.out::println); 4.3 使用流总之，流的使用一般包括三件事： 一个数据源（如集合）来执行一个查询 一个中间操作链，形成一条流的流水线 一个终端操作，执行流水线，并生成结果 流的流水线背后的理念类似于构建器模式。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"Java8 stream","slug":"Java8-stream","permalink":"http://wangminrui.github.io/tags/Java8-stream/"}]},{"title":"Java8：复合Lambda表达式","slug":"Java8-5","date":"2019-07-19T06:30:36.000Z","updated":"2019-07-30T06:10:23.500Z","comments":true,"path":"2019/07/19/Java8-5/","link":"","permalink":"http://wangminrui.github.io/2019/07/19/Java8-5/","excerpt":"Java8中函数式接口都提供了允许复合的方法。比如，可以让两个Predicate之间做一个or操作，组成更大的Predicate，或是让一个函数的结果成为另一个函数的输入。 但是函数式接口怎么可能有这么多方法呢？（函数式接口的定义就是只拥有一个抽象方法的接口）。 所以，实现复合的方法都是默认方法","text":"Java8中函数式接口都提供了允许复合的方法。比如，可以让两个Predicate之间做一个or操作，组成更大的Predicate，或是让一个函数的结果成为另一个函数的输入。 但是函数式接口怎么可能有这么多方法呢？（函数式接口的定义就是只拥有一个抽象方法的接口）。 所以，实现复合的方法都是默认方法 1. 比较器复合在《Java8：方法引用》博客中讲到使用Comparator.comparing，可以使用如下语句对仓库中的苹果重量进行排序 1inventory.sort(comparing(Apple::getWeight)); 如果需要逆序排序，该怎么办呢？ 1inventory.sort(comparing(Apple::getWeight).reversed()); //接口中有一个默认方法reversed 但如果两个苹果一样重，哪个苹果应该排在前面呢？ 123inventory.sort(comparing(Apple::getWeight) .reversed() .thenComparing(Apple::getCountry); //接口中有默认方法thenComparing，当两个苹果一样重时，按国家排序 2. 谓词复合谓词接口（Predicate）包括三个方法：negate、and和or 1234567891011// 非操作，苹果不是红的Predicate&lt;Apple&gt; notRedApple = redApple.negate(); //产生现有Predicate对象redApple的非// and操作，一个苹果是红色又比较重Predicate&lt;Apple&gt; redAndHeavyApple = redApple.and(a -&gt; a.getWeight() &gt; 150);// 要么是重的红苹果，要么是绿苹果Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen = redApple.and(a -&gt; a.getWeight() &gt; 150) .or(a -&gt; \"green\".equals(a.getColor())); 3. 函数复合可以把Function接口所代表的Lambda表达式复合起来，Function接口为此配了andThen和compose两个默认方法，他们都会返回Function的一个实例。 andThen方法对输入应用一个给定函数，再对输出应用另一个函数 1234Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h = f.andThen(g);int result = h.apply(1); //g(f(x)) = 4 compose方法，先把给定的函数用作compose的参数里面给的那个函数，再把函数本身用于结果 1234Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h = f.compose(g);int result = h.apply(1); //f(g(x)) = 3","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"Lambda表达式","slug":"Lambda表达式","permalink":"http://wangminrui.github.io/tags/Lambda表达式/"},{"name":"函数式接口","slug":"函数式接口","permalink":"http://wangminrui.github.io/tags/函数式接口/"}]},{"title":"Java8：方法引用","slug":"Java8-4","date":"2019-07-17T05:59:46.000Z","updated":"2019-07-30T06:10:01.936Z","comments":true,"path":"2019/07/17/Java8-4/","link":"","permalink":"http://wangminrui.github.io/2019/07/17/Java8-4/","excerpt":"1. 什么是方法引用方法引用可以重复使用现有方法定义，并像Lambda一样传递他们。在一些情况下，比起使用Lambda表达式，会更易读也更自然。 2. 如何构建方法引用方法引用可以被看做仅仅调用特定方法的Lambda的一种快捷写法。它的基本思想是，如果一个Lambda代表的只是“直接调用这个方法”，那最好还是用名称来调用它，而不是去描述如何调用它。 方法引用语法：[目标引用] :: [方法名称] 例如Apple :: getWeight就是应用了Apple类中定义的方法getWeight，其实就是Lambda表达式(Apple a) -&gt; a.getWeight()的快捷写法。","text":"1. 什么是方法引用方法引用可以重复使用现有方法定义，并像Lambda一样传递他们。在一些情况下，比起使用Lambda表达式，会更易读也更自然。 2. 如何构建方法引用方法引用可以被看做仅仅调用特定方法的Lambda的一种快捷写法。它的基本思想是，如果一个Lambda代表的只是“直接调用这个方法”，那最好还是用名称来调用它，而不是去描述如何调用它。 方法引用语法：[目标引用] :: [方法名称] 例如Apple :: getWeight就是应用了Apple类中定义的方法getWeight，其实就是Lambda表达式(Apple a) -&gt; a.getWeight()的快捷写法。 方法引用主要有三类： 指向静态方法的方法引用 例如Integer类的parseInt方法，写作Integer::parseInt (args) -&gt; ClassName.staticMethod(args) =&gt; ClassName::staticMethod 指向任意类型实例方法的方法引用 例如String类的length方法，写作String::length 引用的是一个对象的方法，而这个对象本身是Lambda的一个参数，例如(String s) -&gt; s.toUpperCase()可以写作String::toUpperCase (arg0, rest) -&gt; arg0.instanceMethod(rest) =&gt; ClassName::instanceMethod，arg0是ClassName类型的 指向现有对象的实例方法的方法引用 假设有一个局部变量expensiveTransaction，用于存放Transaction类型的对象，它支持实例方法getValue，那么就可以携程Transaction::getValue 这里的引用指的是在Lambda中调用一个已经存在的外部对象中的方法，例如() -&gt; expensiveTransaction.getValue()可以写作expensiveTransaction::getValue (args) -&gt; expr.instanceMethod(args)=&gt; expr::instanceMethod 针对构造函数、数组构造函数和父类调用的一些特殊形式的方法引用，举个例子：如果想对一个字符串的List排序，并忽略大小写 1234567// compareToIgnoreCase是String类中预先定义的List&lt;String&gt; str = Arrays.asList(\"a\", \"b\", \"A\", \"B\");str.sort((s1, s2) -&gt; s1.compareToIgnoreCase(s2));//使用方法引用可以改写为：List&lt;String&gt; str = Arrays.asList(\"a\", \"b\", \"A\", \"B\");str.sort(String::compareToIgnoreCase); 试试把下面的Lambda表达式转换为等效的方法引用 123456781. Function&lt;String, Integer&gt; stringToInteger = (String s) -&gt; Integer.parseInt(s);2. BiPredicate&lt;List&lt;String&gt;, String&gt; contains = (list, element) -&gt; list.contains(element;) 1. Function&lt;String, Integer&gt; stringToInteger = Integer::parseInt;2. BiPredicate&lt;List&lt;String&gt;, String&gt; contains = List::contains; 3. 构建函数引用对于现有构造函数，可以利用它的名称和关键字new来创建它的引用：ClassName::new。它的功能与指向静态方法的引用类似。 例如，假设有一个构造函数没有参数，它适合Supplier的签名() -&gt; Apple： 12345678910111213141516171819202122232425262728293031323334Supplier&lt;Apple&gt; c1 = Apple::new; //指向Apple()默认构造方法Apple a1 = c1.get();//等价于Supplier&lt;Apple&gt; c1 = () -&gt; new Apple();Apple a1 = c1.get();//如果构造函数的签名是Apple(Integer weight)，那么它就适合Function接口的签名Function&lt;Integer, Apple&gt; c2 = Apple::new;Apple a2 = c2.apply(110);//等价于Function&lt;Integer, Apple&gt; c2 = (weight) -&gt; new Apple(weight);Apple a2 = c2.apply(110);//创建List&lt;Apple&gt;对象List&lt;Integer&gt; weights = Arraysa.asList(7, 3, 4, 10);List&lt;Apple&gt; apples = map(weights, Apple::new);public static List&lt;Apple&gt; map(List&lt;Integer&gt; list, Function&lt;Integer, Apple&gt; f)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Integer e : list)&#123; result.add(f.apply(e)); &#125; return result;&#125;//如果是具有两个参数的构造函数Apple(String color, Integer weight)，那么它适合BiFunction接口的签名BiFunction&lt;String, Intger, Apple&gt; c3 = Apple::new;Apple c3 = c3.apply(\"green\", 110);//等价于BiFunction&lt;String, Intger, Apple&gt; c3 = (color, weight) -&gt; new Apple(color, weight);Apple c3 = c3.apply(\"green\", 110); 这样就可以实现：不将构造函数实例化，却能够引用它 4. Lambda-&gt;方法引用实战对List&lt;Apple&gt;按重量大小排序 1234567891011121314151617181920212223242526// 最原始public class AppleComparator implements Comparator&lt;Apple&gt;&#123; public int compare(Apple a1, Apple a2)&#123; return a1.getWeight().compareTo(a2.getWeight()); &#125;&#125;inventory.sort(new AppleComparator());// 使用匿名类inventory.sort(new Comparator&lt;Apple&gt;()&#123; public int compare(Apple a1, Apple a2)&#123; return a1.getWeight().compareTo(a2.getWeight()); &#125;&#125;);// 使用Lambda表达式inventory.sort((Apple a1, Apple a2) -&gt; return a1.getWeight().compareTo(a2.getWeight()) );// Comparator有一个叫做comparing的静态辅助方法，可以接收一个Function来提取Comparable键值，并生成一个Comparator对象import static java.util.Comparator.comparing;inventory.sort(comparing((a) -&gt; a.getWeight()));// 使用方法引用import static java.util.Comparator.comparing;inventory.sort(comparing(Apple::getWeight)); 最终解决方案看起来比较短，而且意思也很明显，代码读起来和问题描述差不多：对库存进行排序，比较苹果的重量。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"方法引用","slug":"方法引用","permalink":"http://wangminrui.github.io/tags/方法引用/"}]},{"title":"Java编程思想读书笔记第二章：一切都是对象","slug":"Java编程思想读书笔记-二","date":"2019-07-16T07:11:05.000Z","updated":"2019-07-30T06:36:22.586Z","comments":true,"path":"2019/07/16/Java编程思想读书笔记-二/","link":"","permalink":"http://wangminrui.github.io/2019/07/16/Java编程思想读书笔记-二/","excerpt":"待整理 2.1 用引用操作对象JAVA中一切都是对象，但实际上操作的是对象的引用 2.2 必须由你创建所有对象用new操作符实现创建新对象","text":"待整理 2.1 用引用操作对象JAVA中一切都是对象，但实际上操作的是对象的引用 2.2 必须由你创建所有对象用new操作符实现创建新对象 2.2.1 存储到什么地方？ 寄存器： 最快的存储区 在处理器内部 数量有限 堆栈： 在RAM中 堆栈指针向下移动分配新内存，向上移动释放内存 速度仅次于寄存器 必须知道堆栈内所有项的生命周期，以便上下移动指针 存储对象引用，但不存储JAVA对象 堆： 在RAM中 存放所有的Java对象 不需要知道存储的项存活多长时间，new的时候会直接在堆中进行内存分配 但清理回收比较麻烦 常量存储：直接存放在程序代码内部 非RAM存储： 数据完全独立于程序之外，没有运行时也可以存在 例子：流对象和持久化对象 必要时可以恢复为常规的基于RAM的对象 2.2.2 特例：基本类型使用基本类型的原因：new对象存储在堆中，但用new创建一个小的、简单的变量往往不是很有效因此，基本类型创建一个并非是引用的“自动”变量，这个变量直接存储“值”，并置于堆栈中。 基本类型存储空间固定，如下图所示： bool变量占用多大空间？ 答：1字节，当值为false的时候存储的是0x00，值为true的时候存储的是0x01 基本类型对应有包装器类，使得它可以在堆中创建一个非基本对象 12345char c = 'x';Character ch = new Character(c);//或者Character ch = new Character('x'); JAVA中基本数据类型一定存储在栈中吗？ 答：不一定。JAVA中基本数据类型一定存储在栈中吗 JAVA中提供高精度计算的类：BigInteger和BigDecimal 2.2.3 JAVA中的数组JAVA确保数组会初始化，且不能再它的范围之外被访问，但需要每个数组少量的内存开销及运行时的下标检查 创建数组对象时，实际上是创建了一个引用数组，并且每个引用都会被初始化为一个特定值。 2.3 永远不需要销毁对象2.3.1 作用域在C、C++和Java种作用于由花括号的位置决定，在作用域里面定义的变量只可用于作用域结束之前 2.3.2 对象的作用域123&#123; String s = new String(\"a string\");&#125;// End of scope 引用s在作用域终点消失，然而，s指向的String对象仍然占据内存空间。后续会通过垃圾回收器回收。 2.4 创建新的数据类型： 类Java中所做的所有工作，就是定义类，产生这些类的对象，以及发送消息给这些对象 2.4.1 字段和方法","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"},{"name":"《Java编程思想》","slug":"《Java编程思想》","permalink":"http://wangminrui.github.io/tags/《Java编程思想》/"}]},{"title":"Leetcode338:Counting Bits","slug":"Leetcode338","date":"2019-07-16T06:50:28.000Z","updated":"2019-07-29T14:28:02.590Z","comments":true,"path":"2019/07/16/Leetcode338/","link":"","permalink":"http://wangminrui.github.io/2019/07/16/Leetcode338/","excerpt":"Leetcode 338题 Given a non negative integer number num. For every numbers i in the range 0 ≤ i ≤ num calculate the number of 1’s in their binary representation and return them as an array. Example 1: 12Input: 2Output: [0,1,1] Example 2:12Input: 5Output: [0,1,1,2,1,2] Follow up: It is very easy to come up with a solution with run time O(n*sizeof(integer)). But can you do it in linear time O(n) /possibly in a single pass? Space complexity should be O(n). Can you do it like a boss? Do it without using any builtin function like __builtin_popcount in c++ or in any other language. 题目概述： 给定一个指定的数字num，对于x（0 ≤ x ≤ num），计算其二进制表示中1的个数并存入对应数组。","text":"Leetcode 338题 Given a non negative integer number num. For every numbers i in the range 0 ≤ i ≤ num calculate the number of 1’s in their binary representation and return them as an array. Example 1: 12Input: 2Output: [0,1,1] Example 2:12Input: 5Output: [0,1,1,2,1,2] Follow up: It is very easy to come up with a solution with run time O(n*sizeof(integer)). But can you do it in linear time O(n) /possibly in a single pass? Space complexity should be O(n). Can you do it like a boss? Do it without using any builtin function like __builtin_popcount in c++ or in any other language. 题目概述： 给定一个指定的数字num，对于x（0 ≤ x ≤ num），计算其二进制表示中1的个数并存入对应数组。 解题思路： 计算tmp = x &amp; (x-1)，假设输出数组为res[num]有如下两种情况： 如果tmp = 0，那么x必然是100..0，即只有一个1； 如果tmp != 0，有如下四种情况： x的形式为[..]10..00，x-1形式为[..]01..11，[]中1的个数与tmp相同，所以res[x]=res[tmp]+1 x形式为[..]01，x-1形式为[..]00，[]中1的个数与tmp相同，所以res[x]=res[tmp]+1 x形式为[..]10，x-1形式为[..]01，[]中1的个数与tmp相同，所以res[x]=res[tmp]+1 x形式为[..]11，x-1形式为[..]10，[]+后一位中1的个数与tmp相同，所以res[x]=res[tmp]+1 综上所述，res[x] = res[tmp]+1 代码如下： 12345678910public int[] countBits(int num) &#123; int[] res = new int[num+1]; res[0] = 0; for (int i = 1; i &lt;= num; i++) &#123; int temp = i &amp; (i-1); if (temp == 0) res[i] = 1; else res[i] = res[temp]+1; &#125; return res;&#125;","categories":[{"name":"算法编程","slug":"算法编程","permalink":"http://wangminrui.github.io/categories/算法编程/"},{"name":"Leetcode","slug":"算法编程/Leetcode","permalink":"http://wangminrui.github.io/categories/算法编程/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"http://wangminrui.github.io/tags/Leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"http://wangminrui.github.io/tags/动态规划/"}]},{"title":"论文search","slug":"论文search","date":"2019-07-16T05:44:48.000Z","updated":"2019-07-30T06:17:00.352Z","comments":true,"path":"2019/07/16/论文search/","link":"","permalink":"http://wangminrui.github.io/2019/07/16/论文search/","excerpt":"","text":"【非CCF推荐会议】Latent Semantic Indexing and Convolutional Neural Network for Multi-Label and Multi-Class TextClassification作者:Quispe, O (Quispe, Oscar)[ 1 ] ; Ocsa, A (Ocsa, Alexander)[ 1 ] ; Coronado, R (Coronado, Ricardo)[ 1 ] 2017 IEEE LATIN AMERICAN CONFERENCE ON COMPUTATIONAL INTELLIGENCE (LA-CCI) 书籍团体作者:IEEE 出版年: 2017 文献类型:Proceedings Paper 会议名称 会议: IEEE Latin American Conference on Computational Intelligence (LA-CCI) 会议地点: Univ Catolica San Pablo, Arequipa, PERU 会议日期: NOV 08-10, 2017 会议赞助商:IEEE Computat Intelligence Soc; IEEE 摘要 The classification of a real text should not be necessarily treated as a binary or multi-class classification, since the text may belong to one or more labels. This type of problem is called multi-label classification. In this paper, we propose the use of latent semantic indexing to text representation, convolutional neural networks to feature extraction and a single multi layer perceptron for multi-label classification in real text data. The experiments show that the model outperforms state of the art techniques when the dataset has long documents, and we observe that the precision is poor when the size of the texts is small. 关键词 作者关键词:Latent Semantic Indexing; Convolution Neural Network; Multi Label Classification; Text Classification 【非CCF推荐会议】Ranking in Multi Label Classification of Text Documents Using Quantifiers作者:Jindal, R (Jindal, Rajni)[ 1 ] ; Taneja, S (Taneja, Shweta)[ 1 ] Proceedings 5th IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2015) 书籍团体作者:IEEE 页: 162-166 出版年: 2015 文献类型:Proceedings Paper 会议名称 会议: 5th IEEE International Conference on Control System, Computing and Engineering (ICCSCE) 会议地点: Batu Ferringhi, MALAYSIA 会议日期: NOV 27-29, 2015 会议赞助商:IEEE; IEEE Control Syst Soc Chapter Malaysia; IEEE Malaysia Chapter; Univ Teknologi Mara 摘要 In today’s world, many real world examples are based on multi label classification. A single document may belong to a set of class labels simultaneously. The process of ranking i.e. strict ordering of class labels is of great concern here. We have used the concept of quantifiers for ranking of class labels. We have proposed eight new quantifiers, which calculate the degree of membership of class labels of a particular text document. As a result, we are able to perform ranking of class labels in multi label learning. The proposed approach is shown with the help of a case study. 关键词 作者关键词:Text Mining; Multi label text classification; Ranking; Quantifiers 【非CCF推荐会议】A Pipeline for Optimizing F1-Measure in Multi-Label Text Classification作者:Wang, BY (Wang, Bingyu)[ 1 ] ; Li, C (Li, Cheng)[ 1 ] ; Pavlu, V (Pavlu, Virgil)[ 1 ] ; Aslam, J (Aslam, Jay)[ 1 ] 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA) 编者:Wani, MA; Kantardzic, M; Sayedmouchaweh, M; Gama, J; Lughofer, E 页: 913-918 DOI: 10.1109/ICMLA.2018.00148 出版年: 2018 文献类型:Proceedings Paper 会议名称 会议: 17th IEEE International Conference on Machine Learning and Applications (IEEE ICMLA) 会议地点: Orlando, FL 会议日期: DEC 17-20, 2018 会议赞助商:IEEE; Assoc Machine Learning &amp; Applicat 摘要 Multi-label text classification is the machine learning task wherein each document is tagged with multiple labels, and this task is uniquely challenging due to high dimensional features and correlated labels. Such text classifiers need to be regularized to prevent severe over-fitting in the high dimensional space, and they also need to take into account label dependencies in order to make accurate predictions under uncertainty. Many classic multi-label learning algorithms focus on incorporating label dependencies in the model training phase and optimize for the strict set-accuracy measure. We propose a new pipeline which takes such algorithms and improves their F1-performance with careful training regularization and a new prediction strategy based on support inference, calibration and GFM, to the point that classic multi-label models are able to outperform recent sophisticated methods (PDsparse, SPEN) and models (LSF, CFT, CLEMS) designed specifically to be multi-label F-optimal. Beyond performance and practical contributions, we further demonstrate that support inference acts as a strong regularizer on the label prediction structure. 关键词 作者关键词:multi-label; f-measure; text classification 【非CCF推荐会议】Multi-label Classification Systems by the Use of Supervised Clustering作者:Rastin, N (Rastin, Niloofar)[ 1 ] ; Jahromi, MZ (Jahromi, Mansoor Zolghadri)[ 1 ] ; Taheri, M (Taheri, Mohammad)[ 1 ] 查看 Web of Science ResearcherID 和 ORCID;hide_show(‘show_resc_blurb_link’, ‘none’);hide_show(‘hide_resc_blurb_link’, ‘inline’)) 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP) 书籍团体作者:IEEE 页: 246-249 出版年: 2017 文献类型:Proceedings Paper 会议名称 会议: 19th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP) 会议地点: Shiraz, IRAN 会议日期: OCT 25-27, 2017 会议赞助商:Shiraz Univ; CSI 摘要 Multi-label classification problem involves finding a model that maps a set of input features to more than one output labels. It is well known that, exploiting label correlations is important for multi-label learning. In this paper, a supervised clustering-based multi-label classification method is proposed that uses supervised clustering for considering label correlations. The proposed approach enhanced the performance of multi-label classification systems in comparison with the state of the art. Experimental results on a number of image, music and text datasets validate the effectiveness of the proposed approach. 关键词 作者关键词:multi-label classification; label correlations; supervised clustering 【非CCF推荐会议】Multi-Label Classification Using Labelled Association作者:Kase, Y (Kase, Yuichiro)[ 1 ] ; Miura, T (Miura, Takao)[ 1 ] 2015 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM) 书籍团体作者:IEEE 丛书: IEEE Pacific Rim Conference on Communications Computers and Signal Processing 页: 90-95 出版年: 2015 文献类型:Proceedings Paper 会议名称 会议: IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM) 会议地点: Victoria, CANADA 会议日期: AUG 24-26, 2015 会议赞助商:IEEE; Univ Victoria 摘要 In this investigation we discuss a multi-label classification problem where documents may have several labels. We put our focus on dependencies among labels in a probabilistic manner, and we extract characteristic features in a form of probabilistic distribution functions by data mining techniques. We show some experimental results, i.e., dependencies among items/labels to see the effectiveness of the approach. 关键词 作者关键词:Classification; Multi-label Classification; Data Mining 【非CCF推荐会议】Labeled Bilingual Topic Model for Cross-Lingual Text Classification and Label Recommendation作者:Tian, MJ (Tian, Ming-Jie)[ 1 ] ; Huang, ZH (Huang, Zheng-Hao)[ 1 ] ; Cui, RY (Cui, Rong-Yi)[ 1 ] 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE 2018) 编者:Li, S; Dai, Y; Cheng, Y 页: 285-289 DOI: 10.1109/ICISCE.2018.00067 出版年: 2018 文献类型:Proceedings Paper 会议名称 会议: 5th International Conference on Information Science and Control Engineering (ICISCE) 会议地点: Zhengzhou, PEOPLES R CHINA 会议日期: JUL 20-22, 2018 会议赞助商:IEEE Comp Soc; Henan Univ Sci &amp; Technol; Swinburne Univ Technol; Hunan Univ; Wayne State Univ; Minjiang Univ; Beijing Univ Civil Engn &amp; Architecture; Xiamen Univ; China Jiliang Univ; Iwate Prefectural Univ; Hunan Univ Humanities, Sci &amp; Technol 摘要 Aiming at the increasingly rich multi language information resources and multi-label data in news reports and scientific literatures, in order to mining the relevance between languages and the correlation between data, this paper proposed labeled bilingual topic model, applied on cross-lingual textclassification and label recommendation. First of all, it could assume that the keywords in the scientific literature are relevant to the abstract in same article, then extracted the keywords and regarded it as labels, and aligned the labels with topics in topic model, instantiated the “latent” topic. Secondly, trained the abstracts in article through the topic model proposed by this paper. Finally, classified the new documents by cross-lingual text classifier, also recommended the labels. The experiment result show that Micro-F1 measure reaches 94.81% in cross-lingual text classification task, and the recommended labels also reflects the sematic relevance with documents. 关键词 作者关键词:topic model; label; cross-lingual text classification; label recommendation; latent topic 【CCF推荐C类期刊】A multi-label classification based approach for sentiment classification作者:Liu, SM (Liu, Shuhua Monica)[ 1 ] ; Chen, JH (Chen, Jiun-Hung)[ 1 ] EXPERT SYSTEMS WITH APPLICATIONS 卷: 42 期: 3 页: 1083-1093 DOI: 10.1016/j.eswa.2014.08.036 出版年: FEB 15 2015 文献类型:Article 查看期刊影响力 摘要 A multi-label classification based approach for sentiment analysis is proposed in this paper. To the best of our knowledge, this work is the first to propose to use multi-label classification for sentiment classification of microblogs. The proposed prototype has three main components, text segmentation, feature extraction, and multi-label classification. Raw segmented words and sentiment features based on the three different sentiment dictionaries, Dalian University of Technology Sentiment Dictionary, National Taiwan University Sentiment Dictionary and HowNet Dictionary, are the features and the bag of words is the feature representation. A detailed empirical study of different multi-label classification methods on sentiment classification is conducted to compare their classificationperformances. Specifically, total 11 state of the art multi-label classification methods are compared on two microblog datasets and 8 evaluation metrics are used. The effects of the three sentiment dictionaries for multi-label classification are empirically studied and compared, which, to the best of our knowledge, have not been performed. The performed empirical comparisons show that Dalian University of Technology Sentiment Dictionary has the best performance among the three different sentiment dictionaries. (C) 2014 Elsevier Ltd. All rights reserved. 本文提出了一种基于多标签分类的情感分析方法。 据我们所知，这项工作是第一个提出使用多标签分类进行微博情感分类的工作。 提出的原型有三个主要组成部分，文本分割，特征提取和多标签分类。 基于三种不同情感词典，大连理工大学情感词典，国立台湾大学情感词典和知网词典的原始分词和情感特征是词的特征和包，是特征表示。 对情感分类的不同多标签分类方法进行了详细的实证研究，以比较其分类表现。 具体地，在两个微博数据集上比较总共11个现有技术的多标签分类方法，并且使用8个评估度量。 三种情感词典对多标签分类的影响是根据经验研究和比较的，据我们所知，尚未进行过。 所进行的实证比较表明，大连理工大学情感词典在三种不同的情感词典中表现最佳。 （C）2014 Elsevier Ltd.保留所有权利。 关键词 作者关键词:Sentiment analysis; Multi-label classification; Microblogs 【CCF推荐C类期刊】Multi-label classification using hierarchical embedding作者:Kumar, V (Kumar, Vikas)[ 1 ] ; Pujari, AK (Pujari, Arun K.)[ 1,2 ] ; Padmanabhan, V (Padmanabhan, Vineet)[ 1 ] ; Sahu, SK (Sahu, Sandeep Kumar)[ 1 ] ; Kagita, VR (Kagita, Venkateswara Rao)[ 1 ] EXPERT SYSTEMS WITH APPLICATIONS 卷: 91 页: 263-269 DOI: 10.1016/j.eswa.2017.09.020 出版年: JAN 2018 文献类型:Article 查看期刊影响力 摘要 Multi-label learning is concerned with the classification of data with multiple class labels. This is in contrast to the traditional classification problem where every data instance has a single label. Multi-label classification (MLC) is a major research area in the machine learning community and finds application in several domains such as computer vision, data mining and text classification. Due to the exponential size of the output space, exploiting intrinsic information in feature and label spaces has been the major thrust of research in recent years and use of parametrization and embedding have been the prime focus in MLC. Most of the existing methods learn a single linear parametrization using the entire training set and hence, fail to capture nonlinear intrinsic information in feature and label spaces. To overcome this, we propose a piecewise-linear embedding which uses maximum margin matrix factorization to model linear parametrization. We hypothesize that feature vectors which conform to similar embedding are similar in some sense. Combining the above concepts, we propose a novel hierarchical matrix factorization method for multi-label classification. Practical multi-label classification problems such as image annotation, text categorization and sentiment analysis can be directly solved by the proposed method. We compare our method with six well-known algorithms on twelve benchmark datasets. Our experimental analysis manifests the superiority of our proposed method over state-of-art algorithm for multi-label learning. (C) 2017 Elsevier Ltd. All rights reserved. 多标签学习涉及具有多个类标签的数据分类。 这与传统的分类问题形成对比，传统的分类问题是每个数据实例都有一个标签。 多标签分类（MLC）是机器学习社区中的一个主要研究领域，可应用于计算机视觉，数据挖掘和文本分类等多个领域。 由于输出空间的指数大小，利用特征和标签空间中的内在信息已成为近年来研究的主要推动力，参数化和嵌入的使用一直是MLC的主要关注点。 大多数现有方法使用整个训练集学习单个线性参数化，因此无法捕获特征和标签空间中的非线性内在信息。 为了克服这个问题，我们提出了一种分段线性嵌入，它使用最大边缘矩阵分解来模拟线性参数化。 我们假设符合类似嵌入的特征向量在某种意义上是相似的。 结合上述概念，我们提出了一种用于多标签分类的新型分层矩阵分解方法。 通过所提出的方法可以直接解决实际的多标签分类问题，例如图像标注，文本分类和情感分析。 我们将我们的方法与12个基准数据集上的六个众所周知的算法进行比较。 我们的实验分析表明我们提出的方法优于多标签学习的最新算法。 （C）2017 Elsevier Ltd.保留所有权利。 关键词 作者关键词:Multi-label learning; Matrix factorization; Label correlation KeyWords Plus:TEXT CATEGORIZATION; FEATURES; SYSTEM 贡献【CCF推荐C类会议】Text Classification: The Case of Multiple Labels作者:Bobicev, V (Bobicev, Victoria)[ 1 ] 2016 INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM 2016) 书籍团体作者:IEEE 丛书: International Conference on Communications (ICC) 页: 39-42 出版年: 2016 文献类型:Proceedings Paper 会议名称 会议: IEEE 11th International Conference on Communications (COMM) 会议地点: Bucharest, ROMANIA 会议日期: JUN 09-11, 2016 会议赞助商:Mil Tech Acad; Politehnica Univ Bucharest; IEEE 摘要 Analysis of subjectivity is the actively developed direction of research in text mining. The paper presents machine learning experiments on classification of sentiments in forum texts. We explore the difficult task of classification when texts are labeled by several sentiment labels and in this condition we reach the average F-measure equal to 0.805. 关键词 作者关键词:machine learning; natural language processing; text classification; sentiment analysis; multi-label classification","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wangminrui.github.io/categories/备忘录/"}],"tags":[]},{"title":"beam学习(二):WordCount","slug":"beam学习-二","date":"2019-07-16T01:39:26.000Z","updated":"2019-07-30T06:22:35.693Z","comments":true,"path":"2019/07/16/beam学习-二/","link":"","permalink":"http://wangminrui.github.io/2019/07/16/beam学习-二/","excerpt":"来自beam官方文档learning resources 1. 概述四种WordCount的demo MinimalWordCount演示了构建管道所涉及的基本原则。 WordCount介绍了创建可重用和可维护管道的一些常见最佳实践。 DebuggingWordCount引入了日志记录和调试实践。 WindowedWordCount演示了如何使用Beam的编程模型来处理有界和无界数据集。 2. MinimalWordCountMinimalWordCount演示了一个最简单的pipeline，硬编码输入输出文件位置，没有任何错误检查和参数设置。 Key Concepts： Creating the Pipeline Applying transforms to the Pipeline Reading input (in this example: reading text files) Applying ParDo transforms Applying SDK-provided transforms (in this example: Count) Writing output (in this example: writing to a text file) Running the Pipeline","text":"来自beam官方文档learning resources 1. 概述四种WordCount的demo MinimalWordCount演示了构建管道所涉及的基本原则。 WordCount介绍了创建可重用和可维护管道的一些常见最佳实践。 DebuggingWordCount引入了日志记录和调试实践。 WindowedWordCount演示了如何使用Beam的编程模型来处理有界和无界数据集。 2. MinimalWordCountMinimalWordCount演示了一个最简单的pipeline，硬编码输入输出文件位置，没有任何错误检查和参数设置。 Key Concepts： Creating the Pipeline Applying transforms to the Pipeline Reading input (in this example: reading text files) Applying ParDo transforms Applying SDK-provided transforms (in this example: Count) Writing output (in this example: writing to a text file) Running the Pipeline 2.1 Creating the Pipeline 创建管道第一步从PipelineOptionsFactory创建一个PipelineOptions对象，用于设置pipeline的各种参数。（此例中以编程方式设置option，但更常见的是用命令行设置PipelineOptions） 12345// Create a PipelineOptions object. This object lets us set various execution// options for our pipeline, such as the runner you wish to use. This example// will run with the DirectRunner by default, based on the class path configured// in its dependencies.PipelineOptions options = PipelineOptionsFactory.create(); 第二步用上一步中的options创建一个Pipeline对象 1Pipeline p = Pipeline.create(options); 2.2 Applying pipline transforms 应用管道转换MinimalWordCount pipeline中包含多种transforms，用于将数据读入管道、操作或者以其他方式转换数据并写出结果。 transforms可以是单个操作，也可以包含多个嵌套变换（复合变换）。每个转换都获取某个输入数据并生成一些输出数据。输入数据和输出数据通常由SDK类PCollection表示。PCollection是一个由Beam SDK提供的特殊类，可用于表示几乎任何大小的数据集，包括无界数据集。 1PCollection怎么表示任何大小的数据集？ MinimalWordCount包含五种transforms： TextIO.Read Transform： 输入：输入数据 输出：PCollection输出，每一个元素代表input file中文本的一行 1p.apply(TextIO.read().from(\"gs://apache-beam-samples/shakespeare/*\")) ParDo Transform: 调用ParDo中的DoFn， Line to words 输入：上一个transform的输出PCollection 输出：另一种PCollection输出，每一个元素代表文本中的单个单词 123.apply(\"ExtractWords\", FlatMapElements .into(TypeDescriptors.strings()) .via((String word) -&gt; Arrays.asList(word.split(\"[^\\\\p&#123;L&#125;]+\")))) Count Transform: SDK提供的Count transform是一种通用transform，可以使用任何类型的PCollection，返回键值对的PCollection 输入：上一个transform的输出PCollection 输出：key/value对形式的PCollection，key表示文本中的唯一单词，value表示的是对应的计数 1.apply(Count.&lt;String&gt;perElement()) ParDo Transform: Map transform封装了一个简单的ParDo，是一个更高级别的复合变换 输入：上一个transform的输出PCollection 输出：格式化为合适写入输出文件的可打印字符串 123.apply(\"FormatResults\", MapElements .into(TypeDescriptors.strings()) .via((KV&lt;String, Long&gt; wordCount) -&gt; wordCount.getKey() + \": \" + wordCount.getValue())) TextIO.Write Transform: 输入：上一个transform的输出PCollection(Formatted Count) 输出：输入的PCollection的每个元素转化为输出文件中的一行文本 1.apply(TextIO.write().to(\"wordcounts\")); 12不懂：Note that the Write transform produces a trivial result value of type PDone, which in this case is ignored. 2.3 Running the pipeline 运行管道调用run方法会使用PipelineOptions中指定的runner运行 1p.run().waitUntilFinish(); 请注意，run方法是异步的。 对于阻塞执行，请对运行调用返回的结果对象调用waitUntilFinish方法。 3. WordCount此例更加复杂，管道更加易于读取，编写和维护。 使用DirectRunner： 12$ mvn compile exec:java -D exec.mainClass=org.apache.beam.examples.WordCount ` -D exec.args=\"--inputFile=pom.xml --output=counts\" -P direct-runner New Concepts: Applying ParDo with an explicit DoFn Creating Composite Transforms Using Parameterizable PipelineOptions 3.1 Specifying explicit DoFns 指定显示DoFns使用ParDo转换时，需要指定应用于输入PCollection中每个元素的处理操作。 此处理操作是SDK类DoFn的子类。 您可以为每个ParDo内联创建DoFn子类，作为匿名内部类实例，如前一个示例（MinimalWordCount）中所做的那样。 但是，在全局级别定义DoFn通常是个好主意，这使得单元测试更容易，并且可以使ParDo代码更具可读性。 12345678910// In this example, ExtractWordsFn is a DoFn that is defined as a static class:static class ExtractWordsFn extends DoFn&lt;String, String&gt; &#123; ... @ProcessElement public void processElement(ProcessContext c) &#123; ... &#125;&#125; 3.2 Creating composite transforms 创建复合变换如果您的处理操作包含多个转换或ParDo步骤，则可以将其创建为PTransform的子类。 创建PTransform子类允许您封装复杂的变换，可以使您的管道结构更加清晰和模块化，并使单元测试更容易。 在此示例中，两个转换被封装为PTransform子类CountWords。 CountWords包含运行ExtractWordsFn的ParDo和SDK提供的Count变换。 当定义CountWords时，我们指定其最终输入和输出; 输入是用于提取操作的PCollection ，输出是由计数操作产生的PCollection","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"大数据","slug":"学习笔记/大数据","permalink":"http://wangminrui.github.io/categories/学习笔记/大数据/"}],"tags":[{"name":"beam","slug":"beam","permalink":"http://wangminrui.github.io/tags/beam/"}]},{"title":"Beam学习：概述","slug":"beam学习-一","date":"2019-07-15T01:30:01.000Z","updated":"2019-07-30T03:21:33.959Z","comments":true,"path":"2019/07/15/beam学习-一/","link":"","permalink":"http://wangminrui.github.io/2019/07/15/beam学习-一/","excerpt":"","text":"待整理 Apache Beam指南 Beam学习笔记 Apache Beam开发指南 Beam documentation Beam Java API","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"大数据","slug":"学习笔记/大数据","permalink":"http://wangminrui.github.io/categories/学习笔记/大数据/"}],"tags":[{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"},{"name":"Beam","slug":"Beam","permalink":"http://wangminrui.github.io/tags/Beam/"}]},{"title":"Java8：Lambda表达式","slug":"Java8-3","date":"2019-07-14T07:44:43.000Z","updated":"2019-07-30T06:09:30.419Z","comments":true,"path":"2019/07/14/Java8-3/","link":"","permalink":"http://wangminrui.github.io/2019/07/14/Java8-3/","excerpt":"1. Why Lambda表达式用匿名类实现行为参数化的代码十分啰嗦 2. What Lambda表达式 Lambda表达式是可传递的匿名函数的一种方式：它没有名称，但有参数列表、函数主体、返回类型 函数：是一种函数，有参数列表、函数主体和返回类型，但不像普通方法一样输出某个特定类 匿名：不像普通方法一样有明确的名称 传递：Lambda表达式可以作为参数传递给方法或存储在变量中 简介：无需像匿名类那样写很多模板代码","text":"1. Why Lambda表达式用匿名类实现行为参数化的代码十分啰嗦 2. What Lambda表达式 Lambda表达式是可传递的匿名函数的一种方式：它没有名称，但有参数列表、函数主体、返回类型 函数：是一种函数，有参数列表、函数主体和返回类型，但不像普通方法一样输出某个特定类 匿名：不像普通方法一样有明确的名称 传递：Lambda表达式可以作为参数传递给方法或存储在变量中 简介：无需像匿名类那样写很多模板代码 eg: 12345678910//使用匿名类Comparator&lt;Apple&gt; byWeight = new Comparator&lt;Apple&gt;()&#123; public int compare(Apple a1, Apple a2)&#123; return a1.getWeight().compareTo(a2.getWeight()); &#125;&#125;//使用Lambda表达式会变简洁许多！Comparator&lt;Apple&gt; byWeight = (Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); Lambda表达式由以下三部分组成： 参数列表：和普通的函数参数列表一样（因为存在类型推断，所以可以有时可以省略类型） 箭头：将参数列表和Lambda主体分开 Lambda主体：函数的内容，表达式就是Lambda的返回值 3. How Lambda表达式3.1 Lambda语法Lambda的基本语法是： (parameters) -&gt; expression 或 (parameters) -&gt; { statements;} 几个例子： 12345678(String s) -&gt; s.length() //String -&gt; int(Apple a) -&gt; a.getWeight() &gt; 150 //Apple -&gt; boolean(int x, int y) -&gt; &#123; //(int, int) -&gt; void，注意Lambda表达式可以是多行 System.out.println(\"Result:\"); System.out.println(x + y);&#125;() -&gt; 42 //() -&gt; int(Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()) //(Apple, Apple) -&gt; int 判断以下哪个不是有效的Lambda表达式 123451. () -&gt; &#123;&#125;2. () -&gt; \"Raoul\"3. () -&gt; &#123;return \"Mario\";&#125;4. (Integer i) -&gt; return \"Alan\" + i;5. (String s) -&gt; &#123;\"IronMan\";&#125; 没有参数，返回void，类似于public void run() {}，所以有效 没有参数，返回String作为表达式，有效 没有参数，显示返回String作为表达式，有效 return是一个控制流语句，需要使用花括号，无效 “Iron Man”是一个表达式，不需要分号和花括号，无效 3.2 函数式接口Lambda可以在函数式接口上使用 3.2.1 什么是函数式接口 函数式接口是只定义一个抽象方法的接口，但可以有默认方法。如果抽象方法覆盖了java.lang.Object的public方法，那么这个抽象方法不计数 eg： 1234567public interface Comparator&lt;T&gt;&#123; int compare(T o1, T o2);&#125;public interface Runnable&#123; void run();&#125; 3.2.2 函数描述符 Lambda表达式允许直接以内联的形式为函数式接口的抽象方法提供实现。Lambda表达式用作函数式接口的实例时，其签名（这里的签名应该指参数列表和返回值，但是签名应该是不包含返回值的）必须和接口的抽象方法一致。这种抽象方法就叫做函数描述符 以下哪些是使用Lambda表达式的有效方式 123456789101112131.execute(() -&gt; &#123;&#125;);public void execute(Runnable r)&#123; r.run();s&#125;2.public Callable&lt;String&gt; fetch()&#123; return () -&gt; \"Tricky example ;-)\";&#125;3.Predicate&lt;Apple&gt; p = &lt;Apple a&gt; -&gt; a.getWeight(); Lambda的签名() -&gt; void与Runnable中抽象方法run()的签名相匹配，有效 Lambda的签名() -&gt; String与Callable中抽象方法fetch()的签名相匹配，有效 Lambda的签名(Apple) -&gt; Integer与抽象方法test()的签名(Apple) -&gt; boolean不匹配，无效 3.3.3 几种常见的函数式接口1. Predicate Predicate接口中有一个test()抽象方法，接收泛型T对象，并返回一个boolean 1234567891011121314@FunctionInterfacepublic interface Predicate&lt;T&gt;&#123; boolean test(T t);&#125;public static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p)&#123; List&lt;T&gt; results = new ArrayList&lt;&gt;(); for (T s : list)&#123; if (p.test(s))&#123; result.add(s); &#125; &#125; return results;&#125; 2. Consumer Consumer接口中有一个accept()抽象方法，接收泛型T对象，没有返回 1234567891011121314@FunctionInterfacepublic interface Consumer&lt;T&gt;&#123; void accept(T t);&#125;public static &lt;T&gt; void forEach(List&lt;T&gt; list, Consumer&lt;T&gt; c)&#123; for (T i : list)&#123; c.accept(i)'' &#125;&#125;forEach( Arrays.asList(1, 2, 3, 4, 5), (Integer i) -&gt; System.out.println(i)); 3. Function Function接口中有一个apply()抽象方法，接收泛型T对象，返回一个泛型R的对象 12345678910111213141516@FunctionalInterfacepublic interface Funciton&lt;T, R&gt;&#123; R apply(T t);&#125;public static &lt;T, R&gt; List&lt;R&gt; map(List&lt;T&gt; list, Function&lt;T, R&gt; f)&#123; List&lt;R&gt; result = new ArrayList&lt;&gt;(); for (T s : list)&#123; result.add(f.apply(s)); &#125; return result;&#125;List&lt;Integer&gt; l = map( Arrays.asList(\"Lambda\", \"in\", \"action\")), (String s) -&gt; s.lenght() ); Java8中可以利用函数式接口避免自动装箱 123456789public interface IntPredicate&#123; boolean test(int t);&#125;IntPredicate evenNumbers = (int i) -&gt; i % 2 == 0; //无装箱evenNumbers.test(1000);IntPredicate evenNumbers = (Integer i) -&gt; i % 2 == 1; //装箱oddNumbers.test(1000); Java8中常用函数式接口 函数式接口 函数描述符 原始类型特化 Predicate&lt;T&gt; T-&gt;boolean IntPredicate, LongPredicate, DoublePredicate Consumer&lt;T&gt; T-&gt;void IntConsumer, LongConsumer, DoubleConsumer Function&lt;T, R&gt; T-&gt;R IntFunction, IntToDoubleFunction, IntToLongFunction, LongFunction, LongToDoubleFunction, LongToIntFunction, DoubleFunction, ToIntFunction, ToDoubleFunction, ToLongFunction Supplier&lt;T&gt; ()-&gt;T BooleanSupplier, IntSupplier, LongSupplier, DoubleSupplier UnaryOperator&lt;T&gt; T-&gt;T IntUnaryOperator, LongUnaryOperator, DoubleUnaryOperator BiPredicate&lt;T&gt; (T, T)-&gt;T IntBinaryOperator, LongBinaryOperator, DoubleBinaryOperator BiPredicate&lt;L,R&gt; (L,R)-&gt;boolean BiConsumer&lt;T, U&gt; (T, U)-&gt;void ObjIntConsumer, ObjLongConsumer, ObjDoubleConsumer BiConsumer&lt;T, U, R&gt; (T, U)-&gt;R ToIntBiFunction, oLongBiFunction, ToDoubleBiFunction 3.3 Lambda实战：环绕执行模式环绕执行模式：资源处理（例如处理文件或数据库）时一个常见的模式就是打开一个资源，做一些处理，然后关闭资源。这个设置和清理阶段总是很类似，并且会围绕着执行处理的哪些重要代码，这就是环绕执行模式。 一个例子—读取文件： 1. 从data.txt文件中读取一行 1234567//代码3.3.1public static String processFile(BufferedReaderProcessor p) throws IOException&#123; try (BufferedReader br = new BufferedReader(new FileReader(\"data.txt\")))&#123; return br.readline(); //做主要工作的代码 &#125; &#125; 2. 行为参数化 上一段代码局限在于只能读取文件的第一行，如果想返回两行，或其他信息就不行了，此时要用到行为参数化。相当于要processFile方法能够对文件执行不同操作，即传递不同行为给processFile。最终processFile希望实现成以下代码，接受BufferedReader的文件并返回String，Lambda的签名为(BufferedReader -&gt; String) 123//代码3.3.2String result = processFile((BufferedReader br) -&gt; br.readLine() + br.readLine()); 3. 使用函数式接口来传递一个行为 此时，我们需要定义一个和Lambda表达式签名一致的函数式接口 12345//代码3.3.3@FunctionalInterfacepublic interface BufferedReaderProcessor&#123; String process(BufferedReader b) throws IOException;&#125; 4. 传递行为 重写代码3.3.1中的processFile方法 1234567//代码3.3.4public static String processFile(BufferedReaderProcessor p) throws IOException&#123; try (BufferedReader br = new BufferedReader(new FileReader(\"data.txt\")))&#123; return p.process(br); //处理BufferReader对象 &#125; &#125; 5. 总结 12345678910111213141516171819202122232425import java.io.BufferedReader;import java.io.FileReader;import java.io.IOException;@FunctionalInterfaceinterface BufferedReaderProcessor&#123; String process(BufferedReader b) throws IOException;&#125;public class LambdaDemo &#123; static String processFile(BufferedReaderProcessor p) throws IOException&#123; try (BufferedReader br = new BufferedReader(new FileReader(\"data.txt\")))&#123; return p.process(br); &#125; &#125; public static void main(String[] args) throws IOException &#123; String oneLine = processFile((BufferedReader br) -&gt; br.readLine()); String twoLines = processFile((BufferedReader br) -&gt; br.readLine() + br.readLine()); System.out.println(oneLine); System.out.println(\"\\n\" + twoLines); &#125;&#125; 任何函数式接口都不允许抛出受检异常，如果需要Lambda表达式抛出异常，有两种办法，一个是定义自己的函数接口，并声明受检异常；另一个是把Lambda主体包含在一个try/catch块中 4. Lambda类型检查、类型推断以及限制4.1 类型检查Lambda的类型检查是从Lambda的上下文推断出来的 同样的Lambda，只要有相同的签名，可以应用于不同的函数式接口 特殊的void兼容规则 如果Lambda的主体是一个语句表达式，它就和返回void的函数描述符兼容（前提是参数列表兼容），如下： 1234// Predicate返回了一个booleanPredicate&lt;String&gt; p = s -&gt; list.add(s);// Consumer返回了一个voidConsumer&lt;String&gt; b = s -&gt; list.add(s); 4.2 类型推断Java编译器可以推断出合适Lambda的签名，因为函数描述符可以通过目标类型得到，这样可以在Lambda语法中省去表述参数类型。 1234Comparator&lt;Apple&gt; c = (Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); //没有类型推断Comparator&lt;Apple&gt; c = (a1, a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); //有类型推断 但标注参数类型会使代码更易读。 4.3 使用局部变量的限制Lambda表达式不仅可以用传入参数，还允许使用自由变量（在外层作用域中定义的变量），这称为捕获Lambda。 12int portNumber = 1337;Runnable r = () -&gt; System.out.println(portNumber); Lambda表达式可以无限制地捕获实例变量和静态变量，但局部变量不许显式声明为final，或事实上是final，Lambda表达式只能捕获指派给它们的局部变量一次 1234// 此代码无法编译，因为portNumber被赋值两次，不是最终的int portNumber = 1337;Runnable r = () -&gt; System.out.println(portNumber);portNumber = 31337; 为什么Lambda中的局部变量要做final限制？ 线程不安全：因为实例变量和局部变量实现的关键不同，实例变量都存储在堆中，而局部变量存储在栈中，如果Lambda在一个线程中访问局部变量，栈上的内容在当前线程执行完成后就被回收，如果再去访问这个变量可能会出错。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"Lambda表达式","slug":"Lambda表达式","permalink":"http://wangminrui.github.io/tags/Lambda表达式/"},{"name":"函数式接口","slug":"函数式接口","permalink":"http://wangminrui.github.io/tags/函数式接口/"}]},{"title":"关于函数式接口Comparator的疑惑","slug":"关于函数式接口Comparator的疑惑","date":"2019-07-13T01:24:03.000Z","updated":"2019-07-30T06:00:41.169Z","comments":true,"path":"2019/07/13/关于函数式接口Comparator的疑惑/","link":"","permalink":"http://wangminrui.github.io/2019/07/13/关于函数式接口Comparator的疑惑/","excerpt":"问：函数式接口只能有一个抽象方法，但Comparator源码中却有两个抽象方法：compare和equals（确定它是函数式接口，因为用@FunctionInterface声明了 答： public @interface FunctionalInterface 官方文档这样说：If an interface declares an abstract method overriding one of the public methods of java.lang.Object, that also does not count toward the interface’s abstract method count since any implementation of the interface will have an implementation from java.lang.Object or elsewhere.如果接口声明了一个抽象方法覆盖的公共方法之一java.lang.Object ，也不会向接口的抽象方法计数统计以来的接口的任何实施都会有一个实现从java.lang.Object或其他地方。如果接口声明了一个覆盖java.lang.Object的全局方法之一的抽象方法，那么它不会计入接口的抽象方法数量中，因为接口的任何实现都将具有java.lang.Object或其他地方的实现。","text":"问：函数式接口只能有一个抽象方法，但Comparator源码中却有两个抽象方法：compare和equals（确定它是函数式接口，因为用@FunctionInterface声明了 答： public @interface FunctionalInterface 官方文档这样说：If an interface declares an abstract method overriding one of the public methods of java.lang.Object, that also does not count toward the interface’s abstract method count since any implementation of the interface will have an implementation from java.lang.Object or elsewhere.如果接口声明了一个抽象方法覆盖的公共方法之一java.lang.Object ，也不会向接口的抽象方法计数统计以来的接口的任何实施都会有一个实现从java.lang.Object或其他地方。如果接口声明了一个覆盖java.lang.Object的全局方法之一的抽象方法，那么它不会计入接口的抽象方法数量中，因为接口的任何实现都将具有java.lang.Object或其他地方的实现。 也就是说：函数式接口中可以额外定义多个抽象方法，但这些抽象方法签名（函数名称和参数列表）必须和Object的public方法一样。接口最终有确定的类实现， 而类的最终父类是Object。 因此函数式接口可以定义Object的public方法。如以下的接口依然是函数式接口： 1234567@FunctionalInterfacepublicinterface ObjectMethodFunctionalInterface &#123; void count(int i); String toString(); //same to Object.toString int hashCode(); //same to Object.hashCode boolean equals(Object obj); //same to Object.equals&#125; 为什么限定public类型的方法呢？因为接口中定义的方法都是public类型的。 举个例子，下面的接口就不是函数式接口：1234interface WrongObjectMethodFunctionalInterface &#123; void count(int i); Object clone(); //Object.clone is protected&#125; 因为Object.clone方法是protected类型。在百度贴吧看到的，——id=“画_夜”","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"函数式接口","slug":"函数式接口","permalink":"http://wangminrui.github.io/tags/函数式接口/"},{"name":"疑惑辣么多","slug":"疑惑辣么多","permalink":"http://wangminrui.github.io/tags/疑惑辣么多/"}]},{"title":"Java8：行为参数化","slug":"Java8-2","date":"2019-07-12T06:08:32.000Z","updated":"2019-07-30T05:59:18.356Z","comments":true,"path":"2019/07/12/Java8-2/","link":"","permalink":"http://wangminrui.github.io/2019/07/12/Java8-2/","excerpt":"1. Why 行为参数化原因：需求频繁变更 软件开发的理想状态是，把开发人员的工作量降到最低。此外，类似的新功能实现起来应该很简单，而且易于长期维护。 2. What 行为参数化将代码块（行为）作为参数传递 是一种可以处理频繁变更需求的软件开发模式","text":"1. Why 行为参数化原因：需求频繁变更 软件开发的理想状态是，把开发人员的工作量降到最低。此外，类似的新功能实现起来应该很简单，而且易于长期维护。 2. What 行为参数化将代码块（行为）作为参数传递 是一种可以处理频繁变更需求的软件开发模式 3. How 行为参数化3.1 一个例子 假设有一个Apple类，它有一个getColor方法和一个getWeight方法 变量inventory保存一个Apples的列表 1. 选出一个绿苹果 12345678910// 代码3.1.1public static List&lt;Apple&gt; filterGreenApples(List&lt;Apple&gt; inventory)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple : inventory)&#123; if (\"green\".equals(apple.getColor()))&#123; result.add(apple); &#125; &#125; return result;&#125; 2. 选择其他颜色的苹果，如红色、黄色等 给方法加一个参数color来应对变化 1234567891011121314// 代码3.1.2public static List&lt;Apple&gt; filterGreenApples(List&lt;Apple&gt; inventory, String color)&#123; //加一个color参数 List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple : inventory)&#123; if (apple.getcolor().equals(color))&#123; result.add(apple); &#125; &#125; return result;&#125;//调用方法List&lt;Apple&gt; greenApples = filterApplesByColor(inventory, \"green\");List&lt;Apple&gt; redApples = filterApplesByColor(inventory, \"red\"); 3. 选出重的苹果，比如超过150g 给方法加一个参数weight来应对变化 12345678910// 代码3.1.3public static List&lt;Apple&gt; filterHeavyApples(List&lt;Apple&gt; inventory, int weight)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple : inventory)&#123; if (apple.getWeight() &gt; weight)&#123; result.add(apple); &#125; &#125; return result;&#125; 虽然方案得到了解决，但是复制了大量代码，并对每个苹果应用筛选条件，这打破了DRY(Don’t Repeat Yourself)的软件工程原则，如果想改变筛选方式就得修改所有方法的实现，代价太大了。 4. 对想到的每个属性做筛选 12345678910111213// 代码3.1.4public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; inventory, String color, int weight, boolean flag)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple : inventory)&#123; if (flag &amp;&amp; (apple.getColor().equals(color) || apple.getWeight() &gt; weight))&#123; result.add(apple); &#125; &#125; return result;&#125;//调用方法List&lt;Apple&gt; heavyApples = filterApples(inventory, \"\", 150, false); 这是一种很差的解决方案，首先，客户端代码非常糟糕，而且不能很好地应对需求变化 5. 行为参数化 对选择标准建模：考虑苹果的各种属性，最后返回一个boolean值（可以称之为谓词：即一个返回boolean值的函数） 1234567891011121314151617181920212223242526272829303132333435363738//代码3.1.5public interface ApplePredicate&#123; //谓词的接口 boolean test (Apple apple);s&#125;//仅仅选出重的苹果public class AppleHeavyWeightPredicate implements ApplePredicate&#123; public boolean test(Apple apple)&#123; return apple.getWeight() &gt; 150; &#125;&#125;//仅仅选出绿苹果public class AppleGreenColorPredicate implements ApplePredicate&#123; public boolean test(Apple apple)&#123; return \"green\".equals(apple.getColor()); &#125;&#125;//选出又红又重的苹果public class AppleRedAndHeavyPredicate implements ApplePredicate&#123; public boolean test(Apple apple)&#123; return \"red\".equals(apple.getColor()) &amp;&amp; apple.getWeight() &gt; 150; &#125;&#125;public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; inventory, ApplePredicate p)&#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple : apple)&#123; if (p.test(apple))&#123; result.add(apple); &#125; &#125; return result;&#125;//调用方法List&lt;Apple&gt; redHeavyApples = filterApples(inventory, new AppleRedAndHeavyPredicate()); 选出重的苹果和选出绿苹果都可以看作是封装的策略（和策略设计模式类似） filterApples方法的行为取决于通过ApplePredicate对象传递的代码，换句话说，把filterApples方法的行为参数化了 如果使用Lambda表达式可以不用定义多个ApplePredicate 行为参数化的好处在于你可以把迭代要筛选的集合的逻辑与对集合重每个元素应用的行为区分开来。这样你可以重复使用同一方法，给它不同的行为来达到不同的目的。 3.2 对付啰嗦3.1中的例子，为了把新的行为传递给filterApples方法时，不得不声明好几个实现ApplePredicate接口的类，然后实例化好几个只会提到一次的ApplePredicate对象，这个过程是很繁琐、啰嗦的。 3.2.1 使用匿名类对付啰嗦12345List&lt;Apple&gt; redApples = filterApples(inventory, new ApplePredicate()&#123; public boolean test(Apple apple)&#123; return \"red\".equals(apple.getColor()); &#125;&#125;) 但匿名类并不够好： 匿名类往往很笨重，因为占用了很多空间 匿名类看上去有些费解，如下展示了一个经典Java谜题 12345678910111213141516171819public class MeaningOfThis&#123; public final int value = 4; public void doIt()&#123; int value = 6; Runnable r = new Runnable()&#123; public final int value = 5; public void run()&#123; int value = 10; System.out.println(this.value); &#125; &#125;; r.run(); &#125; public static void main(String... args)&#123; MeaningOfThis m = new MeaningOfThis(); m.doIt(); //本行输出什么？？ &#125;&#125; 答案是5，因为this指包含它的Runnable，而不是外面的类MeaningOfThis 为了程序员使用行为参数化模式，Java8中引入Lambda表达式使代码变得更干净。 3.2.2 使用Lambda表达式对付啰嗦1List&lt;Apple&gt; result = filterApples(inventory, (Apple apple) -&gt; 'red'.equals(apple.getColor())); Lambda表达式的语法后面再说 3.3 将类型抽象化filterApples方法目前还只适用于Apple，将List抽象化，可以超越眼前要处理的问题： 12345678910111213public interface Predicate&lt;T&gt;&#123; boolean test(T t);&#125;public static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p)&#123; List&lt;T&gt; result = new ArrayList&lt;&gt;(); for (T e : list)&#123; if (p.test(e))&#123; result.add(e); &#125; &#125; return result;&#125; 4. 小结 行为参数化，就是一个方法接受多个不同的行为作为参数，并在内部使用它们，完成不同行为的能力； 行为参数化可以让代码更好地适应不断变化的要求，减轻未来的工作量； 传递代码，就是将新行为作为参数传递给方法。但在Java8之前这实现起来很啰嗦，为减少啰嗦Java8之前可以用匿名类，Java8之后可以使用Lambda表达式； Java API中包含很多用不同行为及逆行参数化的方法，包括排序、线程和GUI处理。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"},{"name":"行为参数化","slug":"行为参数化","permalink":"http://wangminrui.github.io/tags/行为参数化/"}]},{"title":"PO、VO、BO、DTO、POJO、DAO、DO之间的关系","slug":"PO-VO-BO-DTO-POJO-DAO-DO之间的关系","date":"2019-07-12T02:26:03.000Z","updated":"2019-07-30T05:55:49.995Z","comments":true,"path":"2019/07/12/PO-VO-BO-DTO-POJO-DAO-DO之间的关系/","link":"","permalink":"http://wangminrui.github.io/2019/07/12/PO-VO-BO-DTO-POJO-DAO-DO之间的关系/","excerpt":"部分转自PO、VO、BO、DTO、POJO、DAO、DO之间的关系 DOdomain object 持久对象 从现实世界中抽象出来的有形或无形的业务实体。 POpersistant object 持久对象 一个PO就是数据库中的一条记录。好处是可以把一条记录作为一个对象处理，可以方便的转为其它对象。","text":"部分转自PO、VO、BO、DTO、POJO、DAO、DO之间的关系 DOdomain object 持久对象 从现实世界中抽象出来的有形或无形的业务实体。 POpersistant object 持久对象 一个PO就是数据库中的一条记录。好处是可以把一条记录作为一个对象处理，可以方便的转为其它对象。 BObusiness object 业务对象 把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象，比如一个简历，有教育经历、工作经历、社会关系等等。我们可以把教育经历对应一个PO，工作经历对应一个PO，社会关系对应一个PO。建立一个对应简历的BO对象处理简历，每个BO包含这些PO。 VOvalue object 值对象view object 表现层对象 对应界面显示的数据对象。对于一个WEB页面，或者SWT、SWING的一个界面，用一个VO对象对应整个界面的值。 DTOdata transfer object 数据传输对象 用于远程调用等需要大量传输对象的地方。比如我们一张表有100个字段，那么对应的PO就有100个属性。但是我们界面上只要显示10个字段，客户端用WEB service来获取数据，没有必要把整个PO对象传递到客户端， 这时我们就可以用只有这10个属性的DTO来传递结果到客户端，这样也不会暴露服务端表结构.到达客户端以后，如果用这个对象来对应界面显示，那此时它的身份就转为VO POJOplain ordinary java object 简单ava对象个人感觉POJO是最参见最多变的对象，是一个中间对象，也是我们最常打交道的对象。一个POJO持久化以后就是PO直接用它传递、传递过程中就是DTO直接用来对应表示层就是VO DAOdata access object数据访问对象这个大家最熟悉，和上面几个O区别最大，基本没有互相转化的可能性和必要. 主要用来封装对数据库的访问。通过它可以把POJO持久化为PO，用PO组装出来VO、DTO","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"}]},{"title":"Java8：概述","slug":"Java8-1","date":"2019-07-11T02:26:28.000Z","updated":"2019-07-30T05:56:29.480Z","comments":true,"path":"2019/07/11/Java8-1/","link":"","permalink":"http://wangminrui.github.io/2019/07/11/Java8-1/","excerpt":"1. Why Java8 使用Collections处理数据时代码复杂、晦涩，需要更简洁、易于维护的代码 适应并行编程（Java8之前，必须利用线程才能使用多个内核，不能很好地利用多核处理器） 主要是第二点","text":"1. Why Java8 使用Collections处理数据时代码复杂、晦涩，需要更简洁、易于维护的代码 适应并行编程（Java8之前，必须利用线程才能使用多个内核，不能很好地利用多核处理器） 主要是第二点 2. Java8的重要变革 引入新的API—Stream，支持处理数据的并行操作，其思想与SQL语言类似 这样可以避免使用synchronized编写代码，synchronized不仅容易出错，而且在多核CPU上执行成本高昂 基于流处理思想，流是一系列数据项，一次只生成一项。一个程序的输出流可能是另一个程序的输入流 Java8可以把不相关的部分放到几个CPU内核上分别执行Stream操作流水线，实现”免费的并行“，用不着费劲搞Thread 将代码（方法）作为参数传递给方法—行为参数化 虽然Java8之前可以用匿名类实现行为参数化，但代码复杂，不易读，不易维护 Java8中实现行为参数化的方法叫做函数式编程 函数式编程中没有共享的可变数据，意味着一个方法是可以通过它将参数值转化为结果的方式完全描述的，就像一个数学函数，没有可见的副作用 将方法和Lambda作为一等值（编程语言的目的在于操作值，这些值被称为一等值） 接口中加入默认方法 一种扩充接口的方式，同时不需要破坏已有的实现 以default关键字修饰，缺失的方法主题随接口提供（不需要在实现类中再显式实现一遍）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java8","slug":"学习笔记/Java/Java8","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java8","slug":"Java8","permalink":"http://wangminrui.github.io/tags/Java8/"},{"name":"《Java8实战》","slug":"《Java8实战》","permalink":"http://wangminrui.github.io/tags/《Java8实战》/"}]},{"title":"Java中计算二进制数中1的个数","slug":"Java中计算二进制数中1的个数","date":"2019-06-20T03:06:43.000Z","updated":"2019-07-30T03:04:41.444Z","comments":true,"path":"2019/06/20/Java中计算二进制数中1的个数/","link":"","permalink":"http://wangminrui.github.io/2019/06/20/Java中计算二进制数中1的个数/","excerpt":"","text":"Java中计算二进制数中1的个数","categories":[],"tags":[{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"}]},{"title":"Cracking the Coding Interview 阅读笔记(一):数据结构","slug":"Cracking-the-Coding-Interview-阅读笔记（一）：数据结构","date":"2019-06-01T12:04:50.000Z","updated":"2019-07-30T03:05:22.306Z","comments":true,"path":"2019/06/01/Cracking-the-Coding-Interview-阅读笔记（一）：数据结构/","link":"","permalink":"http://wangminrui.github.io/2019/06/01/Cracking-the-Coding-Interview-阅读笔记（一）：数据结构/","excerpt":"","text":"1. 数组和字符串散列表 散列表是一种将键（key）映射为值（value）从而实现快速查找的数据结构 散列表包含： 一个底层数组 一个散列函数（hash function） 哈希冲突键转化为value时冲突 为了防止哈希冲突，底层数组会变得非常大。除了创建按索引hash（key）存储对象的超大数组，还可以选择将对象存储在索引为hash(key) % array_length的数组元素指向的链表中。这样可以先通过散列值找到对应链表，再在链表中查找相应的键。另外还可以采用二叉查找树实现散列表（Java 8中HashMap使用红黑树），只要保持树平衡，可以将数据查找时间复杂度控制在$ O (log n) $。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"offer收割攻略","slug":"学习笔记/offer收割攻略","permalink":"http://wangminrui.github.io/categories/学习笔记/offer收割攻略/"}],"tags":[{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"},{"name":"程序员面试金典","slug":"程序员面试金典","permalink":"http://wangminrui.github.io/tags/程序员面试金典/"},{"name":"数据结构","slug":"数据结构","permalink":"http://wangminrui.github.io/tags/数据结构/"}]},{"title":"博客待改问题","slug":"博客待改问题","date":"2019-05-28T13:54:05.000Z","updated":"2019-07-30T02:42:23.171Z","comments":true,"path":"2019/05/28/博客待改问题/","link":"","permalink":"http://wangminrui.github.io/2019/05/28/博客待改问题/","excerpt":"","text":"高亮问题 pytorch右侧目录栏 图片问题 转载说明 共享按钮 打赏功能 字数统计 浏览量统计 链接样式 加滚滚","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wangminrui.github.io/categories/备忘录/"}],"tags":[]},{"title":"Git基础","slug":"Git","date":"2019-05-26T09:38:05.000Z","updated":"2019-07-31T06:42:47.370Z","comments":true,"path":"2019/05/26/Git/","link":"","permalink":"http://wangminrui.github.io/2019/05/26/Git/","excerpt":"","text":"一、Git简介版本控制工具 svn没有提交描述，Git有 二、Git工作区域 GitRespository(Git仓库)：最终确定的文件保存到仓库，成为一个新的版本，并且对他人可见 暂存区：暂存已经修改的文件最后统一提交到git仓库种 工作区(Working Directory)：添加、编辑、修改文件等动作 三、Git使用流程3.1 创建仓库和添加文件 设置用户名和用户名邮箱 12git config --global user.name 'wangminrui'git config --global user.email '1248994435@qq.com' 初始化仓库 1git init 查看当前状态 1git status 添加到暂存区 1git add [filename] 从暂存区提交到仓库 1git commit -m '[description]' 3.2 修改文件12git add [filename]git commit -m '[edit description]' 3.3 删除文件12git rm [filename]git commit -m '[delete description]' 3.4 推送到远程仓库12345git remote add origin 你的远程库地址 // 把本地库与远程库关联git push -u origin master // 第一次推送时git push origin master // 第一次推送后，直接使用该命令即可推送修改 四、Git管理远程仓库 克隆操作 1git clone [仓库地址] 可以从github上复制别人的仓库下来 把本地仓库同步到远程仓库 1git push 五、基本操作查看当前仓库信息 1git config -l","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Git","slug":"学习笔记/Git","permalink":"http://wangminrui.github.io/categories/学习笔记/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://wangminrui.github.io/tags/Git/"}]},{"title":"SpringBoot：Hello World","slug":"SpringBoot-2","date":"2019-05-25T07:02:57.000Z","updated":"2019-07-30T06:18:17.657Z","comments":true,"path":"2019/05/25/SpringBoot-2/","link":"","permalink":"http://wangminrui.github.io/2019/05/25/SpringBoot-2/","excerpt":"","text":"待整理 配置文件的作用：修改SpringBoot自动配置的默认值 yml是YAML格式的 YAML语法： k: v v之前必须有空格 大小写敏感","categories":[],"tags":[{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"}]},{"title":"SpringBoot：概述","slug":"Springboot-1","date":"2019-05-17T12:46:48.000Z","updated":"2019-07-30T06:17:17.153Z","comments":true,"path":"2019/05/17/Springboot-1/","link":"","permalink":"http://wangminrui.github.io/2019/05/17/Springboot-1/","excerpt":"","text":"1. Why Spring BootJ2EE笨重的开发、繁多的配置、低下的开发效率、复杂的部署流程、第三方技术集成难度大。 Spring Boot满足现今微服务快速开发、测试和部署的需要，能大幅度简化Spring应用开发，约定大于配置，just run就能创立的一个独立的，产品级别的应用 2. Spring Boot的优点 快速创建独立的Spring应用程序以及余主流框架集成 嵌入的Tomcat、Jetty或者Undertow，无需部署WAR文件，可以直接打包jar包 允许通过Maven来根据需要获取starter，可以进行自动依赖和版本控制 大量地自动配置Spring，也可修改默认值 绝对没有代码生成，对XML没有要求配置 准生产环境的运行时应用监控 与云计算的天然集成 缺点：入门容易精通难，不了解Spring底层很难理解Springboot 3. 微服务单体应用：ALL IN ONE 将所有的页面、服务都放在一个war包，然后部署到服务器上只有一个，开发测试简单部署简单，运维没有太大困难扩展时通过在新的服务器上复制应用，性能瓶颈时进行负载均衡 微服务是2014年Matrin Fowler提出的，它一种架构风格。 将每个功能单元都独立出来作为一个小型服务，一个应用由一组小型服务组成，小型服务之间通过HTTP方式进行互联互调。 微服务通过只有在需要的时候才复制，需要的多复制的多。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java框架","slug":"学习笔记/Java/Java框架","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java框架/"},{"name":"Spring Boot","slug":"学习笔记/Java/Java框架/Spring-Boot","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java框架/Spring-Boot/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"Java框架","slug":"Java框架","permalink":"http://wangminrui.github.io/tags/Java框架/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://wangminrui.github.io/tags/Spring-Boot/"},{"name":"《深入浅出Spring Boot》","slug":"《深入浅出Spring-Boot》","permalink":"http://wangminrui.github.io/tags/《深入浅出Spring-Boot》/"}]},{"title":"Java编程思想读书笔记：综述","slug":"Java编程思想读书笔记-一-综述","date":"2019-05-12T06:23:36.000Z","updated":"2019-07-30T11:09:45.445Z","comments":true,"path":"2019/05/12/Java编程思想读书笔记-一-综述/","link":"","permalink":"http://wangminrui.github.io/2019/05/12/Java编程思想读书笔记-一-综述/","excerpt":"","text":"1. 对象导论1.1 抽象过程过程 -&gt; 对象 1.2 每个对象都有一个接口接口确定了某一特定对象所能发出的请求 1.3 每个对象都提供服务把对象想象为程序的服务提供者 1.4 被隐藏的具体实现访问控制：public private protected 1.5 复用具体实现创建一个成员对象，不同的成员对象可以组成新的类 1.6 继承重用和扩展基类，减少代码 1.7 伴随多态的可互换对象泛型后期绑定：编译器只保证代码的存在和对参数类型和返回值进行检查，但是并不知道具体的代码 1.8 单根继承结构所有类最终继承自单一的基类—Object单根继承保证所有的对象都具备某些功能，可以执行某些基本操作 1.9 容器集合：一个可以被操作、从而解决问题的序列泛型：增加参数化类型 1.10 对象的创建和生命期动态内存分配，垃圾回收器 1.11 异常处理：处理错误异常被当作一种对象，异常处理是另一条不会影响正常程序的执行路径 1.12 并发编程共享资源，线程 1.12 Java与Internet客户端、Web、服务器编程 2. 一切都是对象2.1 用引用操作对象JAVA中一切都是对象，但实际上操作的是对象的引用 2.2 必须由你创建所有对象用new操作符实现创建新对象 存储到什么地方？寄存器：最快的存储区，在处理器内部，数量有限堆栈：在RAM中，堆栈指针向下移动分配新内存，向上移动释放内存；速度仅次于寄存器；但必须堆栈内所有项的生命周期，以便上下移动指针；存储对象引用，但不存储JAVA对象堆：在RAM中，存放所有的Java对象；不需要知道存储的项存活多长时间，new的时候会直接在堆中进行内存分配；但清理回收比较麻烦常量存储：直接存放在程序代码内部非RAM存储：数据完全独立于程序之外，没有运行时也可以存在；流对象和持久化对象；必要时可以恢复为常规的基于RAM的对象","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"《Java编程思想》","slug":"《Java编程思想》","permalink":"http://wangminrui.github.io/tags/《Java编程思想》/"}]},{"title":"有参考意义的论文","slug":"有参考意义的论文","date":"2019-04-25T05:56:24.000Z","updated":"2019-08-01T01:34:33.068Z","comments":true,"path":"2019/04/25/有参考意义的论文/","link":"","permalink":"http://wangminrui.github.io/2019/04/25/有参考意义的论文/","excerpt":"","text":"【CCF推荐C类会议IJCNN】【2017】Ensemble Application of Convolutional and Recurrent Neural Networks for Multi-label Text Categorization实验数据集 Reuters-21578 9603 train docs 3299 test docs RCV1-v2 103个类别 M: number of documentsD: total vocabulary sizeL: number of labelsC: average number of lables per document 评价指标 hamming loss the marco/micro-averaged precision the marco/micro-averaged recall the marco/micro-averaged F1 Baseline Binary relevance（BR） Classifier chain (CC) ML-kNN ML-HARAM 结果","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wangminrui.github.io/categories/备忘录/"}],"tags":[]},{"title":"关于Java中基本类型和引用类型的疑惑","slug":"关于Java中基本类型和引用类型的疑惑","date":"2019-04-20T02:24:12.000Z","updated":"2019-07-30T06:00:13.697Z","comments":true,"path":"2019/04/20/关于Java中基本类型和引用类型的疑惑/","link":"","permalink":"http://wangminrui.github.io/2019/04/20/关于Java中基本类型和引用类型的疑惑/","excerpt":"问：为什么Java中有了基本类型还需要有对应的引用类型（包装器类型） 基本类型 引用类型/包装器类型 byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean 答：","text":"问：为什么Java中有了基本类型还需要有对应的引用类型（包装器类型） 基本类型 引用类型/包装器类型 byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean 答： 简单来说：让基本类型具备对象的特征，实现更多的功能 因为Java是一个面向对象的语言，基本类型不具有对象的性质，包装类将基本类型“包装起来”，使得它具有了对象的性质，并且可以添加属性和方法，丰富了基本类型的操作。 为什么不只使用包装器类型，还要使用基本类型呢？ 包装器类型是一种对象，需要通过new来撞见，而new对象存储在堆中，用new创建一个小的、简单的变量往往不是很有效基本类型不是用new关键字，而将变量值直接存储在栈中，但Java中基本数据类型也不一定全都存储在栈中 基本类型和引用类型互相转换 1234567// int转Integerint i = 0;Integer ii = new Integer(i);// Integer转intInteger ii = new Integer(0);int i = ii.value(); 基本类型和引用类型的区别 声明方式不同：基本类型不使用new关键字，引用类型必须使用new关键字 存储方式及位置不同：基本类型将变量值存储在栈中，而引用类型是将对象放在堆中，然后通过引用来使用 初始值不同： 基本类型的初始值如int为0，boolean为false，而包装类型初始值为null 使用方式不同：基本类型直接赋值使用就可以，而包装类型在集合如Collection、Map的时候会用到","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"疑惑辣么多","slug":"疑惑辣么多","permalink":"http://wangminrui.github.io/tags/疑惑辣么多/"}]},{"title":"Java中的装箱和拆箱","slug":"Java中的装箱和拆箱","date":"2019-04-17T03:31:15.000Z","updated":"2019-07-30T05:59:49.317Z","comments":true,"path":"2019/04/17/Java中的装箱和拆箱/","link":"","permalink":"http://wangminrui.github.io/2019/04/17/Java中的装箱和拆箱/","excerpt":"1. 装箱和拆箱的概念装箱指将基本类型转换为引用类型 拆箱指将引用类型转换为基本类型 123Integer i = new Integer(10); // Java SE5之前Integer i = 10; //自动装箱int n = i; //拆箱","text":"1. 装箱和拆箱的概念装箱指将基本类型转换为引用类型 拆箱指将引用类型转换为基本类型 123Integer i = new Integer(10); // Java SE5之前Integer i = 10; //自动装箱int n = i; //拆箱 2. 装箱拆箱的实现方式123456public class Main&#123; public static void main(String[] args)&#123; Integer i = 10; int n = i; &#125;&#125; 反编译class文件之后得到如下内容（图片源，侵删）： 可以看出：装箱的时候调用valueOf(xxx)方法，拆箱的时候调用xxxValue()方法xxx代表int、double等类型 3. 何时发生自动装箱和拆箱主要发生在两种情况： 赋值时 1234567//before autoboxingInteger iObject = Integer.valueOf(3);Int iPrimitive = iObject.intValue() //after java5Integer iObject = 3; //autobxing - primitive to wrapper conversionint iPrimitive = iObject; //unboxing - object to primitive conversion 方法调用时 12345678public static Integer show(Integer iParam)&#123; System.out.println(\"autoboxing example - method invocation i: \" + iParam); return iParam;&#125; //autoboxing and unboxing in method invocationshow(3); //autoboxingint result = show(3); //unboxing because return type of method is Integer 4. 自动装箱的弊端如果在一个循环中进行自动装箱操作，如下面的例子就会创建多余的对象，影响程序的性能。 1234Integer sum = 0; for(int i=1000; i&lt;5000; i++)&#123; sum+=i;&#125; 上述代码中的sum += i具体实现如下，首先对sum进行拆箱操作，然后数值相加，最后发生自动装箱操作转换成Integer对象： 12sum = sum.intValue() + i;Integer sum = new Integer(result); 可是这里的sum为Integer类型，上面的循环会创建将近4000个无用的Integer对象，无疑加重了垃圾回收的工作量，并降低程序性能。 5. 重载与自动装箱在java5之前，value(int)和value(Integer)是完全不同的方法，但java5之后，由于自动装箱、拆箱的引入，传入int还是Integer应该调用哪个方法？典型的例子就是ArrayList的remove方法，它有remove(index)和remove(Object)两种重载，当发生这种情况的时候，不会进行自动装箱操作。 1234567891011121314151617181920public void test(int num)&#123; System.out.println(\"method with primitive argument\"); &#125; public void test(Integer num)&#123; System.out.println(\"method with wrapper argument\"); &#125; //calling overloaded methodAutoboxingTest autoTest = new AutoboxingTest();int value = 3;autoTest.test(value); //no autoboxing Integer iValue = value;autoTest.test(iValue); //no autoboxing //Output://method with primitive argument//method with wrapper argument 6. 几个极端例子 “==”问题 1234567891011Integer i1 = 100;Integer i2 = 100;Integer i3 = 200;Integer i4 = 200;int i5 = 100;int i6 = 200;System.out.println(i1==i2); //trueSystem.out.println(i3==i4); //falseSystem.out.println(i1==i5); //true int和Integer比较时，Integer会自动拆箱，比较值是否相等System.out.println(i3==i6); //true 自动装箱是通过Integer的valueOf()方法实现的，valueOf的源码如下： 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) //low=-128, high=127 return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 因此在通过valueOf()方法创建Integer对象的时候，数值在[-128,127]之间的，会直接返回IntegerCache中对应的对象引用，否则新建一个对象。Long和Short类型也都缓存了[-128,127]而==符号两边都是引用类型，因此比较的是对象，因此第一个输出true，第二个输出false 而double和boolean相应的标准又是不同的 1234567Double i1 = 100.0;Double i2 = 100.0;Double i3 = 200.0;Double i4 = 200.0;System.out.println(i1==i2); //false，源码中double类型无论多大都会直接创建新对象System.out.println(i3==i4); //false 1234567Boolean i1 = false;Boolean i2 = false;Boolean i3 = true;Boolean i4 = true;System.out.println(i1==i2); //true，源码中boolean类型只会返回TRUE和FALSE，这是Boolean的静态成员属性：public static final Boolean FALSE = new Boolean(false);System.out.println(i3==i4); //false Integer i = new Integer(xxx)和Integer i = xxx两种方式的区别 第一种方式不会触发自动装箱的过程；而第二种方式会触发； 在执行效率和资源占用上的区别。第二种方式的执行效率和资源占用在一般性情况下要优于第一种情况（注意这并不是绝对的）。 更复杂的情况 12345678910111213141516Integer a = 1;Integer b = 2;Integer c = 3;Integer d = 3;Integer e = 321;Integer f = 321;Long g = 3L;Long h = 2L;System.out.println(c==d); //trueSystem.out.println(e==f); //falseSystem.out.println(c==(a+b)); //trueSystem.out.println(c.equals(a+b)); //a+b会先拆箱，数值运算，再装箱，比较的是 trueSystem.out.println(g==(a+b)); //比较的是数值 trueSystem.out.println(g.equals(a+b)); //false 调用的Integer.valueOfSystem.out.println(g.equals(a+h)); //true 调用的Long.valueOf 当 &quot;==&quot;运算符的两个操作数都是 包装器类型的引用，则是比较指向的是否是同一个对象，而如果其中有一个操作数是表达式（即包含算术运算）则比较的是数值（即会触发自动拆箱的过程） 如果数值是int类型的，装箱过程调用的是Integer.valueOf；如果是long类型的，装箱调用的Long.valueOf方法","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://wangminrui.github.io/tags/Java基础/"}]},{"title":"Spring：Spring基础","slug":"Spring（一）：Spring基础","date":"2019-04-16T02:59:42.000Z","updated":"2019-07-30T05:55:13.552Z","comments":true,"path":"2019/04/16/Spring（一）：Spring基础/","link":"","permalink":"http://wangminrui.github.io/2019/04/16/Spring（一）：Spring基础/","excerpt":"","text":"什么是SpringSpring是构建Java应用程序的轻量级框架，Spring可以构建Java中的任何应用程序（例如，独立的应用程序、Web应用程序、JEE应用程序） github： 1git clone git://github.com/spring-projects/spring-framework.git Spring项目 SpringBoot SpringCloud SpringSecurity Maven管理Java应用程序依赖项的工具，可以进行应用程序构建、打包和依赖项管理。 GradleGradle是一个强大的构建工具，它放弃了用于配置的臃肿XML，转而利用Groovy的简单性和灵活性。Spring4.x开始，Spring团队已经转向使用Gradle来配置每个Spring产品。 控制反转和依赖注入Spring框架的核心是控制反转Ioc(Inversion of Control, IoC)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java框架","slug":"学习笔记/Java/Java框架","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java框架/"},{"name":"Spring","slug":"学习笔记/Java/Java框架/Spring","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java框架/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://wangminrui.github.io/tags/Spring/"}]},{"title":"JVM：垃圾收集器","slug":"JVM-5","date":"2019-04-11T03:09:23.000Z","updated":"2019-07-30T06:15:25.583Z","comments":true,"path":"2019/04/11/JVM-5/","link":"","permalink":"http://wangminrui.github.io/2019/04/11/JVM-5/","excerpt":"","text":"待整理","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"JVM","slug":"学习笔记/Java/JVM","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://wangminrui.github.io/tags/JVM/"},{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"http://wangminrui.github.io/tags/《深入理解Java虚拟机》/"}]},{"title":"top-k问题","slug":"topk","date":"2019-04-07T02:31:47.000Z","updated":"2019-07-30T06:30:47.943Z","comments":true,"path":"2019/04/07/topk/","link":"","permalink":"http://wangminrui.github.io/2019/04/07/topk/","excerpt":"","text":"","categories":[{"name":"算法编程","slug":"算法编程","permalink":"http://wangminrui.github.io/categories/算法编程/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://wangminrui.github.io/tags/面试/"},{"name":"算法","slug":"算法","permalink":"http://wangminrui.github.io/tags/算法/"}]},{"title":"JVM：垃圾回收机制","slug":"JVM-4","date":"2019-04-04T03:07:54.000Z","updated":"2019-07-30T06:14:54.783Z","comments":true,"path":"2019/04/04/JVM-4/","link":"","permalink":"http://wangminrui.github.io/2019/04/04/JVM-4/","excerpt":"","text":"1. 概述为什么要了解垃圾回收（Garbage Collection, GC）和内存分配呢？ 因为需要排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我们就需要对这些”自动化“的技术实施必要的监控和调节。 Java内存运行时区域中程序计数器、虚拟机栈、本地方法栈随线程而生、随线程而灭，不需要过多考虑垃圾回收的问题。但Java堆和方法区不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，这部分内存的分配和回收都是动态的。 2.3. 垃圾收集算法","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"JVM","slug":"学习笔记/Java/JVM","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://wangminrui.github.io/tags/JVM/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"http://wangminrui.github.io/tags/《深入理解Java虚拟机》/"},{"name":"JVM垃圾回收","slug":"JVM垃圾回收","permalink":"http://wangminrui.github.io/tags/JVM垃圾回收/"}]},{"title":"等差数列和等比数列","slug":"等差数列和等比数列","date":"2019-04-01T02:14:58.000Z","updated":"2019-07-27T02:40:30.381Z","comments":true,"path":"2019/04/01/等差数列和等比数列/","link":"","permalink":"http://wangminrui.github.io/2019/04/01/等差数列和等比数列/","excerpt":"","text":"等差数列 通项公式： a_n=a_1+(n-1)\\cdot d前n项和： S_n=n\\cdot a_1+\\frac{n(n-1)d}{2}或 S_n=\\frac{n(a_1+a_n)}{2}等比数列 通项公式： a_n=a_1\\cdot q^{(n-1)}前n项和： S_n = a_1\\times\\frac{1-q^n}{1-q}前n项积： T_n=a_1^n\\cdot q\\cdot{\\frac{n(n-1)}{2}}","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wangminrui.github.io/categories/备忘录/"}],"tags":[]},{"title":"JVM：HotSpot虚拟机对象探秘","slug":"JVM-3","date":"2019-03-31T03:05:15.000Z","updated":"2019-07-30T06:13:48.526Z","comments":true,"path":"2019/03/31/JVM-3/","link":"","permalink":"http://wangminrui.github.io/2019/03/31/JVM-3/","excerpt":"以常用的HotSpot虚拟机为例 1. 对象的创建本文中讨论的对象仅限于普通Java对象，不包括数组和Class对象等 graph LR A(检测类是否被加载) -->B(分配内存) B --> C(初始化零值) C --> D(设置对象头) D --> E(执行init) 1.1 检测类是否被加载虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。","text":"以常用的HotSpot虚拟机为例 1. 对象的创建本文中讨论的对象仅限于普通Java对象，不包括数组和Class对象等 graph LR A(检测类是否被加载) -->B(分配内存) B --> C(初始化零值) C --> D(设置对象头) D --> E(执行init) 1.1 检测类是否被加载虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 1.2 分配内存类加载检查通过后，为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定。 为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。（在使用Serial、ParNew等代Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表） 指针碰撞：假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那么分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离空闲列表：如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录 内存分配并发问题：对象创建在虚拟机中是非常频繁的行为，在并发情况下，可能出现在给对象A分配内存，指针还没来得及修改，对象B又使用了原来的指针来分配内存。JVM采用两种方式来保证线程安全 CAS+失败重试：不加锁，如果冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 本地线程分配缓冲（Thread Local Allocation Buffer，TLAB）： 为每一个线程预先在 Eden 区分配一块内存—TLAB。JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。是否使用TLAB，可以用过-XX:+/-UserTLAB参数设定 1.3 初始化零值将分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一工作也可以提前至TLAB分配时进行，这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 1.4 设置对象头初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 1.5 执行init方法在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt;方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 2. 对象的内存布局对象在内存中的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 2.1 对象头对象头包括两部分信息： 第一部分用于存储对象自身的自身运行时数据（哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等）官方称这部分为“Mark Word”，这部分数据的长度在32位和64位虚拟机中分别为32bit和64bit，对象需要存储的运行时数据很多，其实已经超出了32bit和64bit，但对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。HotSpot虚拟机对象头Mark Word存储内容如下： 存储内容 标志位 状态 对象哈希码、对象分代年龄 01 未锁定 指向锁记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀（重量级锁定） 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。并不是所有虚拟机实现都必须在对象数据上保留类型指针，也就是说，查找对象元数据信息不一定要经过对象本身。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组的大小。 2.2 实例数据实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容（包括从父类继承下来的和子类自己定义的）。这部分的存储顺序会受到虚拟机分配策略参数和字段在Java源码中定义顺序的影响。HotSpot虚拟机的默认分配策略为long/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers），从分配策略中可以看出，相同宽度的字段总是被分配到一起。在满足这个前提的条件夏，父类中定义的变量会出现在子类之前（但不是绝对的，CompactFileds默认为true，当它是true时，子类中较窄的变量也可能会插入到父类变量的空隙中）。 2.3 对齐填充对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 3. 对象的访问定位Java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过合中方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种： 句柄： Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针访问： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。 对比： 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时（垃圾收集时移动对象是非常普遍的行为）只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后是一项非常可观的执行成本。 Sun HotSpot使用的是直接指针进行对象访问的，但其他语言和框架也有很多使用句柄访问的。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"JVM","slug":"学习笔记/Java/JVM","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://wangminrui.github.io/tags/JVM/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"http://wangminrui.github.io/tags/《深入理解Java虚拟机》/"}]},{"title":"Kth-element问题：找出第k大的数","slug":"Kth-element","date":"2019-03-31T02:12:47.000Z","updated":"2019-08-01T06:35:31.897Z","comments":true,"path":"2019/03/31/Kth-element/","link":"","permalink":"http://wangminrui.github.io/2019/03/31/Kth-element/","excerpt":"Leetcode215：Kth Largest Element in an Array Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element. Example 1: 12Input: [3,2,1,5,6,4] and k = 2Output: 5 Example 2: 12Input: [3,2,3,1,2,4,5,5,6] and k = 4Output: 4 Note:You may assume k is always valid, 1 ≤ k ≤ array’s length.","text":"Leetcode215：Kth Largest Element in an Array Find the kth largest element in an unsorted array. Note that it is the kth largest element in the sorted order, not the kth distinct element. Example 1: 12Input: [3,2,1,5,6,4] and k = 2Output: 5 Example 2: 12Input: [3,2,3,1,2,4,5,5,6] and k = 4Output: 4 Note:You may assume k is always valid, 1 ≤ k ≤ array’s length. 方法一：直接排序基本思想：使用排序算法对整个数组进行排序，然后去第k大的数时间复杂度： 取决于所用排序算法的时间复杂度优点： 简单粗暴缺点： 方法太蠢 123456class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; Arrays.sort(nums); return nums[nums.length-k]; &#125;&#125; Leetcode Submission Runtime: 2 ms, faster than 89.00% of Java online submissions for Kth Largest Element in an Array. Memory Usage: 36.5 MB, less than 94.28% of Java online submissions forKth Largest Element in an Array. 方法二：冒泡排序基本思想： 经过k次冒泡排序，第k大的数字就在倒数第k位时间复杂度： $O(n\\times k)$优点： 简单、易懂缺点： 海量数据时间成本太高 123456789101112131415161718class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; for (int i = 0; i &lt; k; i++) &#123; //k次冒泡，倒数第k个就是第k大的数字 for (int j = 0; j &lt; nums.length-i-1; j++) &#123; if (nums[j] &gt; nums[j+1]) &#123; swap(nums, j, j+1); &#125; &#125; &#125; return nums[nums.length - k]; &#125; public void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; Leetcode Submission Runtime: 67 ms, faster than 5.05% of Java online submissions for Kth Largest Element in an Array. Memory Usage: 37.2 MB, less than 93.23% of Java online submissions forKth Largest Element in an Array. 方法三：简单选择排序基本思想： 每次选择最大的数放在第一个时间复杂度： 和冒泡方式相同，$O(n\\times k)$优点： 简单、易懂缺点： 海量数据时间成本太高 123456789101112131415161718class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; for (int i = 0; i &lt; k; i++) &#123; int max = i; for (int j = i+1; j &lt; nums.length; j++) &#123; if (nums[max] &lt; nums[j]) max = j; &#125; swap(nums, i, max); &#125; return nums[k-1]; &#125; public void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; Leetcode Submission Runtime: 72 ms, faster than 5.05% of Java online submissions for Kth Largest Element in an Array. Memory Usage: 37.7 MB, less than 88.64% of Java online submissions forKth Largest Element in an Array. 方法四：快速排序基本思想： 经过一次partition，数组会被pivot分为左右两部分：S左、S右。当S右元素个数等于k-1时，pivot即是所找的数；当S右元素个数小于k-1时，所找数位于S左中；当S右元素个数大于k-1时，所找数位于S右中时间复杂度： $O(n)$ —证明见算法导论优点： 不必进行完整排序，在大数据情况下能有效降低时间复杂度缺点： 应该还不算是降低时间复杂度的最佳方法 123456789101112131415161718192021222324252627282930class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; //快速排序 return quickSort(nums, 0, nums.length-1, k); &#125; public int quickSort(int[] arr, int begin, int end, int k)&#123; int low = begin; int high = end; int key = arr[begin]; while (low &lt; high)&#123; while(low &lt; high &amp;&amp; key &lt;= arr[high]) high--; while(low &lt; high &amp;&amp; key &gt;= arr[low]) low++; if (low &lt; high) &#123; swap(arr, low, high); &#125; &#125; arr[begin] = arr[low]; arr[low] = key; if (end - high == k-1) return key; else if (end - high &gt; k-1) return quickSort(arr, high+1, end, k); //第k个数在右边 else return quickSort(arr, begin, high-1, k-(end-high+1)); //第k个数在左边 &#125; public void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; Leetcode Submission Runtime: 34 ms, faster than 24.47% of Java online submissions for Kth Largest Element in an Array. Memory Usage: 36.7 MB, less than 93.91% of Java online submissions forKth Largest Element in an Array. 方法五：堆排序基本思想： 借助小顶堆或大顶堆，构建k个元素的堆，每进入一个元素，调整堆结构，直到遍历完所有数据，堆底元素即为第k大的数时间复杂度： $O(nlogn)$优点： 适合海量数据缺点： 需要占用额外空间 12345678910111213class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; //堆排序 小顶堆，保持堆顶元素为当前堆的最小值 PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;(); //会自动排序，默认是小顶堆，默认容量11 for (int ele:nums) &#123; pq.add(ele); if (pq.size() &gt; k) &#123; //堆的大小保持k pq.poll(); //移除堆头，即移除最小的那个元素 &#125; &#125; return pq.peek(); //返回堆头，即第k大元素 &#125;&#125; Leetcode Submission Runtime: 6 ms, faster than 61.33% of Java online submissions for Kth Largest Element in an Array. Memory Usage: 36.7 MB, less than 93.79% of Java online submissions forKth Largest Element in an Array. 方法六：桶排序基本思想：把数据根据一定分到n个桶里面，根据桶中元素数量可以判断第k大的元素在那个桶中，再对该桶中的元素排序，找到第k大的数","categories":[{"name":"算法编程","slug":"算法编程","permalink":"http://wangminrui.github.io/categories/算法编程/"},{"name":"leetcode","slug":"算法编程/leetcode","permalink":"http://wangminrui.github.io/categories/算法编程/leetcode/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://wangminrui.github.io/tags/面试/"},{"name":"算法","slug":"算法","permalink":"http://wangminrui.github.io/tags/算法/"},{"name":"Leetcode","slug":"Leetcode","permalink":"http://wangminrui.github.io/tags/Leetcode/"}]},{"title":"String、StringBuilder和StringBuffer","slug":"String、StringBuilder和StringBuffer","date":"2019-03-29T07:40:14.000Z","updated":"2019-07-30T06:02:01.593Z","comments":true,"path":"2019/03/29/String、StringBuilder和StringBuffer/","link":"","permalink":"http://wangminrui.github.io/2019/03/29/String、StringBuilder和StringBuffer/","excerpt":"","text":"","categories":[],"tags":[{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"}]},{"title":"设计模式：单例模式","slug":"设计模式-1","date":"2019-03-25T07:52:14.000Z","updated":"2019-07-31T08:30:00.655Z","comments":true,"path":"2019/03/25/设计模式-1/","link":"","permalink":"http://wangminrui.github.io/2019/03/25/设计模式-1/","excerpt":"","text":"Why 单例模式当封装的类加载的次数很多，每次初始化都会加载很多资源方法。为了节省内存，出现了单例模式。而且有些类全局只需要实例化一次。 What 单例模式全局中只允许一个实例。构造方法是私有的（即只能在类内部实例化该类）。 How 单例模式实现步骤： 构造方法私有化，不能在类的外部通过new关键字实例化该类对象 在类内部产生唯一一个实例化对象，并且将其封装为private static类型 定义一个静态方法返回这个唯一对象 以下内容参考 设计模式之单例模式 1. 立即加载/饿汉模式立即加载：实用类的时候已经将对象创建完毕（不管以后会不会使用到该实例化对象，先创建了再说。很着急的样子，故又被称为“饿汉模式”） 123456789101112131415161718192021public class Singleton &#123; // 将自身实例化对象设置为一个属性，并用static、final修饰 private static final Singleton instance = new Singleton(); // 构造方法私有化 private Singleton() &#123;&#125; // 静态方法返回该实例 public static Singleton getInstance() &#123; return instance; &#125;&#125;//客户端代码public void main(String[] args)&#123; Singleton s1 = Singleton.getInstance(); Singleton s2 = Singleton.getInstance(); System.out.println(s1==s2 ? \"s1和s2是相同实例\" : \"s1和s2是相同实例\"); //s1和s2是相同实例&#125; 优点：实现起来简单，没有多线程同步问题。缺点：当类SingletonTest被加载的时候，会初始化static的instance，静态变量被创建并分配内存空间，从这以后，这个static的instance对象便一直占着这段内存（即便你还没有用到这个实例），当类被卸载时，静态变量被摧毁，并释放所占有的内存，因此在某些特定条件下会耗费内存。 2. 延迟加载/懒汉模式延迟加载：调用get()方法时实例才被创建（先不急着实例化出对象，等要用的时候才给你创建出来。不着急，故又称为“懒汉模式”）12345678910111213141516public class Singleton &#123; // 将自身实例化对象设置为一个属性，并用static修饰 private static Singleton instance; // 构造方法私有化 private Singleton() &#123;&#125; // 静态方法返回该实例 public static Singleton getInstance() &#123; if(instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 优点：实现起来比较简单，当类SingletonTest被加载的时候，静态变量static的instance未被创建并分配内存空间，当getInstance方法第一次被调用时，初始化instance变量，并分配内存，因此在某些特定条件下会节约了内存。缺点：在多线程环境中，这种实现方法是完全错误的，根本不能保证单例的状态。 3. 线程安全的懒汉模式加了synchronized关键字 12345678910111213141516public class Singleton &#123; // 将自身实例化对象设置为一个属性，并用static修饰 private static Singleton instance; // 构造方法私有化 private Singleton() &#123;&#125; // 静态方法返回该实例，加synchronized关键字实现同步 public static synchronized Singleton getInstance() &#123; if(instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 优点：在多线程情形下，保证了“懒汉模式”的线程安全。缺点：众所周知在多线程情形下，synchronized方法通常效率低，显然这不是最佳的实现方案。 4. DCL双重检查锁机制DCL: double checked locking 12345678910111213141516171819202122public class Singleton &#123; // 将自身实例化对象设置为一个属性，并用static修饰 private static Singleton instance; // 构造方法私有化 private Singleton() &#123;&#125; // 静态方法返回该实例 public static Singleton getInstance() &#123; // 第一次检查instance是否被实例化出来，如果没有进入if块 if(instance == null) &#123; synchronized (Singleton.class) &#123; // 某个线程取得了类锁，实例化对象前第二次检查instance是否已经被实例化出来，如果没有，才最终实例出对象 if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 单例模式的最佳实现方式。内存占用率高，效率高，线程安全，多线程操作原子性。 为什么要进行第二次instance==null的判断？ 如果有两个线程同时调用GetInstance()方法，他们都可以通过第一重instance==null的判断，然后由于synchronized，两个线程只有一个线程进入，另一个线程在排队等候。第一个线程创建完实例出来之后，第二个线程会进入，如果没有第二重instance==null的判断，第二个线程会再创建一个实例，这不符合我们的初衷。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"设计模式","slug":"学习笔记/设计模式","permalink":"http://wangminrui.github.io/categories/学习笔记/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://wangminrui.github.io/tags/设计模式/"},{"name":"单例模式","slug":"单例模式","permalink":"http://wangminrui.github.io/tags/单例模式/"}]},{"title":"JVM：Java内存区域","slug":"JVM-2","date":"2019-03-23T15:03:35.000Z","updated":"2019-07-30T06:11:32.474Z","comments":true,"path":"2019/03/23/JVM-2/","link":"","permalink":"http://wangminrui.github.io/2019/03/23/JVM-2/","excerpt":"C/C++程序员自己管理对象的内存分配，这样容易出现内存泄漏和内存溢出的问题，Java程序员将内存控制的权力交给了Java虚拟机 根据《Java虚拟机规范（Java SE 7版）》的规定，Java虚拟机所管理的内存区域将会包括以下几个运行时数据区域： Method Area（Non-Heap）（方法区） Heap（堆） Program Counter Register（程序计数器） VM Stack（虚拟机栈，也有翻译成JAVA 方法栈的） Native Method Stack （ 本地方法栈 ） 其中方法区 和 堆 是线程共享的Java虚拟机栈，本地方法栈 和 程序计数器 是非线程共享的。","text":"C/C++程序员自己管理对象的内存分配，这样容易出现内存泄漏和内存溢出的问题，Java程序员将内存控制的权力交给了Java虚拟机 根据《Java虚拟机规范（Java SE 7版）》的规定，Java虚拟机所管理的内存区域将会包括以下几个运行时数据区域： Method Area（Non-Heap）（方法区） Heap（堆） Program Counter Register（程序计数器） VM Stack（虚拟机栈，也有翻译成JAVA 方法栈的） Native Method Stack （ 本地方法栈 ） 其中方法区 和 堆 是线程共享的Java虚拟机栈，本地方法栈 和 程序计数器 是非线程共享的。 1. 程序计数器程序计数器是一个比较小的内存区域，用于指示当前线程所执行的字节码执行到了第几行 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 如果线程执行的是一个Java方法，程序计数器记录正在执行的虚拟机字节码指令的地址；如果执行的是Native方法，程序计数器则为空（undefined） 线程隔离的 唯一一个在Java虚拟机规范中没有规定任何OutOfMemory情况的区域 2. Java虚拟机栈虚拟机栈可以叫做Java方法栈，因为它描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量，操作数栈，动态链接，方法出口等信息。每一个方法从调用直至执行完成的过程，就对应这一个栈帧在虚拟机栈中入栈到出栈的过程。栈的内存是连续的。 Java 内存可以粗糙的区分为堆内存和栈内存，但Java内存区域的划分实际上远比这复杂，其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAccess类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（slot），其余数据类型只占用1个。局部变量表所需的内存空间在编译期间完成，当进入一个方法时，这个方法需要在帧内分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 线程隔离的 Java虚拟机规范中规定了两种异常状况： StackOverflowError异常：如果线程请求的栈深度大于虚拟机允许的深度 OutOfMemoryError：如果虚拟机栈可以动态扩展（当前大部分Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），如果扩展时无法申请到足够的内存 3. 本地方法栈本地方法栈发挥的作用和Java虚拟机栈发挥的作用非常相似，Java虚拟机栈位Java方法（也就是字节码）服务，本地方法栈为虚拟机使用到的Native方法服务。在虚拟机规范中对本地方法栈使用的语言、使用方式和数据结构并没有强制规定，因此具体的虚拟机可以自由实现它，甚至有的虚拟机会把Java方法栈和本地方法栈合二为一。 线程隔离的 两种异常：StackOverflowError和OutOfMemoryError 4. Java堆对于大多数应用来说，Java堆是JVM所管理内存中最大的一块。Java堆是被所有线程共享的一块区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java虚拟机规范中的描述是： 所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有对象都分配在堆上逐渐变得不是那么“绝对“了。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称作GC堆（Garbage Collected Heap）。 从内存回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代；再细致一点有：Eden空间、From Survivor、To Survivor空间等。从内存分配的角度来看，线程共享的Java堆种可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer, TLAB），不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是更好地回收内存，或者更快地分配内存。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutofMemoryError异常。 在 JDK 1.8中移除整个永久代，取而代之的是一个叫元空间（Metaspace）的区域（永久代使用的是JVM的堆内存空间，而元空间使用的是物理内存，直接受到本机的物理内存限制）。 Java8内存模型——永久代（PermGen）和元空间（Metaspace）* 5. 方法区方法区是线程共享的一块区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是和Java堆区分开来。 对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人都更愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者使用永久代来实现方法区而已，这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法去编写内存管理代码的工作。对于其他虚拟机（如BEA JRockit、IBM J9等）来说是不存在永久代的概念的。 但使用永久代来实现方法区更容易遇到内存溢出问题（永久代有-XX:MaxPermSize的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系统中的4GB，就不会出现问题)，而且极少数方法（例如 String.intern()）会因为这个原因导致不同虚拟机下有不同表现。 在JDK1.7的HotSpot中，把原本放在永久代的字符串常量池移出 Java虚拟机规范中，方法区和Java堆一样不需要连续的内存，并且除了可以选择固定大小或者可扩展，还可以选择不是先垃圾收集。相对而言，垃圾收集行为在方法区比较少出现，但并非数据进入了方法区就“永久”存在了。方法区的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。在Sun公司的BUG列表中，曾出现过的若干个严重的BUG就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏。 Java虚拟机规范规定：当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常 6. 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Poole Table），用于存放编译器生成的各种字面量和符号引用（字面量和符号引用如下图），这部分内容将在类加载后进入方法区的运行时常量池中存放。 Java虚拟机对Class文件中每一部分（包括常量池）的格式有严格规定，每一个字节用于存储那种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行。但对于运行时常量池，Java虚拟机规范没有做任何细节的要求，不同的虚拟机可以按照自己的需要实现这个内存区域。一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储再运行时常量池中。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得最多的就是String类的intern()方法。 运行时常量池是方法区的一部分，也受到方法区的限制，当无法满足内存分配需求时，将抛出OutOfMemoryError异常 JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 graph TD A(常量池) -->B(字面量) B --> C(文本字符串) B --> D(final常量) B --> E(基本数据类型的值) B --> F(其它) A --> G(符号引用) G --> H(类和结构的完全限定名) G --> I(字段名和描述符) G --> J(方法名和描述符) 7. 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁使用，并且也可能导致OutOfMemoryError异常出现。 JDK1.4中新加入NIO（New Input/Output）类，引入了一种基于通道(channer)和缓冲区(Buffer)的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储再Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 显然，本机直接内存的分配不会受到Java堆大小的限制，但是还是会受到本机总内存（包括RAM基于SWAP区或者分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据之际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统的限制），从而导致动态扩展时出现OutOfMemoryError异常。 8. 总结 内存区域 存放了什么 内存连续 线程共享 异常 程序计数器 存放对象实例 不共享 无 Java虚拟机栈 创建栈帧，每帧存储局部变量（数据类型、对象引用等），操作数栈，动态链接，方法出口等信息 连续 不共享 StackOverflowError: 栈请求深度大于允许深度OutOfMemoryError: 扩展时无法申请到足够内存 本地方法栈 存放native方法 连续 不共享 StackOverflowError: 栈请求深度大于允许深度OutOfMemoryError: 扩展时无法申请到足够内存 Java堆 存放对象实例 不连续 共享 OutOfMemoryError: 无法满足内存分配需求 方法区 存放常量、静态变量、类信息 不连续 共享 OutOfMemoryError: 无法满足内存分配需求 9. 栈和堆的区别 堆 栈 线程共享 共享 不共享 存放对象 实例化对象、数组 局部变量、对象的引用变量 内存分配 只有一个堆内存 每个线程都有一个独立的栈空间 存活周期 跟随整个程序生命周期 线程的生命周期 存取速度 运行时动态分配内存，存取速度较慢 存在栈中的数据大小和生命周期必须是确定的，缺乏灵活性，存取速度较快 内存大小 大 很小 异常错误 java.lang.OutOfMemoryError java.lang.StackOverFlowError，java.lang.OutOfMemoryError 为什么要把堆和栈分离？ 从软件设计的角度来看，栈代表了处理逻辑，而堆代表了数据，这样分离使得处理逻辑更为清晰。这种隔离、模块化的思想在软件设计的方方面面都有体现。 堆与栈的分离，使得堆中的内容可以被多个栈共享。这种共享有很多好处，一方面提供了一种有效的数据交互方式（如内存共享），另一方面，节省了内存空间。 栈因为运行时的需要（如保存系统运行的上下文），需要进行址段的划分。由于栈只能向上增长，因此会限制住栈存储内容的能力。而堆不同，堆的大小可以根据需要动态增长。因此，堆与栈的分离，使得动态增长成为可能，相应栈中只需要记录堆中的一个地址即可。 堆和栈的完美结合就是面向对象的一个实例。其实，面向对象的程序与以前结构化的程序在执行上没有任何区别，但是面向对象的引入使得对待问题的思考方式发生了改变，是更接近于自然的思考方式。当把对象拆开会发现，对象的属性其实就是数据，存放在堆中，而对象的方法就是处理逻辑，存放在栈中。我们编写对象的时候，其实即编写了数据结构，也编写了处理数据的逻辑。 总结：栈主要用来执行程序，堆主要用来存放对象，为栈提供数据存储服务。也正是因为堆与栈分离的思想才使得JVM的垃圾回收成为可能。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"JVM","slug":"学习笔记/Java/JVM","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://wangminrui.github.io/tags/JVM/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://wangminrui.github.io/tags/读书笔记/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"http://wangminrui.github.io/tags/《深入理解Java虚拟机》/"}]},{"title":"Java中的内存泄漏和内存溢出","slug":"Java中的内存泄漏和内存溢出","date":"2019-03-23T02:26:51.000Z","updated":"2019-07-25T12:07:15.190Z","comments":true,"path":"2019/03/23/Java中的内存泄漏和内存溢出/","link":"","permalink":"http://wangminrui.github.io/2019/03/23/Java中的内存泄漏和内存溢出/","excerpt":"什么是内存溢出以及java中内存泄漏5种情况的总结 内存泄漏：没有及时清理内存垃圾，导致系统无法给你提供内存资源（一个不再被程序使用的对象或变量还在内存中占有存储空间内存资源耗尽）（内存使用完毕后，不能释放回收重新使用，如死循环）。内存泄漏是指你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。就相当于你租了个带钥匙的柜子，你存完东西之后把柜子锁上之后，把钥匙丢了或者没有将钥匙还回去，那么结果就是这个柜子将无法供给任何人使用，也无法被垃圾回收器回收，因为找不到他的任何信息。 内存溢出：你要求的内存资源超出了系统能给的，系统不能满足需求，导致内存溢出。（类似于数组越界，超出你能存储数据的上限）","text":"什么是内存溢出以及java中内存泄漏5种情况的总结 内存泄漏：没有及时清理内存垃圾，导致系统无法给你提供内存资源（一个不再被程序使用的对象或变量还在内存中占有存储空间内存资源耗尽）（内存使用完毕后，不能释放回收重新使用，如死循环）。内存泄漏是指你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。就相当于你租了个带钥匙的柜子，你存完东西之后把柜子锁上之后，把钥匙丢了或者没有将钥匙还回去，那么结果就是这个柜子将无法供给任何人使用，也无法被垃圾回收器回收，因为找不到他的任何信息。 内存溢出：你要求的内存资源超出了系统能给的，系统不能满足需求，导致内存溢出。（类似于数组越界，超出你能存储数据的上限） Java的内存管理：Java内存管理就是对象的分配和释放问题。对象的分配是由程序完成的，对象的释放则是由垃圾回收器（GC）完成的，程序员不需要调用函数去释放内存，但GC只能回收无用并且不会再被其他对象引用的对象所占用的空间。 GC为了能够正确的释放对象，必须监控每一个对象的运行状态，释放对象的根本原则就是该对象不会在被引用。 内存泄漏与内存溢出的异同：内存泄露是内存溢出的原因之一；内存泄漏累积起来就会导致内存溢出。内存泄漏可以通过完善代码来避免；内存溢出可以通过调整配置来减少发生频率，但无法完全避免。 如何避免内存泄漏和内存溢出： 尽早释放无用对象的引用（使用临时变量） 程序使用字符串时，尽量避免使用String,而应使用StringBuilder或StringBuffer 少使用静态变量，静态变量是全局的，GC不会回收。（静态变量存放在方法区，永久代） 不要在调用的方法中创建对象，尤其不要在循环中创建对象。 内存泄漏的五种原因： 静态集合类 如HashMap、LinkedList等 如果这些容器为静态的，那么他们的生命周期与程序一致，在程序结束之前不能被释放 简单来说，就是长生命周期的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但却因为长生命周期的对象持有它的引用而导致不能被回收 各种连接 如数据库连接、网络连接和IO连接 在连接不再使用时，需要调用close()方法来释放连接，只有连接close了，垃圾回收器才会回收其对象 变量不合理的作用域 一个变量定义的作用范围大于其使用范围 没有及时地把对象设置为null（对象设置为null之后，垃圾回收器也会对它进行回收） 内部类持有外部类 如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象将不会被回收 改变哈希值 当一个对象存储进HashSet集合中后，就不能修改这个对象中那些参与计算哈希值的字段了，否则，修改后的哈希值与最初存储进HashSet的哈希值就不同了，这种情况下，无法再在HashSet集合重单独删除当前对象，从而造成内存泄漏","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://wangminrui.github.io/tags/Java基础/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"http://wangminrui.github.io/tags/内存泄漏/"},{"name":"内存溢出","slug":"内存溢出","permalink":"http://wangminrui.github.io/tags/内存溢出/"}]},{"title":"JVM：概述","slug":"JVM-1","date":"2019-03-21T14:56:48.000Z","updated":"2019-07-30T06:01:19.277Z","comments":true,"path":"2019/03/21/JVM-1/","link":"","permalink":"http://wangminrui.github.io/2019/03/21/JVM-1/","excerpt":"","text":"","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"JVM","slug":"学习笔记/Java/JVM","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://wangminrui.github.io/tags/JVM/"},{"name":"待整理","slug":"待整理","permalink":"http://wangminrui.github.io/tags/待整理/"}]},{"title":"数据结构：堆","slug":"数据结构-3","date":"2019-03-16T15:22:57.000Z","updated":"2019-08-01T06:08:39.704Z","comments":true,"path":"2019/03/16/数据结构-3/","link":"","permalink":"http://wangminrui.github.io/2019/03/16/数据结构-3/","excerpt":"","text":"1. 堆简介堆是一种优先序列，是一种特别的树状数据结构，但实际上就是一棵完全二叉树。 堆要求其任意节点都必须小于等于（或大于等于）其父节点。 如果是“小于等于”，这个堆是小顶堆如果是”大于等于“，这个堆是大顶堆 2. 堆的建立堆是一个用数组存储的完全二叉树，第i个结点的左孩子下标是2*i+1，右孩子下标是2*i+2，堆有两种建立方式，分别有不同的时间复杂度。 2.1 自顶向下的建堆从根节点开始插入，每插入一次，调整一次堆，确保是大顶堆/小顶堆每次插入都是把结点放在数组的最后，堆的高度为$\\lfloor log_2(n+1) \\rfloor$，第k层结点数为$2^k$，第$k$层结点需要比较的次数为$k$ 时间复杂度：$O(nlogn)$ 2.2 自底向上的建堆这应该是常用的建堆操作，但前提是所有数据已经插入数组中 从第一个非叶子结点开始判断该子树是否满足建堆的性质，如果满足就判断下一个点；否则交换当前结点和子节点，依次递归。 时间复杂度：$O(n)$ 为什么时间复杂度是$O(n)$而不是$O(nlogn)$建堆的时间复杂度应该由一个外层循环n乘以内层调整堆的比较次数logn，但因为这是自底向上的建堆方式，因此每次调整堆的比较次数肯定是小于logn的，因此，该问题是叠加问题，而不是递归问题。而自上而下的建堆，每个插入的节点都与二叉树的深度有关，且都是不断的把树折半来实现插入，因此是典型的递归，而非叠加。详细证明 3. 堆的基本操作3.1 堆的插入 假设堆要插入元素T，新插入的元素放在数组尾部，然后自底向上比较元素T和它的父节点大小是否符合当前堆的性质（小顶堆要求数值比父节点大，大顶堆要求数值比父节点小），如果不符合则交换，直到符合堆的性质，或元素T已经是根节点。 eg： 每一次插入，将数据插入数组尾部。如图，数组为[10, 7, 2, 5, 1] 如果插入元素16，数组变为[10, 7, 2, 5, 1, 16]，堆结构如图 然后自底向上，与父节点比较，由于这是一个大顶堆，16&gt;2，因此16和2交换 和2交换后，16依然比他的父元素10大，因此交换16和10。重复比较操作，直到插入元素的父节点比它大，或它已经是堆顶元素 3.2 堆顶元素的删除 删除堆顶元素后，把最后一个元素L的值赋给根结点，然后自顶向下比较元素L和它的左右孩子大小是否符合当前堆的性质（小顶堆要求数值比孩子节点小，大顶堆要求数值比孩子节点大），如果不符合则交换，直到符合堆的性质，或元素L已经是叶子节点。调整时，注意比较被交换为父节点的元素与另一个孩子节点的大小关系是否需要交换。 eg： 删除堆顶元素10后，如图 把数组中的最后一个元素1赋给根节点 但此时的堆已经不符合堆的性质了，因此要进行一次自顶向下的调整。比较元素1和它的子节点大小，由于这是一个大顶堆，1&lt;7，因此交换1和7 交换1和7后，1的位置仍然不符合堆的性质，因此，交换1和5，直到元素1的位置符合堆的性质，或者它已经是叶子节点。在调整过程中，要注意被交换为父节点的元素与右孩子的关系是否符合堆的性质 3.3 普通堆元素的删除一般操作情况下，堆只进行堆顶元素的删除。 如果删除堆中间的元素，操作和删除堆顶元素也很相似，也是讲最后一个元素赋值给被删除的那个节点，然后自顶向下地调整堆。 4. 堆和树的区别既然堆是一个完全二叉树，直接用完全二叉树（二叉搜索树或其他树）解决问题不就好了吗，为什么还会有堆的出现？ 应用的区别：堆的主要目的是得到堆顶元素（即集合中最大/小的元素），从而快速地进行插入、删除操作；二叉树的主要目的是进行搜索，在堆中搜索效率不高。 堆的建树规则更加简单：在堆中，只需要保证父节点比子节点大（或小）的规则就行；但在二叉搜索树中规则更加严格，左子节点必须比父节点小，右子节点必须必比父节点大。 堆不需要分配指针的内存：普通树占用的内存空间比它们存储的数据要多。你必须为节点对象以及左/右子节点指针分配额为是我内存。堆仅仅使用一个数组来存储数据，且不使用指针。 堆不需要平衡：二叉搜索树必须是“平衡”的情况下，其大部分操作的复杂度才能达到$O(log n)$。你可以按任意顺序位置插入/删除数据，或者使用 AVL 树或者红黑树，但是在堆中实际上不需要整棵树都是有序的。我们只需要满足对属性即可，所以在堆中平衡不是问题。因为堆中数据的组织方式可以保证$O(log n)$的性能。 5. 堆操作的时间复杂度来自维基百科) 操作 描述 时间复杂度 build 创建一个空堆 $O(n)$ insert 向堆中插入一个新元素 $O(logn)$ update 将新元素提升使其符合堆的性质 get 获取当前堆顶元素的值 $O(1)$ delete 删除堆顶元素 $O(logn)$ heapify 使删除堆顶元素的堆再次成为堆 6. 堆的应用 堆排序 海量数据的处理，查找topk元素，查找中位数等 优先队列：Linux内核中的调度器(scheduler)会按照各个进程的优先级来安排CPU执行哪一个进程。计算机中通常有多个进程，每个进程有不同的优先级(该优先级的计算会综合多个因素，比如进程所需要耗费的时间，进程已经等待的时间，用户的优先级，用户设定的进程优先程度等等)。内核会找到优先级最高的进程，并执行。如果有优先级更高的进程被提交，那么调度器会转而安排该进程运行。优先级比较低的进程则会等待。“堆”是实现调度器的理想数据结构。(Linux中可以使用nice命令来影响进程的优先级)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"数据结构","slug":"学习笔记/数据结构","permalink":"http://wangminrui.github.io/categories/学习笔记/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://wangminrui.github.io/tags/数据结构/"},{"name":"堆","slug":"堆","permalink":"http://wangminrui.github.io/tags/堆/"}]},{"title":"数据结构：散列表","slug":"数据结构-2","date":"2019-03-14T14:08:28.000Z","updated":"2019-07-31T03:11:59.067Z","comments":true,"path":"2019/03/14/数据结构-2/","link":"","permalink":"http://wangminrui.github.io/2019/03/14/数据结构-2/","excerpt":"","text":"1. 散列表简介散列表，又称哈希表、Hash表、Hashtable。 哈希表是一种映射关系，即给定一个数据元素，其关键字为key，按一个确定的散列函数（或称哈希函数）计算出hash(key)，把hash(key)作为关键字key对应元素的存储地址（或称散列地址），再进行数据元素的插入和检索操作。简单来说，就是找到数据内容和数据存放地址之间的映射关系。 散列表的插入：哈希函数把key转换成一个整型数字，这个整型数字就当作数组的下标，将value存储在以该数字为下标的数组空间里。散列表的查询：使用哈希函数将key转换为对应的数组下标，并定位到该空间获取value，如此一来，就可以充分利用到数组的定位性能进行数据定位。哈希函数应具备的特点：运算尽可能简单；函数的值域必须在散列表范围内；尽可能减少冲突。 散列表的查询速度非常快，几乎是$O(1)$的时间复杂度，因此常用于海量数据的处理。 散列表是具有固定大小的数组，虽然散列表是存储数据内容和数据存放地址的一种映射关系，但不能保证每个关键字与映射的函数值是意义对应的，极有可能出现不同的数据却计算出相同的函数值，此时就产生了哈希冲突。 2. 散列表的构建方法 直接寻址法 取模法 数字分析法 折叠法 平方取中法 除留余数法 随机数法 2.1 直接寻址法基本思想：取key或者key的线性函数值作为散列地址，即hash(key)=key或hash(key)=a*key+b 优点：不会产生哈希冲突（因为它没有压缩映像） 缺点：效率比较低，当关键字集合很大时，无法使用这种方法实现地址编码的散列 2.2 取模法基本思想：将取模操作作为散列函数，hash(key)=key mod p，其中p为正整数，一般情况下，p为散列表的长度 优点：p选择的是比较大的素数时，效果比较好（为什么？） 缺点：p取得不好时，容易产生哈希冲突 2.3 数字分析法基本思想：假设关键字是d为的以r为基的数（十进制数就是以10为基的数），共有n个关键字，则关键字的每个位可能由r个不同的数符出现（即0，1，2，…，9），但这r个数符在各个位出现的频率不一定相同，可能在某些位上分布比较均匀，即每个数符出现的次数接近n/r，而另一些位上分布不均匀。因此可选取其中分布比较均匀的那些位，重新组成新的数，用其作为散列地址 优点：简单直观 缺点：需要预先知道每个关键字的情况 2.4 折叠法基本思想：将关键字拆分为位数为t的几个部分（最后一部分的位数可能小于t），然后把各部分按位对齐进行相加，将所得和舍弃仅为，留下t位作为散列地址 优点：关键字位数很多，而且关键字中每位上数字分布比较均匀时，采用折叠法很合适 缺点：关键字位数少时不适合 2.5 平方取中法基本思想：将key进行平方运算，然后从结果的中间取出若干位（位数与散列地址的位数相同），将其作为散列地址，具体取几位，由散列表的表长决定 优点： 缺点： 2.6 除留余数法常见的散列函数 基本思想：将取余操作作为散列函数，hash(key) = key % p，p为正整数，p不大于散列表的长度。p一般选取质数，也可以是不包含小于20质因子的合数。 优点：简单 缺点： 取模和取余的区别 2.7 随机数法基本思想：使用一个随机函数作为哈希函数，hash(key)=random(key) 优点：关键字长度不相等时，采用这种方法比较合适（为什么？） 缺点： 3. 哈希冲突的解决方法哈希冲突指，在关键字key映射到散列表中某一个地址后，该地址已存放了另一个关键字 在构建散列表的过程中，不管使用什么构建方法，冲突都是不可能完全避免的。 解决冲突的主要途径是，为当前冲突的关键字寻找新的存储地址 3.1 开放地址法当发生冲突时，在散列表中再按照某种方法继续探测其他的存储地址，直到找到空闲地址为止。其具体过程为： 首先计算当前关键字的散列地址hash(key)，若该地址为空闲，则直接插入，若该地址已有其他的关键字，则继续查看地址为[hash(key) + d]的存储地址，判断其是否为空，如此反复，直到找到空闲的存储地址为止。 增量d可以有不同的取法，常用的有以下三种： d=1,2,3,…,m-1，称为线性探测再散列 d=12, -12, 22, -22, …, -k2(k &lt; m/2)，其中m为散列表长度，称为二次探测再散列 d=伪随机序列，称为伪随机再散列 3.2 链地址法使用数组+链表的思想，为每一个数组元素建立一个链表，如果发生冲突，将冲突元素插入链表末端。 这是Java中HashMap解决冲突的方法 3.3 再散列法当发生冲突时，使用第二个、第三个散列函数计算地址，直到无冲突为止。但计算时间会大幅增加 3.4 建立一个公共溢区在散列表存储空间以外，另外设立存储空间向量OverTable[0…v]，用以存储发生冲突的记录","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"数据结构","slug":"学习笔记/数据结构","permalink":"http://wangminrui.github.io/categories/学习笔记/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://wangminrui.github.io/tags/数据结构/"},{"name":"散列表","slug":"散列表","permalink":"http://wangminrui.github.io/tags/散列表/"}]},{"title":"取模运算和取余运算的不同","slug":"取模运算和取余运算的不同","date":"2019-03-14T02:20:52.000Z","updated":"2019-07-31T03:29:55.078Z","comments":true,"path":"2019/03/14/取模运算和取余运算的不同/","link":"","permalink":"http://wangminrui.github.io/2019/03/14/取模运算和取余运算的不同/","excerpt":"","text":"取模运算 r = a\\mod b取余运算 r = a \\% b如果$a$和$b$同符号，取模运算和取余运算结果是相等的；如果$a$和$b$不同符号，取模运算和取余运算结果是不相等的；求模运算结果的符号和b一致，求余运算结果的符号和a一致。 对于整型数a，b来说，取模运算或者取余运算的方法都是： 求整数商： $c = a/b$ 计算模或者余数：$ r = a - c*b$ 取模运算和求余运算在第一步不同: 取余运算在取c的值时，向0 方向舍入； 取模运算在计算c的值时，向负无穷方向舍入。 eg: a = -7；b = 4；计算 $a\\%b$，$a\\mod b$ 第一步：求整数商c，如进行求模运算c = -2（向负无穷方向舍入），求余c = -1（向0方向舍入）； 第二步：计算模和余数的公式相同，但因c的值不同，求模时r = 1，求余时r = -3。 eg: a = 7；b = -4；计算 $a\\%b$，$a\\mod b$ 第一步：求整数商c，如进行求模运算c = -2（向负无穷方向舍入），求余c = -1（向0方向舍入）； 第二步：计算模和余数的公式相同，但因c的值不同，求模时r = 7-8=-1，求余时r=7-4 = 3。 各个环境下%运算符的含义不同，比如c/c++，java 为取余，而python则为取模。","categories":[],"tags":[{"name":"疑惑辣么多","slug":"疑惑辣么多","permalink":"http://wangminrui.github.io/tags/疑惑辣么多/"}]},{"title":"数据结构：二叉树","slug":"数据结构-1","date":"2019-03-12T08:09:53.000Z","updated":"2019-07-30T14:12:13.565Z","comments":true,"path":"2019/03/12/数据结构-1/","link":"","permalink":"http://wangminrui.github.io/2019/03/12/数据结构-1/","excerpt":"","text":"二叉树的计算 $\\lfloor \\rfloor$表示向下取整 如果一棵满二叉树的高度为h，那么其节点数n为多少？ n=2^0+2^1+...+2^{h-1} \\\\ n=1\\cdot\\frac{1-2^h}{1-2}=2^h-1 如果一棵完全二叉树的高度为h，那么其节点数n为多少？ n_{min}=2^0+2^1+...+2^{h-2}+1=2^{h-1} \\\\ n_{max}=2^h-1 如果一棵满二叉树的节点数为n，那么其高度h为多少？ n=2^h-1 \\\\ h=log_2(n+1) 如果一棵完全二叉树的节点数为n，那么其高度h为多少？ 2^{h-1} - 1 < n \\leq 2^h-1 \\\\ log_2(n+1) +1","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"数据结构","slug":"学习笔记/数据结构","permalink":"http://wangminrui.github.io/categories/学习笔记/数据结构/"},{"name":"树","slug":"学习笔记/数据结构/树","permalink":"http://wangminrui.github.io/categories/学习笔记/数据结构/树/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://wangminrui.github.io/tags/数据结构/"},{"name":"树","slug":"树","permalink":"http://wangminrui.github.io/tags/树/"},{"name":"二叉树","slug":"二叉树","permalink":"http://wangminrui.github.io/tags/二叉树/"}]},{"title":"排序算法总结","slug":"排序算法总结","date":"2019-03-11T02:28:12.000Z","updated":"2019-07-30T06:24:57.672Z","comments":true,"path":"2019/03/11/排序算法总结/","link":"","permalink":"http://wangminrui.github.io/2019/03/11/排序算法总结/","excerpt":"总结 图片名词解释：n: 数据规模k: k个元素/“桶”的个数/关键字个数In-place: 占用常数内存，不占用额外内存Out-place: 占用额外内存稳定性：对于待排序列中相同项的原来次序不能被算法改变则称该算法稳定","text":"总结 图片名词解释：n: 数据规模k: k个元素/“桶”的个数/关键字个数In-place: 占用常数内存，不占用额外内存Out-place: 占用额外内存稳定性：对于待排序列中相同项的原来次序不能被算法改变则称该算法稳定 冒泡排序基本思想： 通过与相邻元素的比较和交换来把大的数交换到最后面。这个过程类似于水泡向上升一样 eg:5 3 8 6 43 5 8 6 43 5 8 6 43 5 6 8 43 5 6 4 8第一遍排序结果：3 5 6 4 8 3 5 6 4 83 5 6 4 83 5 4 6 83 5 4 6 8第二遍排序结果：3 5 4 6 8 3 5 4 6 83 4 5 6 83 4 5 6 83 4 5 6 8第三遍排序结果：3 4 5 6 8 3 4 5 6 83 4 5 6 83 4 5 6 83 4 5 6 8第四遍排序结果：3 4 5 6 8 123456789101112// 升序int[] arr = &#123;5, 3, 8, 6, 4&#125;;int n = arr.length;for (int i = 0; i &lt; n - 1; i++)&#123; for (int j = 0; j &lt; n - i - 1; j++)&#123; if (arr[j] &gt; arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125;&#125; 平均时间复杂度：$O(n^2)$最好情况：$O(n)$ 需要另外写一个方法判断当前循环有没有交换，如果没有证明排序结束最坏情况：$O(n^2)$空间复杂度：$O(1)$排序方式：In-place稳定性：稳定 选择排序基本思想： 每次选择最小的数交换放在最前面eg:5 3 8 6 4 3 5 8 6 43 4 8 6 53 4 5 6 83 4 5 6 8 12345678910// 升序void selectSort(int[] arr)&#123; int n = arr.length; for (int i = 0; i &lt; n - 1; i++)&#123; int min = i; for (int j = i + 1; j &lt; n; j++)&#123; if (arr[min] &gt; arr[j]) min = j; &#125; swap(arr, min, i);&#125; 平均时间复杂度：$O(n^2)$最好情况：$O(n^2)$ 因为就算是有序的，内层循环还是必须循环完所有元素才确定最小的那个值最坏情况：$O(n^2)$空间复杂度：$O(1)$排序方式：In-place稳定性：不稳定 例如:(7) 2 5 9 3 4 [7] 1…选择算法进行排序时候,(7)和1调换,(7)就跑到了[7]的后面了 直接插入排序基本思想： 假设第一个数位置正确，遍历后面的数，插入到正确位置 eg:5 3 8 6 4 &nbsp; &nbsp;5 3 8 6 43 3 5 8 6 48 3 5 8 6 46 3 5 6 8 44 3 4 5 6 8 1234567891011// 升序void insertSort(int[] arr)&#123; for (int i = 1; i &lt; arr.length; i++)&#123; int swapIndex = i-1; int cur = arr[i]; while (swapIndex &gt;= 0 &amp;&amp; arr[swapIndex] &gt; cur)&#123; arr[swapIndex+1] = arr[swapIndex--]; &#125; arr[swapIndex+1] = cur; &#125;&#125; 平均时间复杂度：$O(n^2)$最好情况：$O(n)$ 当序列本身有序，内层循环不需要进行最坏情况：$O(n^2)$ 序列倒序，内层循环需要全部进行空间复杂度：$O(1)$排序方式：In-place稳定性：稳定 希尔排序/缩小增量排序基本思想：先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。 123456789101112131415161718192021//升序void shellSort(int[] arr)&#123; int len = arr.length; int gap = len/2; while (gap &gt; 0)&#123; for (int j = 0; j &lt; gap; j++)&#123; //插入排序 for (int i = j+gap; i &lt; len; i+=gap)&#123; int swapIndex = i-gap; int cur = arr[i]; while(swapIndex &gt;= 0 &amp;&amp; arr[swapIndex] &gt; cur)&#123; arr[swapIndex+gap] = arr[swapIndex]; swapIndex -= gap; &#125; arr[swapIndex+gap] = cur; &#125; &#125; gap /= 2; &#125;&#125; 网上说法好像不一致，证明非常复杂平均时间复杂度：$O(n^{1.5})$最好情况：$O(nlog^2n)$最坏情况：$O(n^2)$空间复杂度：$O(1)$排序方式：In-place稳定性：不稳定 在不同的插入排序子过程中，顺序有可能被打乱 归并排序基本思想： 划分为多个子序列，对子序列进行排序，然后归并子序列（分而治之的思想）eg:49 38 65 97 76 13 27 [49 38] [65 97] [76 13] [27][38 49] [65 97] [13 76] [27][38 49 65 97] [13 27 76][13 27 38 49 65 76 97] 12345678910111213141516171819202122232425262728293031323334// 升序 plan1private int[] merge(int[] left, int[] right) &#123; int len = left.length + right.length; int lenLeft = left.length; int lenRight = right.length; int[] res = new int[left.length + right.length]; int i = 0; int iLeft = 0; int iRight = 0; while (i &lt; len) &#123; if (iLeft &gt;= lenLeft) &#123; res[i++] = right[iRight++]; continue; &#125; if (iRight &gt;= lenRight) &#123; res[i++] = left[iLeft++]; continue; &#125; if (left[iLeft] &gt; right[iRight]) res[i++] = right[iRight++]; else res[i++] = left[iLeft++]; &#125; return res;&#125; private int[] recursion(int[] arr) &#123; if (arr.length &lt; 3) return merge(Arrays.copyOfRange(arr, 0, arr.length / 2), Arrays.copyOfRange(arr, arr.length / 2, arr.length)); else return merge(recursion(Arrays.copyOfRange(arr, 0, arr.length / 2)), recursion(Arrays.copyOfRange(arr, arr.length / 2, arr.length)));&#125; 12345678910111213141516171819202122232425262728293031// 升序 plan2void mergeSort(int[] arr, int left, int right)&#123; if (right - left &lt; 1) return; int mid = (right - left)/2; mergeSort(arr, left, mid+left); //对左半边进行归并排序 mergeSort(arr, mid+left+1, right); //对右半边进行归并排序 merge(arr, left, left+mid, right); //将左右半边的排序结果合并起来&#125;void merge(int[] arr, int left, int mid, int right)&#123; int len = right-left+1; int index = 0; int leftIndex = left; int rightIndex = mid+1; int[] res = new int[len]; //较小的移到新数组 while (leftIndex &lt;=mid &amp;&amp; rightIndex &lt;= right) &#123; if (arr[leftIndex] &lt; arr[rightIndex]) res[index++] = arr[leftIndex++]; else res[index++] = arr[rightIndex++]; &#125; //左半边剩余移到新数组 while(leftIndex &lt;= mid) res[index++] = arr[leftIndex++]; //右半边剩余移到新数组 while(rightIndex &lt;= right) res[index++] = arr[rightIndex++]; for (int i = 0; i &lt; len; i++) arr[left+i] = res[i];&#125; 平均时间复杂度：$O(nlogn)$ 和快排类似，递归树的思想最好情况：$O(nlogn)$最差情况：$O(nlogn)$空间复杂度：$O(n)$ 每次递归需要用到一个辅助表，长度于待排序的表相等，虽然递归次数是$O(log_2n)$，但是每次递归都会释放掉所占用的辅助空间，所以下次递归的栈空间的辅助空间于这部分释放的空间就无关了，因而空间复杂度还是$O(n)$排序方式：Out-place 需要占用额外空间稳定性：稳定 快速排序快速排序原理 基本思想： 选定一个数为基准（一般是第一个数），所有比它小的数挪到它左边，比它大的数挪到它右边。做法：设定两个指针，low指向第一个数，high指向最后一个数。先从high开始比较，如果比基准数大，high—，如果比基准数小，交换基准数和arr[high]的位置。然后从low开始比较，如果比基准数小low++，如果比基准数大，交换基准数和arr[low]的位置。重复以上过程，直到low和high相遇，这样基准数左边的数一定比它小，右边的数一定比它大。再分别对左边和右边的数组进行快速排序，最终得到结果。 为什么一定是从high开始比较？？例子：6 1 2 7 9如果从左边开始，最后6和7会交换位置，这是错误的。因为如果从左边开始比较，遇到比基准数大的一定会换位置，但基准数的初始位置是最左边的，如果交换位置，就出现了左边的数比基准数大的情况，这是错误的所以，必须从右边开始，也就是基准数的对面开始比较 123456789101112131415161718// 升序void quickSort(int[] arr, int begin, int end)&#123; if (begin &gt; end) return; int low = begin; int high = end; int key = arr[begin]; while (low &lt; high)&#123; //先不交换key while(low &lt; high &amp;&amp; key &lt;= arr[high]) high--; while(low &lt; high &amp;&amp; key &gt;= arr[low]) low++; if (low &lt; high) &#123; swap(arr, low, high); &#125; &#125; arr[begin] = arr[low]; arr[low] = key; //最后交换key quickSort(arr, begin, high-1); quickSort(arr, high+1, end);&#125; 平均时间复杂度：$O(nlogn)$最好情况：$O(nlogn)$最坏情况：$O(n^2)$空间复杂度：$O(logn)$排序方式：In-place稳定性：不稳定 快速排序复杂度的分析： 最优情况下，每一次partition都划分地很均匀，如果排序n个关键字，其递归树的深度为$\\lfloor log_2(n+1)\\rfloor$，即仅需递归$\\lfloor log_2n\\rfloor$ 次，需要时间为T（n）的话，第一次partition应该是需要对整个数组扫描一遍，做n次比较。然后，获得的key将数组一分为二，那么各自还需要T（n/2）的时间（注意是最好情况，所以平分两半）。于是不断地划分下去，就有了下面的不等式推断： 因此，最优情况下，快排的时间复杂度为$O(nlogn)$。 最坏情况下，待排序序列为正序或逆序排列时，每次划分只得到一个比上一次划分少一个记录的子序列，另一个为空，此时的递归树是一个斜树，需要执行n-1次递归调用，且第i次划分需要经过n-i次关键字的比较才可以找到第i条记录，也就是key的位置，因此比较次数为$\\sum^{n-1}_{i=1}(n-i)=n-1+n-2+…+1=\\frac{n(n-1)}{2}$。因此，最坏情况下，快排的时间复杂度为$O(n^2)$。 一般情况下，假设key的位置再第k个位置（$1\\leq k \\leq n$），那么 T(n)=\\frac{1}{n}\\sum^n_{k=1}(T(k-1)+T(n-k))+n=\\frac{2}{n}T(k)+n数学归纳法可证明，其平均情况下，快排的数量级为$O(nlogn)$具体证明参照《算法导论》7.4节 就空间复杂度来说，快排的空间复杂度主要是递归造成的栈空间的使用，最好的情况，递归树的深度为$log_2n$，其空间复杂度为$O(logn)$，最坏情况需要进行n-1次调用，其空间复杂度为$O(n)$，平均情况下空间复杂度也为$O(logn)$ 堆排序图解堆排序基本思想：将待排序数组构建为一个堆，堆用完全二叉树实现，从下到上调整堆，调整规则为：每一个父节点都大于等于所有子节点的值。每调整完一次，根节点就是待排序数组中最大的值，将其与数组末尾元素交换，然后剩余元素重新构造一个堆 基本思路：a.将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆（升序选择小顶堆，降序选择大顶堆）; b.将堆顶元素与末尾元素交换，将最大/小元素”沉”到数组末端; c.重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序。 堆可以看作一个完全二叉树，用数组存储，第一个非叶子节点为arr.length/2-1，假设父节点为arr[i]，则左子节点为arr[2*i+1]，右子节点为arr[2*i+2]。堆的调整从第一个非叶子节点开始，比较其和子节点大小，如果子节点比父节点大，则交换位置。直到比较到根节点，此时根节点就是排序数组中的最大值，将其于数组末尾元素交换，然后重新调整堆，一共调整arr.length次。 1234567891011//升序void heapSort(int[] arr)&#123; int cnt = arr.length; while (cnt &gt; 0)&#123; for(int i = cnt/2-1; i &gt;= 0; i--)&#123; if (2*i+1&lt;cnt &amp;&amp; arr[i] &lt; arr[2*i+1]) swap(arr, i, 2*i+1); if (2*i+2&lt;cnt &amp;&amp; arr[i] &lt; arr[2*i+2]) swap(arr, i, 2*i+2); &#125; swap(arr, 0, cnt---1); &#125;&#125; 平均时间复杂度：$O(nlogn)$ 建堆后树的高度为logn，需要循环n-1次最好情况：$O(nlogn)$最差情况：$O(nlogn)$空间复杂度：$O(1)$排序方式：In-place稳定性：不稳定 计数排序基本思想：使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数 1234567891011121314151617181920void countSort(int[] arr)&#123; int max = -1; for (int i = 0; i &lt; arr.length; i++)&#123; //找出最大的数 if (max &lt; arr[i]) max = arr[i]; &#125; int[] countArr = new int[max+1]; //建立max长度的数组 for (int i = 0; i &lt; arr.length; i++)&#123; countArr[arr[i]] += 1; &#125; int index = 0; int cntIndex = 0; while(index &lt; arr.length)&#123; int count = countArr[cntIndex]; while (count &gt; 0)&#123; arr[index++] = cntIndex; count--; &#125; cntIndex++; &#125;&#125; k代表，输入的元素是0~k之间的整数平均时间复杂度：$O(n+k)$最好情况：$O(n+k)$最差情况：$O(n+k)$空间复杂度：$O(k)$排序方式：Out-place 占用了额外的存储空间稳定性：稳定 桶排序基本思想：利用映射函数将数据映射到某个桶中，然后用先进的排序算法对桶内元素进行排序。（映射函数如：f(k) = k/10) 123456789101112131415161718192021222324252627List&lt;Integer&gt; bucketSort(List&lt;Integer&gt; arr, int bucketSize) &#123; if (arr.size() &lt; 2) return new ArrayList&lt;&gt;(); int max = arr.get(0), min = arr.get(0); //找到最大值和最小值 for (int i : arr) &#123; if (max &lt; i) max = i; if (min &gt; i) min = i; &#125; int bucketCount = (max - min) / bucketSize + 1; //计算桶的个数 List&lt;List&lt;Integer&gt;&gt; bucketList = new ArrayList&lt;&gt;(); List&lt;Integer&gt; resList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketCount; i++) &#123; bucketList.add(new ArrayList&lt;Integer&gt;()); &#125; for (int i = 0; i &lt; arr.size(); i++) &#123; bucketList.get((arr.get(i) - min) / bucketSize).add(arr.get(i)); //向桶中添加元素 &#125; for (int i = 0; i &lt; bucketCount; i++) &#123; if (bucketCount == 1) bucketSize--; List&lt;Integer&gt; tempArr = bucketSort(bucketList.get(i), bucketSize); //对每个桶进行排序 for (int j = 0; j &lt; tempArr.size(); j++) &#123; resList.add(tempArr.get(j)); &#125; &#125; return resList; &#125; k代表，桶个数平均时间复杂度：$O(n+k)$最好情况：$O(n+k)$最差情况：$O(n^2)$空间复杂度：$O(n+k)$排序方式：Out-place 占用了额外的存储空间稳定性：稳定 基数排序基本思想：多关键字排序（比如，先比较个位数，再比较十位数，再比较百位数） 12345678910111213141516171819202122232425262728293031void radixSort(int[] arr)&#123; int max = Integer.MIN_VALUE; for (int i : arr) if (max &lt; i) max = i; int digit = 0; //最大数的位数 while (max &gt; 0)&#123; max /= 10; digit++; &#125; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketList = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); for (int i = 0; i &lt; 10; i++)&#123; //10个桶，代表0~9十个数字 bucketList.add(new ArrayList&lt;Integer&gt;()); &#125; for (int k = 1; k &lt;= digit; k++)&#123; //针对每个关键字排序（即每一位） for (int i = 0; i &lt; arr.length; i++)&#123; int bucket = arr[i]; for (int x = 1; x &lt; k; x++) bucket /= 10; bucket %= 10; bucketList.get(bucket).add(arr[i]); //放入对应桶中 &#125; int index = 0; for (int i = 0; i &lt; 10; i++)&#123; for (int j = 0; j &lt; bucketList.get(i).size(); j++)&#123; arr[index++] = bucketList.get(i).get(j); //根据当前关键字对数组排序 &#125; bucketList.get(i).clear(); &#125; &#125; &#125; k代表，关键字个数平均时间复杂度：$O(n\\times k)$最好情况：$O(n\\times k)$最差情况：$O(n\\times k)$空间复杂度：$O(n+k)$ 不知道为什么是这个数，网上说法不一，但维基百科是这个数字排序方式：Out-place 占用了额外的存储空间稳定性：稳定 基数排序、桶排序、计数排序的区别基数排序：根据键值的每位数字来分配桶 计数排序：每个桶之存储单一键值 桶排序：每个桶存储一定范围的数值","categories":[{"name":"算法编程","slug":"算法编程","permalink":"http://wangminrui.github.io/categories/算法编程/"},{"name":"排序算法","slug":"算法编程/排序算法","permalink":"http://wangminrui.github.io/categories/算法编程/排序算法/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://wangminrui.github.io/tags/排序算法/"}]},{"title":"offer收割攻略","slug":"offer收割攻略","date":"2019-02-27T03:24:22.000Z","updated":"2019-07-31T01:22:22.511Z","comments":true,"path":"2019/02/27/offer收割攻略/","link":"","permalink":"http://wangminrui.github.io/2019/02/27/offer收割攻略/","excerpt":"","text":"1. Java1.1 Java基础1.2 多线程高并发1.3 Java框架1.4 Java82. 数据库3. 计算机网络4. 操作系统5. 数据结构5.1 数组5.2 散列表5.3 栈5.4 队列5.5 链表5.6 树5.6.1 霍夫曼树5.6.2 二叉树5.6.2.1 二叉树的建立、插入、删除节点5.6.2.2 二叉搜索树 BST5.6.3 红黑树5.6.4 2-3树5.6.5 B树5.6.6 B+树6. 算法6.1 排序算法7. 开放题","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"offer收割攻略","slug":"学习笔记/offer收割攻略","permalink":"http://wangminrui.github.io/categories/学习笔记/offer收割攻略/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://wangminrui.github.io/tags/面试/"}]},{"title":"PyTorch入门","slug":"PyTorch(一)：PyTorch入门","date":"2019-01-31T01:27:35.000Z","updated":"2019-07-30T03:10:07.601Z","comments":true,"path":"2019/01/31/PyTorch(一)：PyTorch入门/","link":"","permalink":"http://wangminrui.github.io/2019/01/31/PyTorch(一)：PyTorch入门/","excerpt":"PyTorch入门教程 1. PyTorh张量张量只是多维数组。PyTorch中的张量类似于numpy的ndarrays，另外，张量也可以在GPU上使用。PyTorch支持各种类型的张量。 12import torchtorch.FloatTensor([2]) # 定义一个一维矩阵的张量 2. 数学运算123456789# 基本运算a = torch.FloatTensor([2])b = torch.FloatTensor([3])a+b# 矩阵运算matrix = torch.randn(3,3)matrixmatrix.t() # 查看","text":"PyTorch入门教程 1. PyTorh张量张量只是多维数组。PyTorch中的张量类似于numpy的ndarrays，另外，张量也可以在GPU上使用。PyTorch支持各种类型的张量。 12import torchtorch.FloatTensor([2]) # 定义一个一维矩阵的张量 2. 数学运算123456789# 基本运算a = torch.FloatTensor([2])b = torch.FloatTensor([3])a+b# 矩阵运算matrix = torch.randn(3,3)matrixmatrix.t() # 查看 3. Autograd模块PyTorch使用了一种叫做自动微分的技术。也就是说，它会有一个记录我们所有执行操作的记录器，之后再回放记录来计算我们的梯度。这一技术在构建神经网络时尤其有效，因为我们可以通过计算前路参数的微分来节省时间。 1234form torch.autograd import Variablex = Variable(train_x)y = Variable(train_y, requires_grad=False) 4. Optim模块Torch.optim是一个实现各种优化算法的模块，用于构建神经网络。它支持大多数常用的方法，因此我们不必从头开始构建它们。 1optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) 5. 神经网络模块虽然PyTorch Autograd可以很容易的定义计算图形和使用梯度，但是对于定义复杂的神经网络来说可能有点太低级了。而这就需要神经网络模块来提供帮助。 nn包定义了一组模块，我们可以把它看作是一个神经网络层，它产生输入输出，并且可能有一些可训练的权重。 可以把nn模块看作是PyTorch的内核! 123456789import torch# define modelmodel = torch.nn.Sequential(torch.nn.linear(input_num_units, hiddnen_num_units),torch.nn.ReLU(),torch.nn.Linear(hidden_num_units, output_num_units),)loss_fn = torch.nn.CrossEntropyLoss()","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"深度学习","slug":"学习笔记/深度学习","permalink":"http://wangminrui.github.io/categories/学习笔记/深度学习/"}],"tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://wangminrui.github.io/tags/PyTorch/"}]},{"title":"PyTorch常用语法","slug":"PyTorch常用语法","date":"2019-01-30T01:49:16.000Z","updated":"2019-07-30T03:09:49.812Z","comments":true,"path":"2019/01/30/PyTorch常用语法/","link":"","permalink":"http://wangminrui.github.io/2019/01/30/PyTorch常用语法/","excerpt":"pytorch常用语法 1. 张量操作1.1 张量创建12345678910x = torch.empty(5, 3 , dtype = torch.uint8)x = torch.ones(5, 3 , dtype = torch.float64)x = torch.rand(5, 3 , dtype = torch.float32, requires_grad=True)x = torch.view(3,-1) # reshape x to (3,5)x = torch.randn(5, 3 , dtype = torch.long)x_copy = x.new_ones(5, 3 ,dtype = torch.double)x_same_size = torch.randn_like(x, dtype = torch.float)torch.arange(start, end, step=1, dtype=torch.int32)torch.full(size, fill_value)torch.normal(mean, std, out=None) #正态分布","text":"pytorch常用语法 1. 张量操作1.1 张量创建12345678910x = torch.empty(5, 3 , dtype = torch.uint8)x = torch.ones(5, 3 , dtype = torch.float64)x = torch.rand(5, 3 , dtype = torch.float32, requires_grad=True)x = torch.view(3,-1) # reshape x to (3,5)x = torch.randn(5, 3 , dtype = torch.long)x_copy = x.new_ones(5, 3 ,dtype = torch.double)x_same_size = torch.randn_like(x, dtype = torch.float)torch.arange(start, end, step=1, dtype=torch.int32)torch.full(size, fill_value)torch.normal(mean, std, out=None) #正态分布 1.2 类型转换123456789b = a.long() # torch.int64c = a.half() # torch.float16d = a.int() # torch.int32e = a.double() # torch.float64f = a.float() # torch.float32g = a.char() # torch.int8h = a.byte() # torch.uint8j = a.short() # torch.int16c = a.type_as(c) # 转化 a 的数据格式与 c 相同 1.3 张量信息查询12345print(x.size()) # print(x.shape)print(x.dtype) #tensor.uint8 tensor.float64 ....print(type(x))print(x[0][2].item())print(x[0][2]) 1.4 张量操作Pytorch常用函数解析（一） 12345torch.numel() # 返回一个tensor变量内的所有元素个数，可以理解为矩阵内的个数x = x.squeeze() # 对tensor变量进行维度压缩，去除一维x = x.unsqueeze(0) # 增加一维torch.stack(sequence, dim=0, out=None) # tensor拼接，sequence表示Tensor列表，dim表示拼接的维度，注意这个函数和concatenate是不同的，torch的concatenate函数（torch.cat）是在已有的维度上拼接，而stack是建立一个新的维度，然后新的维度上进行拼接b.expand_as(a) # 扩充a的维度，如果a的低纬度比b打，例如b.shape=[3,1]，如果a.shape=[3,2]不会出错，但是a.shape=[2,2]就会报错 1234567891011121314151617181920212223242526272829303132333435b = a.numpy() #numpy torch数据转换a = torch.form_numpy(b)# GPU设备中的运算if torch.cuda.is_available(): device = torch.device(\"cuda\") y = torch.ones_like(x,device= device) #直接从 GPU 创建张量 x = x.to(device) #将 CPU 中变量移动到 GPU 中 z = y + x # 求导相关x = torch.rand(5, 5, requires_grad=True)y = torch.rand(5, 5, requires_grad=True)z=torch.sum(x+y)z.backward(torch.ones_like(z))print(z.grad_fn)print(x.grad, y.grad)with torch.no_grad(): ...# 反向传播net.zero_grad() # 反向传播前，将所有参数的梯度清零out.backward(torch.ones(1,10))import torch.optimout = net(input) # 直接调用 forward 函数criterion = nn.MSELoss() # 损失函数 均方误差loss = criterion(out, y) # 计算 out 于 y 的均方误差# 新建优化器optimizer = torch.optim.SGD(net.parameters(),lr = 0.01, momentum=0.9) optimizer.zero_grad() # equal to : net.zero_grad()loss.backward() # 反向传播optimizer.step() # 更新参数 3. 构建网络3.1 优化器常见的优化器： SGM， RMSProp，Adam 1import torch.optim # 优化器库 3.2 网络层 卷积层 12345678self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)x = self.conv1(x)# parameters:# stride:(high,width) # padding:(high,width) high 上下各补0的行数，width 左右各补零的列数# groups: local convolution 局部卷积，然后拼起来，人脸识别常用到。 # eg. group=4 每个channel分成4份，各自卷积。默认为1 BatchNormal层 12self.bn1 = torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 池化层 ReLU层 存储，加载网络 12345678910# 方法一，仅保持模型参数（推荐）torch.save(the_model.state_dict(), PATH) # PATH, .pt or .pth# 加载the_model = TheModelClass(*args, **kwargs)the_model.load_state_dict(torch.load(PATH))# 方法二torch.save(the_model, PATH)# 加载the_model = torch.load(PATH) 4. 保存和读取模型pytorch保存模型等相关参数，利用torch.save()，以及读取保存之后的文件 假设网络为mode=Net()，optimizer=optim.Adam(model.parameters(), lr=args.lr)，假设在某个epoch，我们要保存模型参数、优化器参数及其epoch 4.1 保存模型参数 建立一个字典，保存三个参数： 1state=&#123;'net':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch&#125; 调用torch.save() 1torch.save(state, dir) # dir表示保存文件的绝对路径+保存文件名，如'/home/wangminrui/model.pt' 4.2 读取模型1234checkpoint = torch.load(dir)model.load_state_dict(checkpoint['net'])optimizer.load_state_dict(checkpoint['optimizer'])start_epoch = checkpoint['epoch'] + 1","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"深度学习","slug":"学习笔记/深度学习","permalink":"http://wangminrui.github.io/categories/学习笔记/深度学习/"}],"tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://wangminrui.github.io/tags/PyTorch/"}]},{"title":"Java基础：内部类和匿名类","slug":"Java基础-1","date":"2018-12-20T08:41:06.000Z","updated":"2019-07-30T05:57:09.034Z","comments":true,"path":"2018/12/20/Java基础-1/","link":"","permalink":"http://wangminrui.github.io/2018/12/20/Java基础-1/","excerpt":"","text":"1. 成员内部类 最普通的内部类，位于一个类的内部。成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员）如果内部类和外部类的变量或方法重名，默认让问内部类成员，如果需要访问外部类同名成员，用以下方法：12外部类.this.成员变量外部类.this.成员方法 外部类必须创建一个成员内部类的对象来访问成员内部类的变量和方法创造成员内部类的对象方法：12345678public static void main(String[] args) &#123; //第一种方式： Outter outter = new Outter(); Outter.Inner inner = outter.new Inner(); //必须通过Outter对象来创建 //第二种方式： Outter.Inner inner1 = outter.getInnerInstance(); &#125; Java内部类详解 用static关键字修饰类（只适用于内部类） 匿名内部类 匿名内部类详解 匿名内部类会隐式的继承一个类或者实现一个接口，或者说，匿名内部类是一个继承了该类或者实现了该接口的子类匿名对象。同时它也是没有class关键字，这是因为匿名内部类是直接使用new来生成一个对象的引用。当然这个引用是隐式的。 使用匿名内部类时，我们必须是继承一个类或者实现一个接口，但是两者不可兼得，同时也只能继承一个类或者实现一个接口。 匿名内部类中是不能定义构造函数的。 匿名内部类中不能存在任何的静态成员变量和静态方法。 匿名内部类为局部内部类，所以局部内部类的所有限制同样对匿名内部类生效。 匿名内部类不能是抽象的，它必须要实现继承的类或者实现的接口的所有抽象方法。 匿名内部类使用外面定义的变量，该变量必须用final修饰 123new 父类构造器（参数列表）|实现接口 ()&#123; //匿名内部类的类体部分&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://wangminrui.github.io/tags/Java基础/"}]},{"title":"Java基础概念","slug":"Java基础概念","date":"2018-12-11T01:09:05.000Z","updated":"2019-07-26T01:16:12.778Z","comments":true,"path":"2018/12/11/Java基础概念/","link":"","permalink":"http://wangminrui.github.io/2018/12/11/Java基础概念/","excerpt":"只要有笔记，不怕记不牢","text":"只要有笔记，不怕记不牢 抽象方法： 抽象方法只有声明，没有具体的实现，抽象方法的声明格式为： 1abstract void fun(); 抽象方法必须用abstract修饰，但接口中的抽象方法可以不用abstract修饰 抽象方法： 如果一个类含有抽象方法，则称这个类为抽象类，抽象类必须用abstract修饰（一个类没有抽象方法，但是用abstract修饰了也是抽象方法）抽象类中含有无具体实现的方法，所以不能用抽象类创建对象 装箱和拆箱： Java类型要么是引用类型（如Byte、Integer、Object、List），要么是原始类型（如int、double、byte、char）。装箱（boxing）是将原始类型转换为对应的引用类型的机制拆箱（unboxing）是将引用类型转换为原始类型的机制 形参： 形式参数，formal parameter，如同占位符，当方法被调用时，传递一个值给形参形参只有在被调用时才分配内存单元，在调用结束时，即刻释放所分配的内存单元。因此，形参只在函数内部有效。函数调用结束返回主调用函数后不能再使用该形参eg: 定义一个函数void add(int a, int b)，这里a和b就是形参 实参： 实际参数，actual parameter，可以是常量、变量、表达式、函数等，在进行函数调用时，都必须有确定的值，以便把这些值传送给形参eg: 当进行函数调用的时候，add(1, 2)，这里的1和2就是实参 方法签名： 方法名称+参数列表（包括参数顺序和类型）注意，签名不包括方法的访问修饰符和返回类型 方法头： 方法的修饰符、返回值类型、方法名、形式参数（最后两项是方法签名）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://wangminrui.github.io/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/"},{"name":"Java基础","slug":"学习笔记/Java/Java基础","permalink":"http://wangminrui.github.io/categories/学习笔记/Java/Java基础/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://wangminrui.github.io/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://wangminrui.github.io/tags/Java基础/"}]},{"title":"论文阅读","slug":"论文阅读","date":"2018-10-01T01:27:08.000Z","updated":"2019-08-01T01:34:21.569Z","comments":true,"path":"2018/10/01/论文阅读/","link":"","permalink":"http://wangminrui.github.io/2018/10/01/论文阅读/","excerpt":"","text":"【arxiv 2019】Adapting RNN Sequence Prediction Model to Multi-label Set Prediction摘要我们提出RNN序列模型适应文本的多标签分类问题，其中目标是一组标签，而不是序列。以前的这种RNN模型定义了序列的概率，但没有定义集合的概率;尝试获得集合概率是网络设计的后想法，包括预先指定标签顺序，或者以特定方式将序列概率与集合概率相关联。 我们的公式来源于集合概率的原则概念，作为集合的相应置换序列的概率之和。我们提供了一个新的训练目标，可以最大化此设置概率，以及一个新的预测目标，可以在测试文档中找到最可能8的集合。这些新目标在理论上具有吸引力，因为它们为RNN模型提供了发现最佳标签顺序的自由，这通常是自然的（但在文档中不同）。我们开发有效的程序来解决培训和预测中涉及的计算困难。基准数据集上的实验表明，我们在这项任务中的表现优于最先进的方法。 顶会文章网址 多标签分类paper具体的几篇介绍 从2006到2017 知乎 深度学习：如何在多标签分类问题中考虑标签间的相关性？ 有两篇文章 英文【第十二周】【2018】【EMNLP】【短文本】Topic Memory Networks for Short Text Classification 原文 本地 原文 在线 问题方法实验结论future work【第十二周】【2018】【EMNLP】【多标签】【短文本】HFT-CNN: Learning Hierarchical Category Structure for Multi-label Short Text Categorization Shimura K, Li J, Fukumoto F. HFT-CNN: Learning Hierarchical Category Structure for Multi-label Short Text Categorization[C]//Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018: 811-816. 原文 本地 原文 在线 问题专注于短文本的多标签分类任务 与较高级别的类别相比，较低级别的类别是细粒度的。此外，通常情况是较低级别的训练数据量远小于较高级别的训练数据量，这会降低分类的整体性能。 方法我们提出了一种方法，通过对CNN进行微调，可以有效地利用上层数据进行较低级别的分类，CNN可以学习类别的HS，并将类别的粒度纳入分类。我们根据HS调整了从上到下训练的CNN的参数，并精确调整了参数。 本文的主要贡献： 我们提出了一种方法，可以最大化预定义类别的影响，以减轻多标签短文本中的数据稀疏性。 我们通过CNN实证检查了适合学习词典编纂者定义类别的HS的微调 结果表明我们的方法通过使用两个基准来竞争最先进的CNN方法数据集，尤其对于由具有大量标签的几个单词组成的短文本的分类是有效的。 实验数据集： RCV1 集中使用了标题，所以是短文本，最长是13words Amazon670K 抽取商品名称和描述中前13个words baseline: XML-CNN WoFT-CNN 结论 We have presented an approach to multi-label categorization for short text. The comparative results with XML-CNN showed that HFT-CNN iscompetitive, especially for the cases that there exists only a small amount of training data. Future work will include: (i) incorporating lexicalsemantics such as named entities and domainspecific senses for further improvement, (ii) extending the method to utilize label dependencyconstraints (Bi and Kwok, 2011), and (iii) improving the accuracy of the top ranking categories todeal with P@1 and NDCG@1 metrics. future work未来的工作将包括：（i）结合词汇语义，如命名实体和领域特定意义进一步改进，（ii）扩展方法以利用标签依赖性约束（Bi和Kwok，2011），以及（iii）提高准确性 处理P @ 1和NDCG @ 1指标的排名最高的类别。 【第十二周】【arxiv】【2017】ProjectionNet Learning Efficient On-Device Deep Networks Using Neural Projections 原文 本地 原文 在线 问题深度神经网络不适合在移动设备这类有限计算能力的设备上运行 方法我们引入了一种使用联合优化框架训练紧凑神经网络的新架构。其核心是一个新的目标，它使用两种不同类型的网络联合训练 - 全训练器神经网络（使用现有架构，如前馈NN或LSTM RNN）与更简单的“投影”网络相结合，利用随机投影来转换输入或中间表示为位。更简单的网络在位空间中编码轻量级且高效的计算操作，内存占用少。这两个网络使用反向传播进行联合训练，其中投影网络从完整的网络中学习，类似于学徒学习。一旦经过训练，较小的网络可以直接用于低内存和计算成本的推理。 本文的主要贡献如下： 神经投影框架可以利用任何现有的深度网络，如前馈或递归神经网络，在联合优化设置中教授轻量级投影模型，该设置使用反向传播进行端到端训练。我们使用基于局部敏感散列的投影来表示轻量级网络的隐藏单元，该网络编码在推理期间非常有效计算的操作 该框架允许有效的分布式培训，但经过优化，可生成内存占用少的神经网络模型，可以低成本运行在设备上。模型大小可根据任务或设备容量进行参数化和配 我们展示了新方法在实现模型尺寸显着缩小的同时，在多种视觉和语言分类任务中提供竞争性能的有效性 所提出的框架进一步用于研究和表征现有深度网络的预测能力，以及紧凑地表示它们所需的神经投影比特数 使用了二进制局部敏感哈希 LSH 实验结果我们引入了一种新的神经投影方法来训练轻量级神经网络模型，以便以低计算和内存成本对设备进行有效推理。 我们展示了这种方法对模型大小和深度网络架构变化的灵活性。 在不同的视觉和语言分类任务上的实验结果表明该方法在提供显着的模型尺寸减小和有效推理的同时提供竞争性能的有效性。 我们还重新审视了深度网络的可预测性问题，并在神经位预测的背景下对此进行了研究。 future work除了深度学习之外，还可以应用该框架来训练其他类型的学习场景中的轻量级模型。 例如，训练范例可以改变为半监督或无监督的设置。 可以修改训练器模型本身以结合在图形或概率图形模型而不是深度神经网络上定义的结构化损失函数。 图3示出了使用图优化损失函数学习轻量模型的端到端投影图方法，该函数可以使用大规模分布图算法甚至神经图方法进行有效训练。 投影模型训练还可以进一步扩展到涉及使用互补技术的分布式设备的场景。 我们将这些探索留作未来的工作。 【第十二周】【EMNLP】【2018】【短文本】elf-Governing Neural Networks for On-Device Short Text Classification Ravi S, Kozareva Z. Self-Governing Neural Networks for On-Device Short Text Classification[C]//Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018: 804-810. 原文 本地 原文 在线 问题在微小内存占用和低计算能力的移动电话或智能手表等设备上运行这些复杂的网络 微小的内存占用 推理延迟和 在云端，与高性能计算系统（如CPU，GPU和TPU）相比显着低的计算容量 方法本文的主要贡献是： 用于短文本分类的设备深度学习的新型自治神经网络（SGNN）。 压缩技术可有效捕获低维语义文本表示，并生成可节省存储和计算成本的紧凑模型。 动态计算投影向量，无需大型预训练词嵌入或词汇修剪。 对话行为数据集的详尽实验评估，优于深度CNN（Lee和Dernoncourt，2016）和RNN变体（Khanpour等，2016; Ortega和Vu，2017）。 模型架构： SGNN： 该网络的自治属性源于其学习模型（例如，分类器）的能力，而无需初始化，加载或存储任何特征或词汇量权重矩阵。 从这个意义上说，我们的方法是一种真正无嵌入的方法，不像NLP中大多数广泛使用的最先进的深度学习技术，其性能取决于在大型语料库上预先训练的嵌入。 相反，我们使用投影函数将每个输入动态转换为低维表示。此外，我们将其与附加层和非线性激活相叠加，以实现投影的深度非线性组合，从而允许网络学习从输入xi到输出yi的复杂映射。 实验数据集对话行为的数据集 baselineWe compare our model against a majority classbaseline and Naive Bayes classifier (Lee and Dernoncourt, 2016). Our model significantly outperforms both baselines by 12 to 35% absolute. 结果我们提出了自我管理神经网络用于设备上的短文本分类。 多个对话行为数据集的实验表明，我们的模型优于最先进的深度学习方法（Lee和Dernoncourt，2016; Khanpour等，2016; Ortega和Vu，2017）。 我们引入了一种压缩技术，可有效捕获低维语义表示，并生成可显着节省存储和计算成本的紧凑模型。 我们的方法不依赖于预先训练的嵌入，并且可以有效地计算投影向量。 future work将来，我们有兴趣将此方法扩展到更自然的语言任务。 例如，我们建立了一个多语言的SGNN模型，用于客户反馈分类（Liu et al。，2017），获得73％的日本，接近最佳绩效系统（Plank，2017）。 与他们的方法不同，我们没有使用任何预处理，标记，解析，预先训练的嵌入或其他资源。 【第十一周】【2018】【EMNLP】【胶囊网络】Investigating Capsule Networks with Dynamic Routing for Text Classification Yang M, Zhao W, Ye J, et al. Investigating Capsule Networks with Dynamic Routing for Text Classification[C]//Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018: 3110-3119. 原文 本地 原文 在线 问题&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;作为一种空间敏感模型，CNN为网格上复制特征探测器的低效性付出了代价。正如在（Sabour等，2017）中所论述的，人们必须在大小随维数增加指数增长的复制检测器和以类似指数方式增加标记训练集的体积之间进行选择。另一方面，空间不敏感的方法在判断的场景中是完全有效的，而不管任何单词或局部模式的顺序如何。但是，它们不可避免地受限于特征序列中呈现的丰富结构。因此，提高编码序列空间顺序的效率，同时保持代表能力的灵活性是一个主要问题。 CNN 在对空间信息进行建模时，需要对特征检测器进行复制，降低了模型的效率 另一方面，空间不敏感的方法不可避免地受限于丰富的文本结构（比如保存单词的位置信息、语义信息、语法结构等），难以有效地进行编码且缺乏文本表达能力。 方法 四层网络： ngram convolutional layer n-gram卷积层 primary capsule layer 初级胶囊层 convolutional capsule layer 卷积胶囊层 fully connected capsule layer 全连接胶囊层 连续两个卷积层采用动态路由替换池化操作 卷积层和初级胶囊层 卷积层：提取低层特征 初级胶囊层：把卷积层输出的标量特征转换为矢量特征，以保留实例化参数 路由过程 在路由过程中，许多胶囊属于背景胶囊，它们和最终的类别胶囊没有关系，比如文本里的停用词、类别无关词等等。因此，我们提出三种策略减少背景或者噪音胶囊对网络的影响。 Orphan类别：在胶囊网络的最后一层，我们引入 Orphan 类别，它可以捕捉一些背景知识，比如停用词。在视觉任务加入 Orphan 类别效果比较有限，因为图片的背景在训练和测试集里往往是多变的。然而，在文本任务，停用词比较一致，比如谓词和代词等。 Leaky-Softmax：除了在最后一层引入 Orphan 类别，中间的连续卷积层也需要引入去噪机制。对比 Orphan 类别，Leaky-Softmax 是一种轻量的去噪方法，它不需要额外的参数和计算量。 路由参数修正：传统的路由参数，通常用均匀分布进行初始化，忽略了下层胶囊的概率。相反，我们把下层胶囊的概率当成路由参数的先验，改进路由过程。 卷积胶囊层 胶囊将乘以变换矩阵来学习孩子 - 父母关系，然后通过协议路由以在上述层中生成父胶囊 全连接胶囊层 下一层的胶囊被放入了一个胶囊列表中，并输入到全连接的胶囊层中，胶囊与胶囊乘以变换矩阵，然后通过协议路由产生最终的胶囊及其概率 两种胶囊网络的架构 Capsule-B的基本结构与Capsule-A类似，不同之处在于我们在N-gram卷积层中采用了滤波窗口（N）为3，4，5的三个并行网络。完全连接的胶囊层的最终输出被馈送到平均池中以产生最终结果。这样，Capsule-B可以学习更有意义和更全面的文本表示。 实验数据集六个标准数据集 movie reviews (MR) (Pang and Lee,2005) Stanford Sentiment Treebankan extension of MR (SST-2) (Socher等，2013) Subjectivity dataset (Subj) (Pang and Lee, 2004) TREC questiondataset(TREC)(LiandRoth,2002) customer review (CR) (Hu and Liu, 2004) AG’s news corpus (Conneau等，2017). baseline LSTM / Bi-LSTM（Cho等，2014） 树型LSTM（Tree-LSTM）（Tai等，2015） 通过语言知识正则化的 LSTM (LR-LSTM) （Qian等，2016） CNNrand/CNN-static/CNN-non-static（Kim等，2014） 深层卷积网络（VD-CNN）（Conneau等，2016） 字符级卷积网络（CL-CNN）（Zhang等，2015） CapsuleB始终比CapsuleA表现好，因为Capsule-B允许学习更有意义和更全面的文本表示 单标签到多标签的分类迁移单标签文字，实际上很容易收集和注释样本。然而，大规模多标签文本数据集的收集和注释负担通常非常高。由于多标签训练样本不足，神经网络（例如，CNN和LSTM）如何最好地处理多标签文本分类仍然是个问题。 根据（Sorower，2010），我们采用微平均精度（Precision），微平均召回（Recall）和微平均F1评分（F1）作为多标签文本分类的评估指标。这些分数中的任何一个都是首先在各个类别标签上计算出来的，然后在所有类别上进行平均，称为基于标签的度量。此外，我们还测量精确匹配率（ER），将部分正确的预测视为不正确，而只计算完全正确的样本。 结果利用胶囊的概念来改善CNN和RNN的表征局限性。（Hinton等，2011）首先介绍了“胶囊”的概念，以解决CNN和RNN的代表性局限性。具有变换矩阵的胶囊允许网络自动学习部分 - 整体关系。因此，（Sabour等，2017）提出了胶囊网络，其用矢量输出胶囊代替了CNN的标量输出特征检测器，并通过协议路由来代替最大池化。胶囊网络通过在MNIST数据上实现最新的结果显示了它的潜力。然而，与CNN中的最大池化技术不同，胶囊网络不会丢弃有关该区域内实体的准确位置的信息。对于低级胶囊，位置信息被编码到较为活跃的胶囊中。（Xi等，2017）进一步测试了胶囊网络在维数较高的CIFAR数据上的应用。（Hinton等，2018）提出了一种基于EM算法的胶囊层之间的迭代路由过程，该算法在小型NORB数据集上实现了更好的精度。迄今为止，还没有工作调查NLP任务中胶囊网络的性能。这项研究在这个主题中占据领先地位。 在本文中，我们调查了用动态路由进行文本分类的胶囊网络。提出了三种策略来提高动态路由过程的性能，以减轻噪声胶囊的干扰。在六个文本分类基准上的大量实验显示了胶囊网络在文本分类中的有效性。更重要的是，当通过与已有效果较好的基本方法比较，测试单标签到多标签文本分类时，胶囊网络也显示出显着的改进。 【第十周】【2018】【NAACL】【Attention】Hierarchical Attention Networks for Document Classification 原文 本地 原文 在线 Yang Z, Yang D, Dyer C, et al. Hierarchical attention networks for document classification[C]//Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016: 1480-1489. a hierarchical structure： words form sentences,sentences form a document 文档层次结构应该是指所有文档都是由句子组成，句子又是由词组成 The key difference to previous work is that oursystem uses context to discover when a sequence oftokens is relevant rather than simply filtering for (sequences of) tokens, taken out of context. 【第十周】【2017】【ACL】【把话语模式识别当做多标签序列标记问题】Discourse Mode Identification in EssaysModel 用word2vec训练好的词向量 用双向GRU做多标签分类 固定五个标签，如果该标签的概率大于0.5则判定该标签正确。 实验结果 SVM: We use bag of ngram (unigram and bigram) features to train a support vector classifier for sentence classification CNN: We implement a convolutional neuralnetwork (CNN) based method (Kim, 2014),as it is the state-of-the-art for sentence classification. GRU: We use the sentence level representation in Figure 2(a) for sentence classification. GRU-GRU(GG): This method is introducedin this paper in §4.1, but it doesn’t considerparagraph information. GRU-GRU-SEG (GG-SEG): The model considers paragraph information on the top of GG as introduced in §4.1.1 【第十周】【2018】【IJCAI】JUMPER: Learning When to Make Classification Decisions in Reading Liu X, Mou L, Cui H, et al. Jumper: Learning when to make classification decisions in reading[C]. International Joint Conference on Artificial Intelligence, 2018. 原文 在线 原文 本地 【第十周】【2018】【ACL】【词向量方向的改进】Joint Embedding of Words and Labels for Text Classification Wang G, Li C, Wang W, et al. Joint Embedding of Words and Labels for Text Classification[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018, 1: 2321-2331. 原文 在线 原文 本地 主要是在词向量方向做的工作没看下去 过段时间看 【第十周】【2016】【ICML】【新的分类层】【只看了实验应用于多标签分类的部分】From softmax to sparsemax: A sparse model of attention and multi-label classification Martins A, Astudillo R. From softmax to sparsemax: A sparse model of attention and multi-label classification[C]//International Conference on Machine Learning. 2016: 1614-1623. 原文 在线 原文 本地 主要是提出了一种新的分类层，从softmax到sparsemax 多标签分类实验数据集 the four small-scale datasets used byKoyejo et al. Reuters RCV1v2 结果【第九周】【2017】【IJCNN】【多标签分类】【RCNN】nsemble Application of Convolutional and Recurrent Neural Networks for Multi-label Text Categorization Chen G, Ye D, Xing Z, et al. Ensemble application of convolutional and recurrent neural networks for multi-label text categorization[C]//Neural Networks (IJCNN), 2017 International Joint Conference on. IEEE, 2017: 2377-2383. 原文 本地 原文 在线 主要工作 word2vec训练词向量 CNN训练从word2vec得到的词向量，从而得到一个feature vectors 输入：the input text isfirstly preprocessed and tokenized into a sequence of words. Each word will look up the word embedding matrix obtainedfrom the word2vec model.Theoriginal text is then a concatenation of word vectors w_i \\in R^k, S = w_{1:m} = w_1 \\bigoplus w_2 \\bigoplus ... \\bigoplus w_m 像TextCNN一样训练，激活函数用ReLu(因为有论文证明它比sigmoid和tanh都好)，池化层用l-maxpooling 用RNN进行标签序列预测 the standardLSTM is used. An additional word embedding layer is alsoapplied for the labels. 把CNN和RNN联合在一起 在LSTM每一次输出前加一个softmax layer，计算最高概率的标签并输出 输出y 等于 上一次循环的输出，与上一次循环的隐含层、与feature vector，联合输入进行计算 猜测：每次输出时计算softmax得出的概率都有一个阈值，如果不超过这个阈值，就认为这里没有输出标签，输出，因此每次输出的标签序列是变长的 使用softmax分类器作为用于标签预测的LSTM的上层，然后将交叉熵损失从RNN向下传播回CNN以更新CNN-RNN模型的权重。 实验数据集 Reuters-21578: 21578个文档；进行10倍交叉验证 RCV1-v2: 超过80万篇新闻；标签103个；进行10倍交叉验证 评估方法标签排名度量：one-error ？计算实例中的小部分(不在相关表中中的预测标签的top1)？ 分类度量 hamming loss 汉明损失 macro/micro-averaged precision 宏/微平均精确度 recall 召回率 F1 score F1积分 参数 The window size is chosen up to 9-gram. The dimension of word vector is chosen as 400 while the number of filters in each window size is chosen as 128. The nonlinear function we choose is Relu, because [32] shows that a rectified linear unit has more benefits than sigmoid and tanh function. 1-Max-pooling is applied in all filters so that each window size will output a 128-dimension feature vector. 结果 Complexity of RNN versus performance: we set the CNN-RNN parameter ratio as 50% and the training epoch is limited to 50. Baseline comparison baseline algorithm: Binary relevance (BR), Classifier chain (CC), MLkNN, ML-HARAM and our CNN-RNN model 对于Reuters-21578，本文模型没有比传统模型BR、CC优秀，原因可能是Reuters-21578中每个文件的平均标签数量大约为1，因此对高阶相关性建模没有太大意义。 对于RCV1-V2数据集，比大多数方法优秀，原因可能是对高阶标签相关性建模有助于预测数据集中发生频率较低的次要标签。 Our evaluations reveal that the power of the proposed method is affected by the size of the training dataset. If the data size is too small, the system may suffer from overfitting. However, when trained over a large-scale dataset, the proposed model can achieve the state-of-the-art performance. 【第八周】【2018】【COLING】【多标签分类】【Seq2Seq】SGM: Sequence Generation Model for Multi-label Classification Yang P, Sun X, Li W, et al. SGM: sequence generation model for multi-label classification[C]//Proceedings of the 27th International Conference on Computational Linguistics. 2018: 3915-3926. 原文 在线 原文 本地 主要工作 将MLC(多标签分类)问题视为序列生成问题，以考虑标签之间的相关性 提出一种新的Encoder-Decoder结构，不仅能捕获数据还能捕获标签之间的相关性，还会自动选择最有信息量的单词预测不同标签 细节 Sequence Generation 序列生成 Encoder 将输入的one-hot representation乘以一个矩阵得到一个词向量 使用双向LSTM得到每个词的隐含层 添加注意力机制（为每个词分配权重），从而得到语境向量c_t Decoder（给了一堆公式计算，几乎没看懂，理解如下） 根据语境向量计算隐含向量s_t 利用MS(masked softmax layer 应该是种softmax)得到对应t时刻的输出y_t，即一个标签 y_t$$利用Global embedding再计算下一时刻的$$y_{t+1} ==问题是：最后输出标签是否固定为n个？== Global Embedding 全局嵌入 前面预测的标签会影响后面的标签预测，称为exposure bias，如果前面预测的标签错了，会很大程度影响后面预测的标签 通过考虑每个标签的概率，该模型能够减少由前一时间步骤中的错误预测造成的损害。 全局嵌入是使用变换门H的原始嵌入和加权平均嵌入的优化组合，可以自动确定每个维度中的组合因子 y_{t-1} 是在 t-1 时刻标签空间 L 中的概率分布 e 是在 y_{t-1} 分布下最高概率的标签的嵌入 \\overline{e} 是在 t 时刻的具有权重的平均嵌入 1\\overline&#123;e&#125; = \\sum^&#123;L&#125;_&#123;i=1&#125;&#123;y_&#123;t-1&#125;^&#123;(i)&#125;e_i&#125; 1H = W_1e + W_2\\overline&#123;e&#125; 1g(y_&#123;t-1&#125;) = ((1 - H)\\bigodot e + H \\bigodot \\overline&#123;e&#125;) 实验数据集 Reuters Corpus Volume I (RCV1-V2) 80多万篇新闻，主题有103个 Arxiv Academic Paper Dataset (AAPD) 55,840篇论文，总共有54个科目 评估方法 汉明损失 micro-F1 micro-precision micro-recall 细节 不在词汇表中的词标记为unk 嵌入大小512 LSTM层数2 使用最小化交叉熵损失函数来训练数据 使用dropout避免过度你和 ？剪辑梯度下降到最大标准10？ 结果Baselines 【第六周】【ECCV】【2016】【深度残差网络】Identity Mappings in Deep Residual Networks He K, Zhang X, Ren S, et al. Identity mappings in deep residual networks[C]//European conference on computer vision. Springer, Cham, 2016: 630-645. 原文 本地 原文 在线 译文博客 中心思想这篇文章证明了当跳跃连接(skip connections)以及附加激活项**都使用恒等映射(identity mappings)时，前向和后向的信号能够直接的从一个block 传递到其他任意一个block。 跳跃连接使用恒等映射指的是跳跃过程中信息不变 附加激活项使用恒等映射指的是最后x_{l+1}不再使用激活函数非线性化F(x) + x_l ==具体的分析和消融实验过程没有看== 预激活 pre-activation： 把激活函数挪位置到F路径中后，看上去就像预激活 【第六周】【ACL】【2018】【zero-shot】Zero-shot Learning of Classifiers from Natural Language Quantification Srivastava S, Labutov I, Mitchell T. Zero-shot Learning of Classifiers from Natural Language Quantification[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018, 1: 306-316. 原文 本地 P306 基本思想： 在没有labeled examples的情况下学习（zero-shot) 利用量词的使用频率来分类，比如经常、偶尔 先把自然语言映射成量词的constraint 然后再利用constraint分类 ……没太看懂，也没有仔细看 【第六周】【ACL】【2018】【迁移学习】【ULMFiT】Universal Language Model Fine-tuning for Text Classification Howard J, Ruder S. Universal language model fine-tuning for text classification[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018, 1: 328-339. 原文 本地 P328 原文 在线 主要工作 提出了一个模型—ULMFiT，可以在NLP领域实现类似CV的迁移学习 提出了discriminative fine-tuning，slanted triangular learning rates， 和 gradual unfreezing （判别性微调，倾斜三角学习率和渐进解冻） 在六个具有代表性的文本分类数据集上表现明显优于最新技术，大多数数据集的误差减少了18-24％ We show that ourmethod enables extremely sample-efficient transfer learning and perform an extensive ablationanalysis（我们证明了我们的方法能够实现极其样本有效的转移学习并进行广泛的消融分析） 提供的预训练模型和代码可以广泛使用 提出的方法ULMFiT1. 通用域语言模型预训练(General-domain LM pretraining) 使用的通用域语料库为Wikitext-103（已经预处理的28595个维基百科文章和1.03亿个词） 没有细写具体的预训练方法，只给了一张图 a) The LM is trained on a general-domain corpus to capturegeneral features of the language in different layers 2. 目标任务语言模型微调(Target task LM fine-tuning)主要工作在于：discriminative fine-tuning，slanted triangular learning rates（判别性微调，倾斜三角学习率） discriminative fine-tuning 常规的梯度下降学习速率在每一层都是统一的，本文中将每一层的学习速率都做了区分 \\theta^l_t = \\theta^l_{t-1} - \\eta \\nabla_{\\theta^l}J(\\theta) 根据经验，先选择最后一层的学习速率\\eta^L，前一层的学习速率为\\eta^{l-1} = \\frac{\\eta^l}{2.6} slanted triangular learning rates 想要快速收敛到一个合适的区域，使用相同的学习速率或是annealed learning rate(退火学习速率？)并不是一个好的方法 倾斜三角学习速率首先线性地增加学习率，然后根据以下更新时间表线性衰减它 T是训练迭代次数 cut_frac = cut / T，相当于 \\eta从增加到减少的迭代次数占总迭代次数的比例 cut是当学习速率从增加到减少时的迭代次数 p是增加或即将减少学习速率的迭代次数除以总迭代次数 ratio指最小的学习速率和最大学习速率之间的差 \\eta_t是在第t次迭代时的学习速率 一般来说，cut_frac=0.1, ratio=32, \\eta_{max}=0.01 横轴是迭代次数 3. 目标任务分类器微调(Target task classifier fine-tuning) Contact pooling 联合池化 如果只考虑最后一层隐含层的状态，会丢失很多有用的信息 因此把上一个时间节点隐含状态h_T和所有隐含隐含状态的max-pooled和mean-pooled串联起来 h_c = [h_T, maxpool(H),meanpool(H)]，其中H = \\{h_1,...,h_T\\}，[ ]表示concatenation Gradual unfreezing 渐进解冻 从最后一层开始渐进解冻模型，而不是一次性fine-tuning所有层 首先解冻最后一层，并且微调所有未解冻的层；然后解冻倒数第二层，以此类推 ==什么是unfreezing？== BPTT for Text Classification(BPT3C) BPTT: backpropagation through time 提出BPT3C(BPTT for Text Classfication)，以解决大规模文本问题 首先把文档划分为大小为b 的固定长度的批次；在每个批次的初始状态，模型初始化为前一批次的最终状态；保持追踪平均池化和最大池化的隐含状态 ==这一段并没有看懂== Bidrectional language model 双向语言模型 与训练了前向传播和反向传播的LM 使用BPT3C分别微调了每个LM的分类器，然后平均分类器预测 ==也没有太看懂== 实验 应用的task：情感分析，问题分类，主题分类 数据集：IMDb，TREC-6，AG &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 别人的博客论文分享|《Universal Language Model Fine-tuning for Text Classification》 【第六周】【ACL】【2017】【DPCNN】Deep Pyramid Convolutional Neural Networks for Text Categorization Johnson R, Zhang T. Deep pyramid convolutional neural networks for text categorization[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2017, 1: 562-570. 原文 在线 原文 本地 DPCNN的关键点 下采样 预激活的跳跃连接和恒等映射（残差网络） 使用无监督训练，增强了text region embedding，以提高准确率 主要工作DPCNN 下采样 Downsampling 池化层，使用max-pooling,size 3,stride 3,两个步长，一次采样 不同于其他文献增加特征映射数量（增加特征映射应该是指增加卷积核）来提高准确率，本文采用固定的特征映射数，特征映射数250，卷积核size 3 基于以上两点形成了一个“金字塔”，我的理解是，每次池化之后，维度下降了一半，然后再次卷积、池化 因此，DPCNN的计算时间受一个常数限制，是单个块的计算时间的两倍（==为什么是单个块的两倍？单个块指什么？==） 预激活的跳跃连接 参考深度残差网络的文章，在本文中，跳跃了两层卷积层 使用深度残差网络中的预激活pre-activation 无需尺寸匹配 在下采样或者使用不同大小的特征映射时，可能会导致残差无法直接相加，需要执行尺度匹配 本文中采用两点解决以上问题 不跳跃任何下采样的层 在整个网络中使用固定大小的特征映射，这也节省了计算时间 区域文本嵌入 把k个words当成一个整体，用了三种输入：sequential input, bow input, bag-of-n-gram input，其中sequential input表现非常不好就省去了 使用了和ShallowCNN中相同的词向量训练方法tv-embedding tv-embedding tv-embedding需要两个view 把一个text region定义为view-1，把与其相邻的text region定义为view-2 用view-1预测view-2来训练神经网络 实验数据集如下 数据中的所有大写字母转为小写字母 词汇量大小限制在30K以内（但有文章证明这足以涵盖98%的文本） 实验结果如下： large dataset 的结果 small dataset 的结果 DPCNN深度一般是15，15表示两层的7个卷积块加上一层区域嵌入 总结这篇讲的是深层金字塔CNN，使用了残差网络思想+下采样造就了深层金字塔状的CNN，残差网络思想用于深层，下采样形成了金字塔。 实验结果比列出的所有网络都优秀 实验结果中反复提到了ShallowCNN，说DPCNN其实是更深的ShallowCNN Improved Neural Network-based Multi-label Classification with Better Initialization Leveraging Label Co-occurrence 2016 ACL 多标签分类 原文 本地 主要在神经网络的权重初始化上做的文章 首先调查已有的数据集中出现的共现标签组合，将权重矩阵的一部分变为每个标签组合的向量，其余随机初始化 数据集： 3133个查询用于训练；其中1695个有多标签； 394个查询用于评估；其中158个有多标签； 独立的标签一共有526个； 实验的CNN中，词向量维度100；卷积核1000,；输出神经元526 据作者说这样可以获得标签之间的关系，这样有一种聚类的效果。相似的样本会标记为相同的标签。此外他还提出了损失函数的计算方法。 Recurrent Convolutional Neural Networks for Text Classification 2015 原文 本地 别人的博客讲解 别人的博客翻译 翻得不好 卷积层：前向计算词语w_i的上文c_l(w_i) = f (W^{(l)}c_l(w_{i-1} + W^{(sl)}e(w_{i-1}))；后向计算词语w_i的上文c_r(w_i) = f (W^{(r)}c_r(w_{i-1} + W^{(sr)}e(w_{i-1}))；输入x_i = [c_l(w_i);e(w_i);c_r(w_i)]；卷积层输出y_i^{(2)} = tanh(W^{(2)}x_i + b^{(2)}) 池化层采用max-pooling，如图 最后用softmax输出概率 数据集 20Newsgroups Fudan set ACL Anthology Network Stanford Sentiment Treebank 结果分析：CNN只能通过定长的窗口来捕捉上下文信息，但是RCNN是通过循环结构获取更长的上下文信息;时间复杂度只有O(n) Recurrent Neural Network for Text Classification with Multi-Task Learning 2016 原文 在线 原文 本地 基于多任务的 研究方法 提出了三种架构的基于LSTM的共享模型 Uniform-Layer 任务之间共享LSTM层和Embedding层 Coupled-Layer 每个任务有自己的LSTM层 但是会相互交互 Shared-Layer 每个任务有自己的LSTM层，又加入了双向LSTM捕捉任务共享信息 实验数据集 SST-1 SST-2 SUBJ IMDB 实验过程 没有太看懂 实验结果误差分析 在复杂句子结构和要求推理的句子上表现不好 Convolutional Neural Networks for Sentence Classiﬁcation 最早开始将CNN应用于nlp领域的论文 原文 本地 原文 在线 上面那篇论文的中文博客比较好理解 还是上面那篇论文的中文博客不太好理解 但是比较详细 输入是词向量构成的矩阵，从上到下（用的是word2vec训练过的词向量） 卷积核比较特别，是一个h*k的矩阵，k是词向量的维度，h是一次卷积覆盖的单词数。 一个卷积核(Filter)就是一种特征识别器 池化层用最大池化max-pooling，解决了可能由于句子长度不同导致输出列向量长度不同的问题 全连接层，为了将pooling层输出的向量转化为我们想要的预测结果，加上一个softmax层即可 softmax层，逻辑回归模型在多分类问题上的推广CSDN博客 softmax层 CSDN博客 softmax、softmax loss、cross entropy 1f(z_j) = \\frac&#123;e^&#123;z_j&#125;&#125;&#123;\\sum^n_&#123;i=1&#125;e^&#123;z_i&#125;&#125; softmax输出的是样本属于个各类的概率 数据集 Google News; 100 billions words; 词向量维度300; 四种模型: CNN-rand: 所有词向量通过随机初始化得来，然后用CNN训练 CNN-static: 词向量通过word2vec得来，然后用CNN训练；如果存在词未知对应词向量则随机初始化，并且词向量在训练过程中不会改变 CNN-non-static: 词向量来源同上一条，但词向量会在训练过程中进行微调 CNN-multichannel: 两组词向量作为两个通道同时输入 中文硕博论文神经网络基于深度学习的知乎标题的多标签文本分类 北交专硕 2018 原文 本地 CNN 和 LSTM 和 CNN-LSTM 数据集 291433条知乎数据，百分之十测试集，百分之十验证集，百分之八十训练集 没什么创新 就是数据实验看上去比较真实 非神经网络基于新浪微博的短文本分类与个性化推荐 北邮硕士 2018 原文 本地 LDA做特征选择 SVM做文本分类 用k折交叉验证选取LDA和SVM的参数 感觉很水 期刊会议论文神经网络基于神经网络探究标签依赖关系的多标签分类 计算机研究与发展 2018 原文 本地 解决了两个问题： 不能充分探究标签依赖关系 标签缺失问题 本文的贡献 在神经网络顶层加入表示语义标签类之间的相似性度量矩阵Ω \\in R^{L*L}，刻画标签之间的依赖关系 基于标签之间的依赖关系处理标签缺失问题 构建３层网络结构，结构简单，能够有效避免复杂网络结构所引发的梯度不稳定性问题． 数据集： 非神经网络基于标签聚类的多标签分类算法 软件学报 2014 k-means 原文 本地 LCMLC(基于标签聚类的多标签分类算法) 将相关度高的标签聚合在一起形成新的标签组合，以此来发现那些重要的但不可见的标签组合 数据集：enron, gebase, medical, yeast, tmc2007，分别有文本、生物等领域的数据 ==什么是重要但不可见的标签？？==","categories":[{"name":"备忘录","slug":"备忘录","permalink":"http://wangminrui.github.io/categories/备忘录/"}],"tags":[]}]}